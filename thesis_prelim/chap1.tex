\chapter{Introduction}
\label{ch:intro}

Functional programming seeks to bring the benefits of mathematical functions over to the world of programming. In mathematics, a function's return value can only depend on the input, not on when -- or more generally, under which ``circumstances'' -- the function was called. This is in sharp contrast to imperative programming languages, which have a concept of \textit{mutable} state. For instance, a variable might be assigned different values at different times during the execution of a program, and a function might depend upon the value of this variable. A purely functional programming language doesn't allow the programmer to work with mutable state, which means that functions defined in such a language can be understood in the same way a mathematical function can. This clarity makes (purely) functional languages potentially less error-prone than imperative languages, since the programmer doesn't need to consider the mutable state, e.g., of variables.

Many functional programming languages, in particular, languages with static type-checking, have the language construct of \textit{data type definitions}. When type-checking is performed statically, i.e., before the execution of a program, the type-checker must be able to assign a type to each expression that appears in the program. Types can be regarded as sets of values; looking at it the other way around, values which are of a given type are said to \textit{inhabit} the type. With data type definitions, the programmer can specify -- or rather postulate -- which values are to inhabit the thus defined type. This is done by giving a number of \textit{constructors} for the type. For instance, a type for natural numbers can be defined by giving a constructor for the zero value, and one for successors, which takes an argument -- the predecessor -- which is itself a natural number.

In functional programming, a function definition often consists of a number of equations. This is strongly analogous to mathematics; a left-hand side (lhs) of such an equation specifies which inputs are to be considered, and the right-hand side specifies the corresponding output. Thus, there needs to be a way to introspect inputs. This brings us back to the data type definitions and their constructors. On the lhs of some equation for, e.g., a function $fun(\mathbb{N})$ with a natural number as input, the programmer can specify that he wishes the equation to define the output corresponding to, e.g., the zero value, or a successor, by using the respective constructor of the data type for $\mathbb{N}$, possibly together with variables or further constructors for its arguments. In symbols, for constructors $zero()$ and $succ(\mathbb{N})$, the lhs that captures the zero value input of $fun$ is $fun(zero())$, and the one that captures the input of a successor, with the predecessor argument left unspecified, it $fun(succ(x))$, where $x$ is a variable. This concept is called \textit{pattern matching}, and the constructors and variables used in this way to introspect the input are called \textit{patterns}. For many concepts, it is interesting to also explore their \textit{dual}. The dual of patterns are the so-called copatterns. Basically, they allow to introspect, or observe, the output of a function; more on this later.

Another important feature of many functional programming languages is that they have \textit{first-class functions}. This is to say that functions can be used just like other objects, e.g., a function can be passed as an argument to another function. This can be very useful, e.g., to define filters or maps over collections. A language with first-class functions is also called \textit{higher-order}, in contrast to languages lacking this feature, which are called \textit{first-order}.

Sometimes, a first-order specification of some function can be beneficial over an equivalent higher-order specification, and sometimes it is the other way around. This can depend upon whether human understandability or a certain property advantageous for machine processing is desired. For this reason, researchers are interested in finding and automatizing transformations which can bring a higher-order program into a semantically equivalent first-order form, or the other way around. Transforming a higher-order program (with first-class functions) into an equivalent first-order program (without first-class functions) is called defunctionalization, the opposite direction is called refunctionalization.

In this work, we develop automatic program transformations for a specific language with copattern matching, called \textit{Uroboro}. One major goal is to support automatic de- and refunctionalization for all of Uroboro. Uses for these kinds of transformations have been presented by Reynolds and Danvy, among others. Uroboro is interesting for the purpose of automatizing such transformations, because, as Rendel et al.\cite{rendel15automatic} have shown, copatterns and refunctionalization are related. Rendel et al. have already developed automatic de- and refunctionalization between two fragments of Uroboro, called the Data and Codata Fragment. Based on their work, we contribute the following.
\begin{itemize}
\item We formally define the full language Uroboro, which is an extension of both the Data and the Codata Fragment.

\item We have developed and/or adapted the necessary transformation steps, such that one can now automatically de- and refunctionalize all of Uroboro; these transformations preserve the semantics of programs -- see the next point.

\item For some of the steps, we have identified a generalization; we call such transformations \textit{extractions}. We also show how extractions preserve the semantics of programs; we essentially use this result when proving that our automatic de- and refunctionalization preserve semantics.

\item When developing automatic refunctionalization, we have encountered a complication which doesn't have an analogue in defunctionalization; we have identified the general problem underlying this, shining a light on an asymmetry between patterns and copatterns.
\end{itemize}
We intend the transformations of this work to be a foundation for an entire toolbox of automatic transformations for Uroboro.

In this introduction, we first give an informal overview of de- and refunctionalization. Next, we briefly describe copatterns. We then outline how Uroboro relates these two concepts and why we consider this language interesting. Finally, we sum up the contents of this thesis.

\textit{Defunctionalization} is a technique to transform higher-order programs into semantically equivalent first-order programs. It was first described by Reynolds\cite{reynolds72definitional}, who uses it as one of several tools to compile interpreters. We illustrate defunctionalization with the following example program, presented in a Haskell-like pseudocode.

\begin{lstlisting}

filterNats :: ((Nat -> Bool), [Nat]) -> [Nat]
filterNats (f, x:xs)
  | f x = x:(filterNats (f, xs))
  | otherwise = filterNats (f, xs)
filterNats (_, []) = []

even :: Nat -> Bool
even Zero = True
even Succ(n) = not (even n)

main :: [Nat]
main = filterNats (even, [1, 2, 3, 4, 5])

\end{lstlisting}

This program is higher-order because the first argument of \texttt{filterNats} has a function type (\texttt{Nat -> Bool}). Defunctionalization does the following:
\begin{enumerate}
\item  A data type \texttt{NatBoolFun} for this function type is introduced, with a constructor \texttt{Even} for \texttt{even}.
\item A function \texttt{apply :: (NatBoolFun, Nat) -> Bool} is introduced, which has an equation for every equation in \texttt{even}. The left-hand side \texttt{even $p$}, where $p$ is some pattern, of an equation of \texttt{even} is replaced by \texttt{apply (Even, $p$)}, and the respective right-hand sides are identical (preliminarily).
\item Each call to \texttt{even} is replaced by the corresponding call to \texttt{apply}, and each occurrence of \texttt{even} in an argument position is replaced by \texttt{Even}.
\item The function definition for \texttt{even} is removed.
\end{enumerate}
The result is presented below.

\begin{lstlisting}

data NatBoolFun = Even

apply :: (NatBoolFun, Nat) -> Bool
apply (Even, Zero) = True
apply (Even, Succ(n)) = not (apply (Even, n))

filterNats :: (NatBoolFun, [Nat]) -> [Nat]
filterNats (f, x:xs)
  | f x = x:(filterNats (f, xs))
  | otherwise = filterNats (f, xs)
filterNats (_, []) = []

main :: [Nat]
main = filterNats (Even, [1, 2, 3, 4, 5])

\end{lstlisting}

This transformation is easily automatized. In general, the procedure described above is applied to all occurrences of function types in the program.

\textit{Refunctionalization} is the left inverse of defunctionalization, first described by Danvy and Millikin\cite{danvy09refunctionalization}. Its goal is to undo defunctionalization. When one knows where to find the function that serves the role of \texttt{apply} in the example above, this is easily done by just reverting the steps described above. However, in general there can be multiple functions which have the correct form for this, and could all possibly be \texttt{apply} functions. In its originally described form, refunctionalization therefore only works on programs which are the result of the defunctionalization of some other program.

However, it would be desirable to have a transformation that transforms \textit{all} first-order programs into semantically equivalent higher-order programs, like defunctionalization does it the other way around. This is where another concept comes into play: copatterns and codata.

\textit{Copatterns} are the dual to patterns, in the following sense. Where patterns allow one to distinguish between different inputs to a function, with copatterns one can observe the output. The need to observe output arises naturally when describing infinite structures. Copatterns are thus connected to \textit{codata}. Where data type definitions are used for finite structures like natural numbers, codata type definitions are used for infinite structures like streams. Consider the following example program:

\begin{lstlisting}

codata Stream = {head :: Nat, tail :: Stream}

repeat :: Nat -> Stream
head (repeat n) = n
tail (repeat n) = repeat n

\end{lstlisting}

The codata type definition for \texttt{Stream} gives the ways, called \textit{destructors}, in which a stream can be observed, or \textit{destructed}. One is fetching its head, which is a natural number, the other is fetching the tail, which again is a stream. The function \texttt{repeat} describes a stream that always returns the same number when fetching its head. For this, the left-hand sides of the definition for \texttt{repeat} use copatterns; one applies the destructor \texttt{head}, the other the destructor \texttt{tail}.

Uroboro is a functional programming language. Instead of first-class functions, Uroboro has its generalization, codata types, and copattern matching. We first show how two fragments of Uroboro relate codata and copatterns with refunctionalization. Then we motivate why Uroboro is interesting -- in general, and in particular for our purpose of automatic program transformations.

How do copatterns and codata relate to refunctionalization? Rendel et al.\cite{rendel15automatic} show how a program in a certain first-order language -- which they call the Data Fragment -- can be automatically transformed to a language -- which they call the Codata Fragment -- with copattern matching, and vice versa. The authors intend these two languages to be fragments of Uroboro. The key idea of Rendel et al. is that codata can be regarded as a generalization of first-class functions. This solves the problem of the multiple apply functions described above. Consider the following example program in the Data Fragment.

\begin{lstlisting}

data Nat where
  Zero(): Nat
  Succ(Nat): Nat

function add(Nat, Nat): Nat where
  add(Zero(), n) = n
  add(Succ(m), n) = Succ(add(m, n))

function multiply(Nat, Nat): Nat where
  multiply(Zero(), n) = Zero()
  multiply(Succ(m), n) = add(multiply(m, n), n)

\end{lstlisting}

Here, both \texttt{add} and \texttt{multiply} could possibly play the role of apply functions. The refunctionalization of Rendel et al. does the following:
\begin{enumerate}
\item The data type definition \texttt{Nat} is replaced by a codata type definition which has a destructor for each function whose first argument has type \texttt{Nat}.
\item For each constructor of \texttt{Nat}, a function definition is added, the equations of which correspond to the equations of all function definitions (here, both \texttt{add} and \texttt{multiply}) where the first argument of the left-hand side pattern is this constructor. Instead of a pattern with a constructor, the left-hand sides of these are now copatterns with the corresponding destructor. The right-hand sides are likewise transformed.
\end{enumerate}
The result of refunctionalization is shown below.

\begin{lstlisting}

codata Nat where
  Nat.add(Nat): Nat
  Nat.multiply(Nat): Nat

function Zero(): Nat where
  Zero().add(n) = n
  Succ(m).add(n) = Succ(m).add(n)

function Succ(Nat): Nat where
  Zero().multiply(n) = Zero()
  Succ(m).multiply(n) = m.multiply(n).add(n)

\end{lstlisting}
The Codata Fragment's syntax for destructors, \texttt{fun(s).des} is taken from Abel et al.\cite{abel13copatterns} and is syntactical sugar for the form \texttt{des(fun(s))} used above.

Rendel et al.s\cite{rendel15automatic} refunctionalization for the Data Fragment finds its reverse in their defunctionalization for the Codata Fragment. As an example, consider the result of refunctionalization of the example program above. Defunctionalizing this program leads back to the original program. Rendel et al. show that, when one views programs as two-dimensional matrices, defunctionalizing the Codata Fragment and refunctionalizing the Data Fragment can be regarded as one and the same function, namely matrix transposition.

Rendel et al. intend the Data Fragment and the Codata Fragment to be fragments of a common language, called Uroboro. In the \hyperref[ch:uro]{following chapter}, we formally define this language in full for the first time. Here, we motivate why we think Uroboro is interesting in general and for our purpose, automatic program transformations.

In our opinion, Uroboro is well suited for automatic program transformations which are related to the conversion between first-order and higher-order programs. There are two major reasons for this:
\begin{itemize}
\item Uroboro isn't truly ``higher-order'', i.e., it has no first-class functions and no function types. Functions and destructors have fixed-length argument lists, i.e., there can be no ``underapplication'' (but this can be emulated with destructors). Destructors in Uroboro are thus somewhat similar to methods in object-oriented programming languages.

\item Uroboro is symmetric in the sense that it has both data type definitions and its dual codata type definition, along with patterns and its dual copatterns. This is interesting for automatic transformations, since, as described before, the Data Fragment and the Codata Fragment of Uroboro are connected by refunctionalization and defunctionalization.
\end{itemize}
We aren't aware of any existing languages which have both of these properties.

As stated before, codata generalizes first-class functions. For this reason, Uroboro doesn't lose expressiveness when compared to languages with first-class functions but without parametric polymorphism. Thus, in our opinion, Uroboro, or rather a future version of it that includes parametric polymorphism, has the potential to replace certain higher-order languages. We give more details on this in \autoref{sec:reluro}.

We now sum up the remaining contents of this work.

In \autoref{ch:uro}, we define the language Uroboro. We give its syntax in \autoref{sec:urosyn}, typing in \autoref{sec:urostatsem}, and finally its dynamic semantics in a small-step operational way \autoref{sec:urosos}. Then we discuss coverage (\autoref{sec:cc}) and type soundness (\autoref{sec:urots}). We also show how the reduction relation of the full Uroboro extends that of the Data and Codata Fragment.

In \autoref{ch:extr}, we introduce the notion of \textit{extractions}. Extractions are basic automatic program transformations that decrease the syntactic complexity of the program while preserving its reduction semantics in some way. Syntactic complexity is decreased in the left-hand sides of some of the program's equations, such that the new lhs is the result of what we call a extraction projection applied to the old lhs. An extraction projection is a function which is the inverse of either a substitution or its dual, a co-substitution. The reduction semantics are preserved in a weak bisimulation; this is achieved by introducing an auxiliary function. The precise definition of extractions is given in \autoref{sec:extrdef}; example extractions are given in \autoref{sec:extrex}. The proof of bisimulation follows in \autoref{sec:extrbis}. Under which circumstances an important property, the absence of overlaps, holds in programs that are the result of extraction, is stated and proven in \autoref{sec:extrovl}. The preservation of well-typedness is discussed in \autoref{sec:extrpwt}.

In \autoref{ch:derefunc}, we give an automatic defunctionalization and refunctionalization for the full Uroboro. Both are made up of two phases. First, the program needs to be simplified. We describe this process, called unnesting, in \autoref{sec:unn}. After this, core defunctionalization and core refunctionalization follow, described in \autoref{sec:coredefunc} and \autoref{sec:corerefunc}, respectively.

In \autoref{ch:impl}, we describe how we implemented our program transformations in Haskell. We also give an example application for defunctionalization and one for refunctionalization, both of which are known from the literature, but have only been transformed manually before.

\autoref{ch:rel} considers related and future work.

The \hyperref[ch:concl]{seventh and final chapter} concludes.
