% !TEX root = main.tex
\chapter{Extraction transformations}
\label{ch:extr}

The automatic de- and refunctionalization algorithms presented in \autoref{ch:derefunc} are made up of several ingredients, some of which are part of the motivation for the contents of this chapter. In the preprocessing phase of either algorithm, there are steps which eliminate destructors or constructors from copatterns. In this chapter, we generalize this concept to arbitrary \textit{extractions}.

Extractions are (a way to describe) transformations, that roughly speaking, decrease, in some way, the syntactic complexity of the program, while preserving its semantics to some degree. We think that this might also be interesting independent of its application for automatic de- and refunctionalization in \autoref{ch:derefunc}. For instance, the user might want to decrease the syntactic complexity, e.g., by reducing the maximum number of destructors appearing in any lhs, in order to better understand the program. This situation is comparable to certain refactorings in object-oriented programming, like moving methods or extracting classes.

As an example, consider the extraction of a destructor out of the following program fragment.
\begin{lstlisting}
fun().des().des() = t
\end{lstlisting}
The result is shown below; the transformation has introduced an auxiliary function, which is the reason why we chose the name ``extraction'': Some syntactic component is ``extracted'' into a newly added part of the program.
\begin{lstlisting}
fun().des() = aux()
aux().des() = t
\end{lstlisting}
The resulting program fragment doesn't contain any copatterns with two destructors, unlike the original, thus the transformation has decreased the syntactic complexity in this way. The transformation preserves the semantics because, roughly, in the transformed program there is a way to go from the original equation's lhs to its rhs: $\mathtt{fun().des().des()} \longrightarrow \mathtt{aux().des()} \longrightarrow \mathtt{t}$.

In the next section, we formally define extractions and how they are applied to programs (\autoref{sec:extrdef}). We give some example extractions, two of which are used in \autoref{ch:derefunc} (\autoref{sec:extrex}). Then we show how extractions preserve the semantics of a program in a weak bisimulation (\autoref{sec:extrbis}). The preservation of the semantics depends upon the absence of overlapping equations both in the original and in the resulting program; therefore, the section that follows shows under which circumstances extractions don't introduce overlaps (\autoref{sec:extrovl}). Then we show that extractions preserve the well-typedness of programs (\autoref{sec:extrpwt}).

\section{Extractions}
\label{sec:extrdef}

Extractions are induced by a function $\pi$ that specifies how to decrease the syntactic complexity. Broadly, extractions fall into two classes: extractions that change the ``outer'' form, and those which change the ``inner'' form. Before defining extractions, we describe a way to uniformly express extractions that change the ``outer'' form, such as the destructor extraction exemplified above.

Changing the ``outer'' form of the copattern, i.e., removing or adding destructors, is dual to changing its ``inner'' form, i.e., replacing patterns with other patterns. For the purpose of defining extractions of the latter type, substitutions will be used. For the purpose of defining extractions of the former, we introduce the notion of \textit{co-substitution}.

\begin{definition}[Co-substitution]
A function $\sigma$ from copatterns to copatterns is called a \textit{co-substitution}, if, for every copattern $q$, it is defined as follows:
\[
\sigma(q) = q.\overline{des(\overline{p})},
\]
for some $\overline{des(\overline{p})}$ possibly depending on the $q$.
\end{definition}

Finally, extraction functions can be defined. More precisely, it is defined what it means to be an extraction projection, and for such an extraction projection $\pi$, a $\pi$-extraction targeting a set of equations $T$. For this, we make use of the notion of lenses, as defined by Foster et al.\cite{foster05combinators}.

\begin{definition}[Extraction projection]
\label{def:extrproj}
A function $\pi$ from copatterns to copatterns is called an extraction projection if for every copattern $q$ there exists a (co-)substitution $\sigma^q_\pi$ such that $\sigma^q_\pi(\langle q \rangle^\pi) = q$.
\end{definition}

\begin{definition}[$\pi$-lens]
The $\pi$-lens, for an extraction projection $\pi$, is the lens defined as follows:
\[
\mathtt{get} = \pi
\]
\[
\mathtt{putback}(q^a, q^c) = \sigma^{q^c}_\pi(q^a),
\]
where the $\sigma^{q^c}_\pi$ is the (co)-substitution for $q^c$ and $\pi$ as given in the definition of the extraction projection.
\end{definition}

\begin{definition}[$\pi$-extraction target]
A $\pi$-extraction target $T$ is a set of equations such that $\pi(q) = \pi(q')$ for any two lhss $q, q'$ of equations in $T$.
\end{definition}

\begin{definition}[$\pi$-extraction targeting $T$]
Let $aux$ be a fresh function name \footnote{In practice this means that is in undeclared in the program that is transformed by the extraction lifted to programs (see next section).} Let the pair of \textsf{get} and \textsf{putback} be the $\pi$-lens. For any copattern $q$, let $\langle q \rangle^{vars}$ denote the list of all variables of $q$ in the order that they appear in in $q$. Let $\langle \cdot \rangle^{aux}$ be the call to the auxiliary function that corresponds to the given copattern, defined as follows for copatterns $q$: $\langle q \rangle^{aux} = aux(\langle q \rangle^{vars})$. A \textit{$\pi$-extraction targeting an extraction target $T$} is a triple consisting of
\begin{itemize}
\item an equation $\epsilon$ with lhs $q_\epsilon = \textsf{get}(q)$ and rhs $t_\epsilon = \langle q_\epsilon \rangle^{aux}$, for some lhs $q$ of an equation in $T$,
\item a function $\zeta$ with domain $T$, defined as follows: $\zeta_r := ``\textsf{putback}(t_\epsilon, q_r) = t_r  "$, and
\item the following signature for the auxiliary function $aux$ (its equations are the image of $\zeta$): $`` \textrm{\textbf{function }} aux(\tau_1, ..., \tau_n): \sigma "$, with $\tau_1, ..., \tau_n$ the types inferred, using the signatures of $prg$, for the variables in $q_\epsilon$, in the order that they appear in in $q_\epsilon$, and $\sigma$ the type inferred, also using the signatures of $prg$, for $q_\epsilon$.
\end{itemize}
\end{definition}

\subsection{Applying extractions to programs}

An extraction function was defined as a triple. As it will be used to transform programs into programs, however, it is necessary to define how it should be applied to programs. The definition of the apply function is straightforward; all it does is replace each targeted lhs in the program with $\epsilon$, leaving all other lhss unchanged, and collecting the $\zeta_r$ for each targeted equation $r$ in an auxiliary function definition.

Let $e = (\epsilon, \zeta, sig)$ be an extraction targeting $T$, with
\[
def_T = `` \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} eqns "
\]
the function definition that contains the lhss of $T$.

\begin{alignat*}{4}
\langle prg \rangle^{apply(e)} & = &&\{ && \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} \{ r ~ | ~ r \in eqns, r \not\in T \} \cup \{ \epsilon \}, \\
& && && \textrm{\textbf{function }} sig \textrm{\textbf{ where }} \{ \zeta_r ~ | ~ r \in T \} \} \\
& \cup && \{ def \in prg ~ | ~ def \neq def_T \} \span\span\span\span
\end{alignat*}

\section{Prime extractions}
\label{sec:extrex}

In this section, we give some example extractions, destructor extraction and those from the family of constructor extractions. They are \textit{prime} extractions, in the sense that all other extractions' extraction projections are compositions of the underlying projections of destructor and constructor extractions.

\subsection{Destructor extraction}
\label{sec:desextr}

The extraction \textsf{ExtractDes} of a single destructor can be defined as follows: It is the $\pi$-extraction (targeting some $T$) for the extraction projection $\pi$ defined below.

\[
\pi(`` fun(\overline{p}) ") = `` fun(\overline{p}) "
\]
\[
\pi(`` q.des(\overline{p}) ") = `` q "
\]

Since copatterns without destructors aren't affected, this extraction is only meant to be used for copatterns with at least one destructor. We now show that $\pi$ is indeed an extraction projection, by giving a cosubstitution $\sigma^q_\pi$ for each $q$ such that $\sigma^q_\pi(\pi(q)) = q$.
\[
\sigma^{q^c}_\pi(q^a) = \begin{cases}
                              q^a.des(\overline{p}) &,\text{ if } q^c = q'.des(\overline{p}) \\
                              q^a &,\text{ otherwise}
                              \end{cases}
\]
With $\texttt{get} = \pi$ and $\texttt{putback}(q^a, q^c) = \sigma^{q^c}_\pi(q^a)$ we have the $\pi$-lens. We would like to illustrate with a little Haskell implementation how straightforward the two parts of the lens fit together.

\begin{lstlisting}

desExtrGet :: Cop -> Cop
desExtrGet (Des _ cop _) = cop

desExtrPutback :: Cop -> Cop -> Cop
desExtrPutback cop (Des des _ args) = Des des cop args

\end{lstlisting}

All extraction projections that are the counterparts to cosubstitutions can be defined as a composition of the destructor extraction projection: Simply extract the destructors one after the other.

As an example for destructor extraction, consider the function definition for \texttt{oneElemArray} from the program of \autoref{fig:ch2uroex}.
\begin{lstlisting}
function oneElemArray(Nat): Array where
  oneElemArray(n).get(Zero()) = n
  oneElemArray(n).get(Succ(m)) = Zero()
\end{lstlisting}
Targeting both equations for extraction of destructor \texttt{get} leads to the changed function definition for \texttt{oneElemArray} and an auxiliary function definition.
\begin{lstlisting}
function oneElemArray(Nat): Array where
  oneElemArray(n) = aux(n)

function aux(Nat): Array
  aux(n).get(Zero()) = n
  aux(n).get(Succ(m)) = Zero()
\end{lstlisting}
Note that this transformation didn't decrease the overall syntactic complexity of the program, since the complexity of \texttt{oneElemArray}, where the lhss contained one constructor and one destructor each, is simply transferred over to \texttt{aux}. One way to actually decrease the syntactic complexity of this example is the extraction of the constructor calls \texttt{Zero()} and \texttt{Succ(m)}; constructor extraction is defined in the next section.

\subsection{Constructor extraction}
\label{ssec:conextr}

We define a family $\textsf{ExtractCon}(\ell)$ of extractions of single constructors. The parameter $\ell$ stands for the position of the constructor call to be extracted in the targeted copatterns. We assume that $\ell$ actually points to a constructor call with only variables as arguments. For such a position $\ell$, $\textsf{ExtractCon}(\ell)$ is defined as the $\pi_\ell$-extraction (targeting some $T$) for the extraction projection $\pi_\ell$ defined below.

We assume that, in all copatterns, any variable is named according to its position. This can be  achieved by renaming variables according to a naming schema. For instance, the variables $fun(m, n)$ might be renamed such that the resulting term is $fun(x0, x1)$, where the position of each variable can be identified by its name. This approach is easily extended to destructor copatterns; for constructor calls, the schema needs to be applied recursively. Write $\textsf{name}(\ell)$ for the name given to a variable at position $\ell$ under such a naming schema. Using this, we define $\pi_\ell$ for any copattern $q$ which satisfies our assumptions that (a) $\ell$ points to a constructor call with only variables as arguments and (b) $q$ is named according to the schema used in \textsf{name}.
\[
\pi_\ell(q) := q[con(\overline{x}) \mapsto \textsf{name}(\ell)]_\ell
\]
The bracket notation means that the replacement occurs at position $\ell$.

We now show why $\pi_\ell$ is an extraction projection, that is, we give, for each $q$, a substitution $\sigma^q_{\pi_\ell}$ such that $\sigma^q_{\pi_\ell}(\pi_\ell(q)) = q$: Set $\sigma^q_{\pi_\ell} := \{\textsf{name}(\ell) \mapsto con(\overline{x})\}$.

All extraction projections that are the counterparts to substitutions can be defined as a composition of constructor extraction projections: Simply extract the constructors one after the other, from innermost to outermost.

As an example for constructor extraction, consider again the function definition for \texttt{oneElemArray} from the program of \autoref{fig:ch2uroex}.
\begin{lstlisting}
function oneElemArray(Nat): Array where
  oneElemArray(n).get(Zero()) = n
  oneElemArray(n).get(Succ(m)) = Zero()
\end{lstlisting}
Targeting both equations for extraction of the constructor calls at the argument position of \texttt{get} leads to the changed function definition for \texttt{oneElemArray} and an auxiliary function definition.
\begin{lstlisting}
function oneElemArray(Nat): Array where
  oneElemArray(n).get(m) = aux(n, m)

function aux(Nat, Nat): Array
  aux(n, Zero()) = n
  aux(n, Succ(m)) = Zero()
\end{lstlisting}
Note than in this example, other than destructor extraction, this transformation actually decreased the overall syntactic complexity of the program. The original definition for \texttt{oneElemArray} contained lhss with both destructor and constructor calls; the new definition has one lhs with one destructor, but no constructor call, and the auxiliary definition has two lhss which both have one constructor, but no destructor. Of course, the opposite case also exists, i.e., there are programs which cannot be syntactically simplified by constructor extraction, but by destructor extraction.

\section{Bisimulation}
\label{sec:extrbis}

Every extraction preserves the semantics of programs in a kind of weak bisimulation, assuming that neither the original nor the transformed program have overlapping equations. There are two equivalent characterizations of this bisimulation. One is given and proved in the first subsection, the other follows in the second subsection and is shown to be equivalent to the first. For this section, we will always assume that neither the original nor the transformed program have overlapping equations.

Before we start, we define a function $\langle \cdot \rangle^{aux^{-1}}$ from terms to terms that serves as the opposite of $\langle \cdot \rangle^{aux}$. It is defined as replacing calls to the auxiliary function as generated by $\langle \cdot \rangle^{aux}$ with the original copatterns with their variables instantiated accordingly. This corresponds to what Setzer et al.\cite{setzer14unnesting} call a \textit{back-interpretation}; we will use this term here as well when referring to $\langle \cdot \rangle^{aux^{-1}}$.

\subsection{Using a modified value judgement}

For the definition of this weak bisimulation, we modify the value judgement, using the back-interpretation, in the following way. For any term $t$ with names declared in $\langle prg \rangle$, let
\[
\langle prg \rangle \vdash'_v t :\iff prg \vdash_v \langle t \rangle^{aux^{-1}}.
\]

From this definition it immediately follows that $\mathcal{E}$ is an evaluation context with respect to this modified value judgement for $\langle prg \rangle$ if and only if $\langle \mathcal{E} \rangle^{aux^{-1}}$ is an evaluation context with respect to the original value judgement for $prg$. It also means that, for a term $t$ with all names declared in $\langle prg \rangle$, the immediate subterms of $t$ are values with this judgement for $\langle prg \rangle$ if and only if the immediate subterms of $\langle t \rangle^{aux^{-1}}$ are values with the original judgement for $prg$.

Write $\longrightarrow'$ for the reduction relation $\longrightarrow$ with its value judgement modified in this way. This modified reduction relation can (but doesn't need to) ``sidestep'' reductions which don't change the back-interpretation of a term; as an example, consider a program with a function $fun$, where the extraction creates an auxiliary function $aux$ with an equation $\epsilon = ``fun() = aux()"$: Assume the term $fun().des()$ reduces in one step to some term $t$ with $\longrightarrow_{prg}$. It cannot do so with $\longrightarrow_{\langle prg \rangle}$ because it first has to reduce to $aux().des()$ by the $\epsilon$ equation. But since $\longrightarrow'_{\langle prg \rangle}$ considers $aux()$ a value because $\langle aux() \rangle^{-1} = fun()$ is a value in $prg$, this reduction can ``ignore'' $\epsilon$ and directly go to $t$.

The weak bisimulation is defined as follows, for every $s,t$ with all of their names declared in $prg$:
\begin{equation}
\label{eq:bisim1}
s \longrightarrow_{prg}^* t \iff s {\longrightarrow'}_{\langle prg \rangle}^* t
\end{equation}
In other words, $\longrightarrow'_{\langle prg \rangle}$ is a conservative extension of $\longrightarrow_{prg}$. This statement is now proved using Theorem 4a of Setzer et al.\cite{setzer14unnesting} Their theorem makes use of a set \textsf{Good} which limits the terms of $\langle prg \rangle$ for which there is a back-interpretation, but which is only relevant in a context with first-class functions. We therefore present Theorem 4a in a simplified form -- a special case -- which omits any mention of \textsf{Good}, because in our case \textsf{Good} is simply the entire set of terms of $\langle prg \rangle$.

\begin{theorem}[Setzer et al.]
\label{thm:setzer4a}
Let $(\mathcal{A}, \longrightarrow), (\mathcal{A}', \longrightarrow')$ be abstract reduction systems, i.e., it is $\longrightarrow \subseteq \mathcal{A} \times \mathcal{A}$ and $\longrightarrow' \subseteq \mathcal{A}' \times \mathcal{A}'$, such that $\mathcal{A} \subseteq \mathcal{A}'$. Let \textsf{int} be a back-interpretation from $\mathcal{A}'$ into $\mathcal{A}$, $\textsf{m} : \mathcal{A}' \to \mathbb{N}$. We define the following conditions for the back-interpretation:\\
(SN 1) $\forall a, a' \in \mathcal{A}. a \longrightarrow a' \implies a {\longrightarrow'}^{\geq 1} a'$\\
(SN 2) If $a \in \mathcal{A}, a' \in \mathcal{A}'$ and $a \longrightarrow' a'$ then $\textsf{int}(a) {\longrightarrow}^{\geq 1} \textsf{int}(a')$ or $\textsf{int}(a) = \textsf{int}(a') ~ \land ~ \textsf{m}(a) > \textsf{m}(a')$.

(SN 1), (SN 2) imply that $(\mathcal{A}', \longrightarrow')$ is a conservative extension of $(\mathcal{A}, \longrightarrow)$, i.e. it is $a \longrightarrow^* a' \iff a {\longrightarrow'}^* a'$ for all $a, a' \in \mathcal{A}$, preserving strong normalisation.
\end{theorem}

\begin{proposition}
\label{prop:bisim1}
The weak bisimulation statement~\ref{eq:bisim1} holds for any transformation defined as $apply(e)$ for some $\pi$-extraction $e$ targeting a $T$.

\begin{proof}
By \autoref{thm:setzer4a}, it suffices to show the statements (SN1) and (SN2). For this, set $\textsf{int} = \langle \cdot \rangle^{aux^{-1}}$. Note that this unconversion is compatible with evaluation contexts, i.e.,
\[
\langle \mathcal{E}[s'] \rangle^{aux^{-1}} = \langle \mathcal{E} \rangle^{aux^{-1}}[\langle s' \rangle^{aux^{-1}}],
\]
because $\langle \cdot \rangle^{aux}$ converts to function calls, not destructor calls. Analogously, $\langle \cdot \rangle^{aux^{-1}}$ is compatible with substitutions, i.e.,
\[
\langle q[\sigma] \rangle^{aux^{-1}} = \langle q \rangle^{aux^{-1}}[\langle \sigma \rangle^{aux^{-1}}],
\]
where $\langle \cdot \rangle^{aux^{-1}}$ has been straightforwardly lifted to substitutions by applying it to each right-hand side individually.
Further, set \textsf{m} as the number of calls to the function targeted in the transformation, i.e., that of $q_\epsilon$.

(SN 1): We know that $s = \mathcal{E}[q_r[\sigma]] \longrightarrow_{prg} \mathcal{E}[t_r[\sigma]] = t$, for some evaluation context $\mathcal{E}$ of $prg$ and some equation $r$ of $prg$. When $r \not\in T$, i.e., $r$ is taken over unchanged to $\langle prg \rangle$, the reduction $\mathcal{E}[q_r[\sigma]] {\longrightarrow'}_{\langle prg \rangle} \mathcal{E}[t_r[\sigma]]$ can be derived identically to $\mathcal{E}[q_r[\sigma]] \longrightarrow_{prg} \mathcal{E}[t_r[\sigma]]$. When $r \in T$, it is $q_r = \sigma^{q_r}_\pi(q_\epsilon)$ and $t_r = t_{\zeta_r}$, and we distinguish between whether $\sigma^{q_r}_\pi$ is a substitution or a co-substitution.

When $\sigma^{q_r}_\pi$ is a substitution, it is $\sigma^{q_r}_\pi(q_\epsilon)[\sigma] = q_\epsilon[\sigma \circ \sigma^{q_r}_\pi]$, and we can derive:
\begin{flalign*}
&s = \mathcal{E}[q_r[\sigma]] = \mathcal{E}[q_\epsilon[\sigma \circ \sigma^{q_r}_\pi]] \\
\longrightarrow'_{\langle prg \rangle} ~ &\mathcal{E}[t_\epsilon[\sigma \circ \sigma^{q_r}_\pi]] = \mathcal{E}[q_{\zeta_r}[\sigma]] \\
\longrightarrow'_{\langle prg \rangle} ~ &\mathcal{E}[t_{\zeta_r}[\sigma]] = \mathcal{E}[t_r[\sigma]] = t
\end{flalign*}

When $\sigma^{q_r}_\pi$ is a co-substitution, it is $\sigma^{q_r}_\pi(q_\epsilon) = q_\epsilon.\overline{des(\overline{p})}$, and thus $\mathcal{E}[q_\epsilon.\overline{des(\overline{p})}[\sigma]] = \mathcal{E}[[].\overline{des(\overline{p})}[\sigma]][q_\epsilon[\sigma]]$. Since $\mathcal{E}_{des} := \mathcal{E}[[].\overline{des(\overline{p})}[\sigma]]$ is $\mathcal{E}$ with the hole ``shrunken'' from the right, it is an evaluation context for the same value judgements as $\mathcal{E}$, and thus we can derive:
\begin{flalign*}
&s = \mathcal{E}[q_r[\sigma]] = \mathcal{E}_{des}[q_\epsilon[\sigma]] \\
\longrightarrow'_{\langle prg \rangle} ~ &\mathcal{E}_{des}[t_\epsilon[\sigma]] = \mathcal{E}[q_{\zeta_r}[\sigma]] \\
\longrightarrow'_{\langle prg \rangle} ~ &\mathcal{E}[t_{\zeta_r}[\sigma]] = \mathcal{E}[t_r[\sigma]] = t
\end{flalign*}

(SN 2): Three cases will be distinguished: The reduction in $\langle prg \rangle$ can use either an equation taken over unchanged from $prg$ (1.), it can use a $\zeta_r$ (2.), or it can use $\epsilon$ (3.). Each case makes use of an evaluation context $\mathcal{E}$ of the reduction relation for $\langle prg \rangle$.
\begin{enumerate}
\item We know $s = \mathcal{E}[s'] = \mathcal{E}[q_r[\sigma]] \longrightarrow'_{\langle prg \rangle} \mathcal{E}[t_r[\sigma]] = t$. The desired reduction sequence can be given as follows:
\begin{flalign*}
&\langle \mathcal{E}[s'] \rangle^{aux^{-1}} \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle s' \rangle^{aux^{-1}}] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle q_r \rangle^{aux^{-1}}[\langle \sigma \rangle^{aux^{-1}}]] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[q_r[\langle \sigma \rangle^{aux^{-1}}]] \\
 \longrightarrow_{prg}~& \langle \mathcal{E} \rangle^{aux^{-1}}[t_r[\langle \sigma \rangle^{aux^{-1}}]] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle t_r \rangle^{aux^{-1}}[\langle \sigma \rangle^{aux^{-1}}]] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle t_r[\sigma] \rangle^{aux^{-1}}] \\
=~& \langle \mathcal{E}[t_r[\sigma]] \rangle^{aux^{-1}} \\
=~& \langle t \rangle^{aux^{-1}}.
\end{flalign*}

\item We know $s = \mathcal{E}[s'] = \mathcal{E}[q_{\zeta_r}[\sigma]] \longrightarrow'_{\langle prg \rangle} \mathcal{E}[t_{\zeta_r}[\sigma]] = t$. The desired reduction sequence can be given as follows:
\begin{flalign*}
&\langle \mathcal{E}[s'] \rangle^{aux^{-1}} \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle s' \rangle^{aux^{-1}}] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle q_{\zeta_r} \rangle^{aux^{-1}}[\langle \sigma \rangle^{aux^{-1}}]] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[q_r[\langle \sigma \rangle^{aux^{-1}}]] \\
\longrightarrow_{prg}~& \langle \mathcal{E} \rangle^{aux^{-1}}[t_r[\langle \sigma \rangle^{aux^{-1}}]] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle t_r \rangle^{aux^{-1}}[\langle \sigma \rangle^{aux^{-1}}]] \\
=~& \langle \mathcal{E} \rangle^{aux^{-1}}[\langle t_r[\sigma] \rangle^{aux^{-1}}] \\
=~& \langle \mathcal{E}[t_r[\sigma]] \rangle^{aux^{-1}} \\
=~& \langle \mathcal{E}[t_{\zeta_r}[\sigma]] \rangle^{aux^{-1}} = \langle t \rangle^{aux^{-1}}.
\end{flalign*}

\item We know $s = \mathcal{E}[s'] = \mathcal{E}[q_\epsilon[\sigma]] \longrightarrow'_{\langle prg \rangle} \mathcal{E}[t_\epsilon[\sigma]] = t$. In this case, instead of giving a reduction sequence, the other side of the disjunction will be shown to hold.

Because $\langle q_\epsilon \rangle^{aux^{-1}} = \langle t_\epsilon \rangle^{aux^{-1}}$, it is $\langle s \rangle^{aux^{-1}} = \langle t \rangle^{aux^{-1}}$.

And because $q_\epsilon$ is of the function that is targeted in the transformation, and $t_\epsilon$ isn't, it is $\textsf{m}(q_\epsilon) > \textsf{m}(t_\epsilon)$, and consequently $\textsf{m}(s) > \textsf{m}(t)$. \qedhere
\end{enumerate}
\end{proof}
\end{proposition}

\subsection{Using the back-interpretation directly}

This characterization of the bisimulation, which is equivalent to the first, directly uses the back-interpretation. In short, extractions preserve semantic properties by introducing an equation which leads from a, syntactically, more complex to a less complex term, where both terms are meant to represent, semantically, the same ``object''. This ``sameness'' is expressed by one being the back-interpretation of the other.

The bisimulation is characterized as follows:
\[
s {\longrightarrow}_{prg}^* t \iff s \longrightarrow^*_{\langle prg \rangle} \widetilde{t}, \text{ with } \langle \widetilde{t} \rangle^{aux^{-1}} = t
\]
In order to prove it, it suffices to show that this characterization is equivalent to the first characterization:
\begin{equation}
s {\longrightarrow'}_{\langle prg \rangle}^* t \iff s \longrightarrow^*_{\langle prg \rangle} \widetilde{t},
\end{equation}
for every $s, t$ with names declared in $prg$.

First, we show that the $`` \Rightarrow "$ direction of (2.2), as expressed in the following lemma, holds. In the following, all reductions are meant with respect to program $\langle prg \rangle$.

\begin{lemma}[$`` \Rightarrow "$ direction of (2.2)]
\label{lem:prop2lr}
\[
s {\longrightarrow'}_{\langle prg \rangle}^* t \implies s \longrightarrow^*_{\langle prg \rangle} \widetilde{t}
\]
\end{lemma}

In order to prove this, we define a counterpart to the $\longrightarrow'$ reduction relation: Let
\[
\longrightarrow^{aux} = \{(a,b) : a \longrightarrow^{all} b ~ \land ~ \langle a \rangle^{aux^{-1}} = \langle b \rangle^{aux^{-1}}\},
\]
where $\longrightarrow^{all}$ is the reduction relation for $\langle prg \rangle$ whose underlying value set is the set of all terms, i.e., the reduction is allowed to choose any redex. Where $\longrightarrow'$ can ``sidestep'' reductions which don't change the back-interpretation of a term, $\longrightarrow^{aux}$ is purely ``interpretative'', that is, it only allows reductions to terms with equal back-interpretation. This is expressed formally in the following lemmas relating $\longrightarrow'$ and $\longrightarrow^{aux}$, one concerning their commutation, the other what we call their complementarity. The $`` \Rightarrow "$ direction of (2.2) follows from these, as shown below.

\begin{figure}
\begin{subfigure}{0.3\textwidth}
\begin{tikzpicture}
\path (0,0) node(a) {} 
      (3,0) node(b) {}
      (0,-3) node(c) {}
      (3,-3) node(d) {};
\draw[->] (a) -- (b);
\draw[->,color=blue] (a) -- (c);
\draw[->,dashed,color=blue] (b) -- (d) node [midway, above, sloped] () {$*$};
\draw[->,dashed] (c) -- (d) node [midway, above, sloped] () {$=$};
\end{tikzpicture}
\caption{For \autoref{lem:cdpaux}}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
\begin{tikzpicture}
\path (0,0) node(a) {}
      (3,1) node (a') {}
      (3,0) node(b) {}
      (0,-3) node(c) {}
      (3,-3) node(d) {};
\draw[->,dashed] (a) -- (a') node [midway, above, sloped] () {$=$};
\draw[->,dashed,color=blue] (a') -- (b) node [midway, above, sloped] () {$*$};
\draw[->,dashed,color=blue] (a) -- (c) node [midway, above, sloped] () {$*$};
\draw[->,color=blue] (b) -- (d);
\draw[->] (c) -- (d);
\end{tikzpicture}
\caption{For \autoref{lem:comminv}}
\label{fig:comminv}
\end{subfigure}
\caption{The commutations of \autoref{lem:cdpaux} and \autoref{lem:comminv}: blue arrows represent $\longrightarrow^{aux}$, black arrows $\longrightarrow'$}
\end{figure}

\begin{restatable}[Commutation]{lemma}{cdpaux}
\label{lem:cdpaux}

For all terms $a,b,c$ it holds that:
\[
a {\longrightarrow'} b ~ \land ~ a \longrightarrow^{aux} c \implies \exists d . b {\longrightarrow^{aux}}^* d ~ \land ~ c {\longrightarrow'}^= d
\]

\end{restatable}
\begin{proof}
Left for the appendix.
\end{proof}

\begin{corollary}
\label{cor:cdpauxcor}

For all terms $a,b,c$ and $n \in \mathbb{N}$ it holds that:
\[
a {\longrightarrow'}^n b ~ \land ~ a {\longrightarrow^{aux}}^* c \implies \exists d . b {\longrightarrow^{aux}}^* d ~ \land ~ c {\longrightarrow'}^{\leq n} d
\]

\begin{proof}

By induction on $n$ and on the length of $a {\longrightarrow^{aux}}^* c$.

\end{proof}

\end{corollary}

\begin{restatable}[Complementarity]{lemma}{compl}
\label{lem:compl}

For all terms $a,b$ it holds that:

When $a \longrightarrow' b$ but $a \not\longrightarrow b$, then there is a $c$ with $a \longrightarrow c$ and $a \longrightarrow^{aux} c$.

\end{restatable}

\begin{proof}
Left for the appendix.
\end{proof}

\begin{proof}[Proof of \autoref{lem:prop2lr}]

By induction on the length $n$ of $s {\longrightarrow'}_{\langle prg \rangle}^* t$. For $n = 0$ it is $s = t$, thus simply choose $\widetilde{t} = t$. Now, consider the case that $n = n'+1$ for some $n' \geq 0$. We proceed by induction on the number $k$ of calls in $s$ to the function targeted in the transformation, i.e., that of $q_\epsilon$.

\begin{itemize}
\item $k = 0$. Consider the first step $s {\longrightarrow'}_{\langle prg \rangle} s_1$ of $s {\longrightarrow'}_{\langle prg \rangle}^* t$. Because there are no calls to the function of $q_\epsilon$ in $s$, for all subterms $s^0$ of $s$ it is $\vdash'_v s^0$ iff $\vdash_v s^0$. Consequently, the reduction step from $s$ to $s_1$ is also possible with reduction relation $\longrightarrow_{\langle prg \rangle}$, that is, $s \longrightarrow_{\langle prg \rangle} s_1$. By the outer induction hypothesis, we have the rest of the desired reduction sequence $s_1 \longrightarrow_{\langle prg \rangle} \widetilde{t}$.

\item $k = k' + 1$. Again, consider the first step $s {\longrightarrow'}_{\langle prg \rangle} s_1$ of the original sequence. We distinguish two cases.
\begin{enumerate}
\item $s \longrightarrow_{\langle prg \rangle} s_1$. With this, we have the first step of the desired reduction sequence. By the outer induction hypothesis, we have the rest of the desired reduction sequence $s_1 \longrightarrow_{\langle prg \rangle} \widetilde{t}$.

\item $s \not\longrightarrow_{\langle prg \rangle} s_1$. By \autoref{lem:compl}, we have an $s_{aux}$ with $s \longrightarrow^{aux} s_{aux}$ and $s \longrightarrow_{\langle prg \rangle} s_{aux}$. By \autoref{cor:cdpauxcor}, we have a $\widetilde{t}'$ with (a) $s_{aux} \longrightarrow^{\leq n} \widetilde{t}'$ and (b) $t {\longrightarrow^{aux}}^* \widetilde{t}'$ and thus $\langle \widetilde{t}' \rangle^{aux^{-1}} = t$. Apply the inner induction hypothesis to $s_{aux} \longrightarrow^{\leq n} \widetilde{t}'$ to obtain the desired sequence.
\end{enumerate}
\end{itemize}

\end{proof}

%%-- under construction
Now, we show the $`` \Leftarrow ''$ direction of (3.2).

\begin{lemma}[$`` \Leftarrow "$ direction of (3.2)]
\label{lem:prop2rl}
\[
s \longrightarrow^*_{\langle prg \rangle} \widetilde{t} \implies s {\longrightarrow'}_{\langle prg \rangle}^* t
\]
\end{lemma}

Again, we begin by showing a commutation lemma; but this time, we operate on the inverse relations of $\longrightarrow'$ and $\longrightarrow^{aux}$. The commutation of the inverses is different and non-standard, since it has an intermediate sequence of $\longrightarrow^{aux}$-steps, as shown in \autoref{fig:comminv}.

\begin{restatable}[Commutation (inverses)]{lemma}{comminv}
\label{lem:comminv}

For all terms $b,c,d$ it holds that:
\[
c {\longrightarrow'} d ~ \land ~ b \longrightarrow^{aux} d \implies \exists a, a' . a {\longrightarrow^{aux}}^* c ~ \land ~ a {\longrightarrow'}^= a' {\longrightarrow^{aux}}^*  b
\]

\end{restatable}
\begin{proof}
Left for the appendix.
\end{proof}

\begin{corollary}
\label{cor:comminvcor}

For all terms $b,c,d$ it holds that:
\[
c \longrightarrow' d ~ \land ~ b {\longrightarrow^{aux}}^* d \implies \exists a, a' . a {\longrightarrow^{aux}}^* c ~ \land ~ a {\longrightarrow'}^= a' {\longrightarrow^{aux}}^* b
\]

\begin{proof}

By induction on the length of $b {\longrightarrow^{aux}}^* d$.

\end{proof}
\end{corollary}

\begin{proof}[Proof of \autoref{lem:prop2rl}]

First, note that this direction is logically equivalent to the statement
\[
\forall s, t \in \textrm{Term}_{prg}, \widetilde{t} \in \textrm{Term}_{\langle prg \rangle}. (s \longrightarrow^* \widetilde{t} ~ \land ~ \langle \widetilde{t} \rangle^{aux^{-1}} = t) \implies s {\longrightarrow'}^* t.
\]
We prove this statement by induction on the length $n$ of $s \longrightarrow^* \widetilde{t}$. For $n = 0$ it is $s = \widetilde{t}$; since $s \in \textrm{Term}_{prg}$ it is $\langle s \rangle^{aux^{-1}} = s$ and it follows that $s = \langle \widetilde{t} \rangle^{aux^{-1}} = t$. 

Now, consider the case that $n = n'+1$ for some $n' \geq 0$. Since $\longrightarrow \subseteq \longrightarrow'$ it is $s_1 \longrightarrow' \widetilde{t}$; and since $t = \langle \widetilde{t} \rangle^{aux^{-1}}$ it is $t {\longrightarrow^{aux}}^* \widetilde{t}$. Thus, by \autoref{cor:comminvcor} we have terms $t', t''$ with $t' {\longrightarrow'}^= t'' {\longrightarrow^{aux}}^* t$ and $t' {\longrightarrow^{aux}}^* s_1$. Because $t \in \textrm{Term}_{prg}$ it must be $t'' = t$. By the induction hypothesis we have a reduction sequence $s {\longrightarrow'}^* \langle s_1 \rangle^{aux^{-1}}$. Since it is $t' {\longrightarrow'}^= t$, and $t$ contains no calls to $aux$, neither does $t'$. Thus, from $t' {\longrightarrow^{aux}}^* s_1$ it follows that $\langle s_1 \rangle^{aux^{-1}} = t'$. By combining the thus known sequences and equalities, we get the desired sequence $s {\longrightarrow'}^* \langle s_1 \rangle^{aux^{-1}} = t' {\longrightarrow'}^= t$.

\end{proof}

Combining \autoref{lem:prop2lr} and \autoref{lem:prop2rl}, statement (3.2) obtains.
\begin{proposition}
\label{prop:bisim2}
Statement (3.2), that is
\[
s {\longrightarrow'}_{\langle prg \rangle}^* t \iff s \longrightarrow^*_{\langle prg \rangle} \widetilde{t},
\]
for every $s, t$ with names declared in $prg$, holds.
\end{proposition}

\section{Absence of overlaps}
\label{sec:extrovl}

For the bisimulation, we presupposed that the transformed program has no overlapping copatterns. Here, we shown that this is the case whenever $q_\epsilon$ doesn't overlap with any lhs of an equation taken over unchanged from $prg$.

\begin{proposition}
For any well-behaved extraction function lifted to programs, $\langle \cdot \rangle$, it is the case that if $prg$ has no overlapping copatterns and $q_\epsilon$ doesn't overlap with any lhs of an equation taken over unchanged from $prg$, then $\langle prg \rangle$ has no overlapping copatterns, as well.

\begin{proof}
First, the equations of the transformed are classified. There are three kinds of them: Those taken over unchanged over from $prg$ (indicated as $r$ in the table below), those which are an $\epsilon$ in a transformation result ($\epsilon$), and those which are, also in such a transformation result, a $\zeta_r$ ($\zeta$). The table below shows all possible combinations; its fields are filled with the number of the proof that lhss of equations of the respective kinds don't overlap.

\begin{tabular}{ l | c | c | r }  & r & $\epsilon$ & $\zeta$ \\ \hline r & (1) &  &  \\ \hline $\epsilon$ & (2) & (3) &  \\ \hline $\zeta$ & (4) & (5) & (6) \\ \hline \end{tabular}

\textit{ad} (1): Both equations are present in $prg$, thus their lhss don't overlap.

\textit{ad} (2): By assumption.

\textit{ad} (3): By the definition of the $q$-extraction, there is only one $\epsilon$-equation in the transformed program.

\textit{ad} (4): The $\zeta$-equation has a function name not declared in $prg$, unlike the $r$-equation.

\textit{ad} (5): The $\zeta$-equation has a function name not declared in $prg$, unlike the $\epsilon$-equation.

\textit{ad} (6): The lhss of each of the $\zeta$-equations are equivalent to a lhs in $prg$, thus, if they overlapped, so would these lhss in $prg$, contrary to fact.
\end{proof}
\end{proposition}

\section{Preservation of well-typedness}
\label{sec:extrpwt}

In this section, we show that extractions preserve well-typedness, i.e., that when applying an extraction to a well-typed program a well-typed program obtains. Let $prg$ be the original program, and $\langle prg \rangle$ the program after extraction. By definition a program is well-typed when all of its equations $eqn$ are well-typed, i.e., it is $\Sigma \vdash eqn \textrm{ ok}$, where $\Sigma$ are the signatures of the program. Let $\Sigma_{prg}$ be the signatures of $prg$, and $\Sigma_{\langle prg \rangle}$ be the signatures of $\langle prg \rangle$. Since extractions only add one function signature, but leave the other signatures unchanged, it is $\Sigma_{prg} \subseteq \Sigma_{\langle prg \rangle}$. The following thus holds trivially.

\begin{fact}
\label{fac:wtpfac}
All typing judgements still hold when replacing $\Sigma_{prg}$ with $\Sigma_{\langle prg \rangle}$.
\end{fact}

Like in \autoref{sec:extrovl}, we distinguish three kinds of equations in $\langle prg \rangle$: those left unchanged, the $\epsilon$ equation, and the $\zeta_r$ equations. For each of these kinds, we show a lemma stating that all of its equations are well-typed, under the assumption that $prg$  is well-typed (and thus all its equations). Combining these, the preservation of well-typedness follows.

\begin{lemma}
Assuming that $prg$ is well-typed, all equations $eqn$ of $\langle prg \rangle$ taken over unchanged from $prg$ are well-typed.

\begin{proof}
By assumption, we know that $\Sigma_{prg} \vdash eqn \textrm{ ok}$. By \autoref{fac:wtpfac} it follows that $\Sigma_{\langle prg \rangle} \vdash eqn \textrm{ ok}$.
\end{proof}
\end{lemma}

\begin{lemma}
\label{lem:wtpeps}
Assuming that $prg$ is well-typed, the equation $\epsilon$ of $\langle prg \rangle$, as specified in the definition of extractions, is well-typed.

\begin{proof}
We want to show that $\Sigma_{\langle prg \rangle} \vdash `` q_\epsilon = t_\epsilon " \textrm{ ok}$. By the judgement for well-typedness of equations this means that we have to show the following.
%\begin{enumerate}
%\item $q_\epsilon$ is either a function or destructor call, with the respective function or destructor signature present in $\Sigma_{\langle prg \rangle}$; let the return type given in this signature be $\sigma$.
%
%\item For each variable $x$ in $q_\epsilon$ it is $q_\epsilon \vdash_{\Sigma_{\langle prg \rangle}} x : \sigma_x$ for some type $\sigma_x$.
%
%\item It is $\{ x : \sigma_x ~ | ~ x \in V(q_\epsilon) \} \vdash_{\Sigma_{\langle prg \rangle}} t_\epsilon : \sigma$.
%\end{enumerate}
%The first point is easy to see. Since there is at least one left-hand side $q \in T$ (part of the extraction target) of $prg$, that we know is the result of applying a (co-)substitution to $q_\epsilon$, and $prg$ is well-typed, there must be a signature in $\Sigma_{prg}$ which holds the return type $\sigma$ for the destructor or function call that $q_\epsilon$ is. Consequently, since $\Sigma_{prg} \subseteq \Sigma_{\langle prg \rangle}$, we also have the return type $\sigma$ for the destructor or function call $q_\epsilon$ in the signature set $\Sigma_{\langle prg \rangle}$ of $\langle prg \rangle$.
%
%For the second point, again consider an lhs $q \in T$. Because it is possible to infer, using $\Sigma_{prg}$, a type for all variables in $q$, which results from applying a (co-)substitution to $q_\epsilon$, it also is possible to infer a type for all variables in $q_\epsilon$ using $\Sigma_{prg}$, and, by \autoref{fac:wtpfac}, also using $\Sigma_{\langle prg \rangle}$.
%
%The third point follows immediately from the definition of the signature of $aux$, as it is $t_\epsilon = aux(x_1, ..., x_n)$, with the $x_i$ being the variables of $q_\epsilon$, and the argument types of $aux$ are defined to be the types inferred for the variables of $q_\epsilon$, and the return type of $aux$ is defined to be the type $\sigma$ inferred for $q_\epsilon$.

\begin{enumerate}
\item $\Sigma_{\langle prg \rangle} \vdash q_\epsilon : \tau, \Gamma$ for some type $\tau$ and some typing context $\Gamma$, and

\item $\Gamma \vdash_{\Sigma} t_\epsilon : \tau$.
\end{enumerate}
First, consider the first point. There is at least one left-hand side $q \in T$ (part of the extraction target) of $prg$, that we know is the result of applying a (co-)substitution to $q_\epsilon$. Since $prg$ is well-typed, it is $\Sigma_{prg} \vdash q : \tau'; \Gamma'$, and by \autoref{fac:wtpfac} also $\Sigma_{\langle prg \rangle} \vdash q : \tau'; \Gamma'$. We can rebuild this derivation into a derivation for $\Sigma_{\langle prg \rangle} \vdash q_\epsilon : \tau, \Gamma$. When $q_\epsilon$ results from $q$ by a co-substitution, cut off the ``Des'' steps of the derivation until arriving at the statement concerning $q_\epsilon$. When $q_\epsilon$ results from $q$ by a substitution, we rebuild the derivations of the auxiliary judgements used for type inference of variables in patterns. Replace each such derivation for a statement $\tau \vdash_{\Sigma} p : \Gamma$, that concerns a pattern $p$ in $q$ which is replaced by some variable $x$ in $q_\epsilon$, with a derivation for $\tau \vdash_{\Sigma} x : x:\tau$ by the ``Var'' rule. Then adapt the (typing contexts in the) derivation steps following this accordingly.

Now, consider the second point. $t_\epsilon$ was defined as $aux(x_1, ..., x_n)$, with the $x_i$ being exactly the variables of $q_\epsilon$. The signature of $aux$ is defined as $`` aux(\tau_1, ..., \tau_n): \tau "$ with $\tau_i$ being precisely defined to be the types inferred for the $x_i$ in $q_\epsilon$, i.e., those that $\Gamma$ assigns to the $x_i$. Thus we can derive $\Gamma \vdash_{\Sigma} t_\epsilon : \tau$ using the ``Var'' rule for these variables, followed by the ``Fun'' rule for $aux$.
\end{proof}
\end{lemma}

\begin{lemma}
Assuming that $prg$ is well-typed, the equations $\zeta_r$, as specified in the definition of extractions, are well-typed.

\begin{proof}
First, note that by definition $aux$ is the function definition that $\zeta_r$ is a part of. We want to show that $\Sigma \vdash `` q_{\zeta_r} = t_{\zeta_r} " \textrm{ ok}$. By the judgement for well-typedness of equations this means that we have to show the following.
%\begin{enumerate}
%\item $q_{\zeta_r}$ is either a function or destructor call, with the respective function or destructor signature present in $\Sigma_{\langle prg \rangle}$; let the return type given in this signature be $\sigma$.
%
%\item For each variable $x$ in $q_{\zeta_r}$ it is $q_{\zeta_r} \vdash_{\Sigma_{\langle prg \rangle}} x : \sigma_x$ for some type $\sigma_x$.
%
%\item It is $\{ x : \sigma_x ~ | ~ x \in V(q_{\zeta_r}) \} \vdash_{\Sigma_{\langle prg \rangle}} t_{\zeta_r} : \sigma$.
%\end{enumerate}
%For the first point, we distinguish between the possible forms of $q_{\zeta_r}$. It can either be a function call, then we infer its type as the return type $\sigma$ of $aux$, given in the signature for $aux$, which is present in $\Sigma_{\langle prg \rangle}$. Or it can be a destructor call; by definition, $q_{\zeta_r}$ is the result of a (co-)substitution applied to $t_\epsilon$, and since $q_{\zeta_r}$ contains a destructor call and $t_\epsilon$ doesn't, the destructor must be a part of the co-substitution. Since $q_r \in T$ results from $q_\epsilon$ by applying this co-substitution to it, and $prg$ is well-typed, we know that the respective destructor signature is present in $\Sigma_{prg}$, and thus in $\Sigma_{\langle prg \rangle}$.
%
%Concerning the second point, first note that the variables of $q_{\zeta_r}$ are exactly those of $q_r$. The types inferred for the variables in $q_{\zeta_r}$ are identical to the types inferred for them in $q_r$. To see this, combine the facts that the argument types of $aux$ are defined to be the types inferred for the variables of $q_\epsilon$, the return type of $aux$ is defined to be the type inferred for $q_\epsilon$, and that $q_r$ is the result of applying a (co-)substitution to $q_\epsilon$. Thus we know the following. For each variable $x$ of $q_r$ and $q_{\zeta_r}$, let $\sigma_x$ be the type inferred for it in $prg$, i.e., it is $q_r \vdash_{\Sigma_{prg}} x : \sigma_x$. Since the types inferred for the variables in $q_{\zeta_r}$ are identical to the types inferred for them in $q_r$, it also is $q_{\zeta_r} \vdash_{\Sigma_{\langle prg \rangle}} x : \sigma_x$.
%
%For the third point, we use the fact that the types inferred for the variables of $q_{\zeta_r}$ and $q_r$ are identical in $prg$ and $\langle prg \rangle$, as established for the second point. Since $prg$ is well-typed, and thus it is $\Sigma_{prg} \vdash `` q_r = t_r " \textrm{ ok}$, it also is $\{ x : \sigma_x ~ | ~ x \in V(q_r) \} \vdash_{\Sigma_{prg}} t_r$, and by \autoref{fac:wtpfac} it is $\{ x : \sigma_x ~ | ~ x \in V(q_r) \} \vdash_{\Sigma_{\langle prg \rangle}} t_r$.

\begin{enumerate}
\item $\Sigma_{\langle prg \rangle} \vdash q_{\zeta_r} : \tau; \Gamma$ for some type $\tau$ and some typing context $\Gamma$, and

\item $\Gamma \vdash_{\Sigma_{\langle prg \rangle}} t_{\zeta_r} : \tau$.
\end{enumerate}
Since $prg$ is well-typed, by the derivation of the well-typedness for $r$ we know that $\Sigma_{prg} \vdash q_r : \tau'; \Gamma'$ for some type $\tau'$ and some typing context $\Gamma'$ with a type assignment for each variable in $q_r$; the same holds for $\Sigma_{\langle prg \rangle}$ by \autoref{fac:wtpfac}. Now, we consider the two points above in turn: We will show that they hold for $\Gamma = \Gamma'$ and $\tau = \tau'$.

For the first point, we note that it is $q_{\zeta_r} = \textsf{putback}(t_\epsilon, q_r) = \sigma^{q_r}_\pi(t_\epsilon)$, and we distinguish whether $\sigma^{q_r}_\pi$, from now on shortened to $\sigma$, is a substitution or a co-substitution.
\begin{itemize}
\item When $\sigma$ is a substitution, it is $q_{\zeta_r} = aux(\sigma(x_1), ..., \sigma(x_n))$. Since, by definition, $t_\epsilon$ has the same variables as $q_\epsilon$, and it is $\sigma(q_\epsilon) = q_r$, we know that each $\sigma(x_i)$ is a subterm of $q_r$ and that the variables of $q_{\zeta_r}$ are exactly those of $q_r$. From the derivation of $\Sigma_{\langle prg \rangle} \vdash q_r : \tau'; \Gamma'$ we know that it is $\tau_i \vdash_{\Sigma_{\langle prg \rangle}} \sigma(x_i) : \Gamma_i$ for some type $\tau_i$ and some typing context $\Gamma_i$. Each $\tau_i$ is the $i$-th argument type of $aux$ because these argument types were defined to be the types inferred for the variables in $q_\epsilon$ and it is $q_r = \sigma(q_\epsilon)$. Since the variables of $q_{\zeta_r} = \sigma(x_1), ..., \sigma(x_n)$ are exactly those of $q_r$, we know that any variable of $q_r$ is contained in some $\sigma(x_i)$, and thus it must be $\Gamma' = \Gamma_1, ..., \Gamma_n$. The function $aux$ has return type $\tau'$ since its return type is defined to be the return type of whatever function or destructor $q_\epsilon$ is a call to and $q_r = \sigma(q_\epsilon)$ is also a call to this same function or destructor. Apply the ``Fun'' rule for $aux$ on top of the derivations for the $\tau_i \vdash_{\Sigma_{prg}} \sigma(x_i) : \Gamma_i$ to derive $\Sigma_{\langle prg \rangle} \vdash q_{\zeta_r} : \tau'; \Gamma'$.

\item When $\sigma$ is a co-substitution, it is $q_{\zeta_r} = aux(x_1, ..., x_n).\overline{des(\overline{p})}$ and $q_r = q_\epsilon.\overline{des(\overline{p})}$. Derive $\Sigma_{\langle prg \rangle} \vdash q_{\zeta_r} : \tau'; \Gamma'$ as follows. Start with the ``Var'' rules for each $x_i$ to derive $\tau_i \vdash_{\Sigma_{\langle prg \rangle}} x_i : x_i:\tau_i$, where $\tau_i$ is the $i$-th argument type of $aux$; note that the argument types of $aux$ were defined to be the types inferred for the variables in $q_\epsilon$ and are thus identical to the types inferred for these variables by $\Sigma_{\langle prg \rangle} \vdash q_r : \tau'; \Gamma'$ (1). Then use the ``Fun'' rule and follow it up with the ``Des'' rule steps at the end of the derivation of $\Sigma_{\langle prg \rangle} \vdash q_r : \tau'; \Gamma'$. This infers the types for the rest of the variables in $q_r$ (i.e., those not in $\{x_1, ..., x_n\}$) identically to $\Sigma_{\langle prg \rangle} \vdash q_r : \tau'; \Gamma'$ (2). Combining (1) and (2) we know that we have derived $\Sigma_{\langle prg \rangle} \vdash q_{\zeta_r} : \tau'; \Gamma'$.
\end{itemize}

Now, consider the second point. From the derivation of the well-typedness of $r$ we also know that $\Gamma \vdash_{\Sigma_{prg}} t_r : \tau$; by \autoref{fac:wtpfac} it follows that $\Gamma \vdash_{\Sigma_{\langle prg \rangle}} t_r : \tau$. Since $t_{\zeta_r}$ was defined to be $t_r$, we have the desired statement.
\end{proof}
\end{lemma}
