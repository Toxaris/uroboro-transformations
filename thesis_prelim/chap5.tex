% !TEX root = main.tex
\chapter{Related and future work}

In this chapter, we consider related and future work. We begin with several applications for our transformations, as they have been considered by previous authors (\autoref{sec:relappl}). Then we review work that our thesis builds upon: the unnesting algorithm of Setzer et al. (\autoref{sec:relunn}), and the (principal idea for the) language Uroboro (\autoref{sec:reluro}). Finally, we talk about avenues for future research (\autoref{sec:futr}).

\section{Applications}
\label{sec:relappl}

As already hinted at in the introduction, authors like Reynolds and Danvy have shown how de- and refunctionalization, along with other transformations like CPS transformation, can be used to automatically transform programs of a more (human-) understandable form into semantically equivalent programs with certain desirable properties with regards to computation, and the other way around. In this section, we flesh this out somewhat and connect it to our automatic transformations. First, we talk about how our transformations apply to Reynolds' meta-circular interpreter example (\autoref{ssec:mci}). Then we consider some other applications for defunctionalization, as presented by Danvy and Nielsen\cite{danvy01defunctionalization} (\autoref{ssec:defuncex}). Finally, we consider some example applications for refunctionalization as given by Danvy and Millikin\cite{danvy09refunctionalization} (\autoref{ssec:refuncex}).

\subsection{The meta-circular interpreter}
\label{ssec:mci}

Reynolds' classical example is the ``meta-circular'' interpreter for the lambda calculus: Instead of writing an interpreter in a first-order language from scratch, he first straightforwardly translates the intuitive understanding of the semantics of the lambda calculus into a higher-order program, then mechanically defunctionalizes this program. The other direction, refunctionalization into a program that can be better understood than its first-order counterpart, has first been considered by Danvy and Millikin\cite{danvy09refunctionalization}; more details follow in \autoref{ssec:refuncex}.

Rendel et al.\cite{rendel15automatic} have already shown how Uroboro facilitates both the defunctionalization direction and the refunctionalization direction; they have also done so specifically for the meta-circular interpreter example. But their approach still required manual, even though mechanical, work to bring arbitrary Uroboro programs into either the form required by their defunctionalization or their refunctionalization, i.e., into the Codata or Data Fragment, respectively. Our work fully automatizes these pretransformations; all in all, we give an algorithm to defunctionalize any Uroboro program with copattern coverage, and one that refunctionalizes any such program. Our transformations can now be implemented in an IDE such that a programmer can start with an easier to understand higher-order program, like Reynolds\cite{reynolds72definitional} did with the meta-circular interpreter, and then literally ``press a button'' to get the corresponding first-order program. What is more, this higher-order program can use the full expressiveness of Uroboro, not just that of either the Data or Codata Fragment. To illustrate this, we give an Uroboro definition of Reynolds' meta-circular interpreter that we think is as straightforward as one might wish for. By this we mean that anybody with an intuitive understanding of lambda calculus (and the knowledge on how to read functional programs with data and codata types) should be able to comprehend it without thinking deeply about it (one shouldn't need to ``run an interpreter'' in their mind).

TODO: make the example more concise by moving some stuff into an assumed standard library
TODO2: in the Uroboro section, continue this example instead of the one from the introduction

\begin{lstlisting}

data Nat where
  Zero() : Nat
  Succ(Nat) : Nat

data Exp where
  Var(Nat) : Exp
  App(Exp, Exp) : Exp
  Abs(Exp) : Exp

codata Val where
  Val.apply(Val) : Val

codata Env where
  Env.lookup(Nat) : Val

function nil() : Env where
  nil().lookup(x) = error -- may never be called

function cons(Val, Env) : Env where
  cons(val, env).lookup(zero()) = val
  cons(val, env).lookup(succ(n)) = env.lookup(n)

function eval(Exp, Env) : Val where
  eval(Var(n), env) = env.lookup(n)
  eval(App(exp1, exp2), env) = eval(exp1, env).apply(eval(exp2, env))
  eval(Abs(exp), env).apply(val) = eval(exp, cons(val, env))

function interpret(Exp) : Val where
  interpret(exp) = eval(exp, nil())

\end{lstlisting}

Note especially the equation

\begin{lstlisting}
  eval(Abs(exp), env).apply(val) = eval(exp, cons(val, env)),
\end{lstlisting}

which is allowed neither in the Data nor in the Codata Fragment, since it has both a constructor and a destructor in its lhs.

\subsection{Other defunctionalization examples}
\label{ssec:defuncex}

Danvy and Nielsen\cite{danvy01defunctionalizations} explore other applications of defunctionalization, among them defunctionalization of programs processing lists, and of CPS transformed programs. Here, we would just like to pick out a result of their work that concerns a relation between CPS transformations and defunctionalization, which motivates future work on automatic transformations for Uroboro. As Danvy and Nielsen succinctly put it:

\blockcquote[20]{danvy01defunctionalization}{Defunctionalizing a CPS-transformed first-order program provides a systematic way to construct an iterative version of this program that uses a push-down accumulator. One can then freely change the representation of this accumulator.}

In a toolbox for transforming Uroboro programs, one might therefore want to have automatic CPS transformations to compliment the automatic de- and refunctionalization of this work.

\subsection{Refunctionalization examples}
\label{ssec:refuncex}

Danvy and Millikin\cite{danvy09refunctionalization} present two worked-out applications for refunctionalization, a recognizer for Dyck words and Dijktra's shunting yard algorithm; in addition, they point to three more applications for it without giving details. First, we exemplarily consider the recognizer for Dyck words, i.e., well-matched words over the alphabet of two parentheses. We concentrate on how refunctionalization brings the recognizer into a higher-level form that is easier understood by humans, which is a purpose dual to that of defunctionalization. Afterwards, we relate one of the preprocessings used by Danvy and Millikin to our transformations.

The recognizer for Dyck words, as presented by Danvy and Millikin, is an implementation of a tail-recursive push-down automaton. The stack of this push-down automaton, where ``open brace'' symbols increase the stack and ``close brace'' symbols decrease the stack, is not explicitly present anymore after refunctionalization. This is because the language processor of the higher-order language (in Danvy and Millikin's example, ML) deals with this stack in the background. This demonstrates that the purpose of refunctionalization is dual to that of defunctionalization: Refunctionalization turns programs which are closer to the representation used by the machine, e.g., by explicitly using a stack, into a form which abstracts away such low-level concepts. Note also that after the refunctionalization, the recognizer for Dyck words of Danvy and Millikin is in continuation-passing style. To make it even more human-readable, a transformation to direct style can be helpful. One logical next step in the development of the Uroboro toolbox therefore is, along with the addition of CPS transformations, the addition of direct style transformations.

All of the applications have in common that some preprocessing is necessary to bring them into the form required by their actual refunctionalization.\footnote{As already outlined in the introduction, this refunctionalization eliminates the data types for what are intended to be first-class functions and the apply function by replacing these data type definitions with abstractions that take their content from the respective equations of the apply function, and by replacing calls to the apply function with calls to the first-class function.} One of these preprocessings is called ``disentangling'', and it is used to split up a function that dispatches over more than one of its parameters. In our work, the transformation that corresponds to this is constructor extraction. The following \autoref{sec:relunn} goes into more detail how ``disentangling'' is dealt with in our work. At the end of \autoref{sec:relunn} we give some more consideration to what we contribute with the general notion of extractions.

\section{Unnesting}
\label{sec:relunn}

Our de- and refunctionalization is basically just the de- and refunctionalization of Rendel et al.\cite{rendel15automatic} together with a preprocessing. This preprocessing is the ``unnesting'' algorithm of Setzer et al.\cite{setzer14unnesting} for their copattern language, adapted for Uroboro. We first consider general properties of the unnesting algorithm, and then consider its adaptation to Uroboro.

Setzer et al.'s\cite{setzer14unnesting} unnesting operates on the copattern coverage trees of the function definitions. It is the natural counterpart to the interactive construction of a coverage-complete function definition by refinement, as can be done, e.g., in Agda. ``Unnesting'' essentially means undoing the steps of the derivation of the copattern coverage; the algorithm proceeds step-wise and distinguishes a case for each rule the final derivation step could have used. In this way, it can be guaranteed that an unnesting step always leads to a program with copattern coverage and without overlaps.

The drawback of the unnesting algorithm is that it requires a derivation for the copattern coverage. This has to be established in some way; as already mentioned in \autoref{ssec:cc}, we aren't aware of any algorithm for copattern coverage that has better than exponential worst-case time complexity. We have also given some consideration to how to unnest function definitions without knowing the derivation of their copattern coverage. But this always lead us to the problem of how to avoid introducing overlaps; we were only able to avoid these at the cost of exponential worst-case time complexity. Thus, in the end, we decided to adapt the algorithm of Setzer et al.; it is natural in the sense described in the previous paragraph and therefore, in our view, the best algorithm for the task when one presupposes that the derivation of the copattern coverage is known. Our tentative suggestion is that, at least in more cases than is the case today, programmers could construct their programs interactively; this way, the programmer itself would provide the unnesting algorithm with the coverage derivation it needs. As interactive program construction can help avoid simple mistakes, this approach also need not necessarily be to the disadvantage of the programmer.

When we say that we adapted the unnesting algorithm to Uroboro, we mean that we simplified the algorithm from a language with first-class functions to a language without first-class functions. Because Uroboro isn't ``truly'' higher-order, the coverage derivation rules dealing with such higher-order concepts are not needed here, and consequently the corresponding cases of the unnesting algorithm are also unnecessary. Two coverage derivation rules remain to be considered: the result splitting and the variable splitting. For the first, the corresponding ``undo'' transformation is destructor extraction, and for the second it is constructor extraction. Destructor and constructor extraction are special cases of the general concept which we presented as ``extractions'' in chapter 3. With the notion of extraction, we have identified and generalized a concept which was previously known, but had appeared in various places and under various names, e.g. as two of the cases of the unnesting algorithm of Setzer et al.\cite{setzer14unnesting} or as ``disentangling'' in Danvy and Millikin\cite{danvy09refunctionalization}. The form of the definition of extractions we presented is specific to Uroboro, but the underlying idea is not. We believe that consolidating the knowledge of a topic, as opposed to having it pop up in several contexts where it isn't clear that the underlying concept is the same, is useful for its further exploration. Therefore, concerning the topic of what we decided to call extractions, we think that our work contributes at least the impulse towards such a consolidation.

\section{Uroboro}
\label{sec:reluro}

In the introduction, we have already considered the Data Fragment and Codata Fragment of Uroboro and how they relate to re- and defunctionalization, respectively. We also have already talked about why Uroboro is interesting for the purpose of automatic program transformations \autoref{ssec:urofull}. In this section, we examine why Uroboro is interesting beyond that: As already outlined in \autoref{ssec:urofull}, we think that Uroboro is a potential replacement for certain higher-order languages; in the following we illustrate this point.

For instance, consider the \texttt{filterNats} example, repeated from \autoref{ssec:defunc}. We will desugar it to a form which only uses codata type definitions, but no first-class functions.

\begin{lstlisting}

filterNats :: ((Nat -> Bool), [Nat]) -> [Nat]
filterNats (f, x:xs)
  | f x = x:(filterNats (f, xs))
  | otherwise = filterNats (f, xs)
filterNats (_, []) = []

even :: Nat -> Bool
even Zero = True
even Succ(n) = not (even n)

main :: [Nat]
main = filterNats (even, [1, 2, 3, 4, 5])

\end{lstlisting}

We first turn the Haskell-like syntax into a syntax closer to Uroboro.

\begin{lstlisting}

function filterNats((Nat -> Bool), [Nat]): [Nat] where
  filterNats (f, x:xs)
    | f x = x:(filterNats (f, xs))
    | otherwise = filterNats (f, xs)
  filterNats (_, []) = []

function even(): Nat -> Bool where
  even Zero = True
  even Succ(n) = not (even n)

function main(): [Nat]
  main = filterNats (even, [1, 2, 3, 4, 5])

\end{lstlisting}

Then, we do the following:
\begin{itemize}
\item Add a codata type definition \texttt{NatBoolFun} with one destructor \texttt{apply}.

\item Replace function type \texttt{Nat -> Bool} with codata type \texttt{NatBoolFun}.

\item Desugar the calls to a function of type \texttt{NatBoolFun} to calls to destructor \texttt{apply}.
\end{itemize}
The result of this is shown below.

\begin{lstlisting}

codata NatBoolFun where
  NatBoolFun.apply(Nat): Bool

function filterNats(NatBoolFun, [Nat]): [Nat] where
  filterNats (f, x:xs)
    | f.apply(x) = x:(filterNats (f, xs))
    | otherwise = filterNats (f, xs)
  filterNats (_, []) = []

function even(): NatBoolFun where
  even.apply(Zero) = True
  even.apply(Succ(n)) = not (even.apply(n))

function main(): [Nat]
  main = filterNats (even(), [1, 2, 3, 4, 5])

\end{lstlisting}

For this simple example, it is no problem that we need to introduce the codata type \texttt{NatBoolFun}. However, since we don't have parametric polymorphism, we would have to introduce a codata type for \textit{every} concrete function type. The lack of parametric polymorphism therefore is a rather severe limitation. Rendel et al. are currently working on bringing parametric polymorphism to Uroboro.

\section{Future research}
\label{sec:futr}

Finally, we consider possible future research avenues. Uroboro is intended to not just be yet another language, but rather a programme with the goal of bringing useful automatic refactorings to higher-order programs. This programme has both theoretical and practical aspects to it. For both, we give some ideas where future research, starting from our work, could lead to.

On the practical side, our transformations can be implemented in an IDE. In such an implementation, on the one hand, the user might be able to interactively carry out individual extraction refactorings. Speaking in the terminology we developed in chapter 3, the user can select a target set of equations, then, just like in other IDEs, he can be informed whether the extraction can be carried out without problems. Such problems can be the introduction of overlaps, or that the selected equations aren't actually a target set in the sense of chapter 3.

On the other hand, the user might also request to de- or refunctionalize the program or some of its function definitions. In this case, as described in chapter 4, the extractions necessary for preprocessing are automatically chosen by the IDE. It might also be useful to display to the user whether the program is in a certain desired fragment of Uroboro, like the defunctionalized or refunctionalized fragment, or whether it is coverage complete.\footnote{As suggested in \autoref{sec:relunn}, instead of this one might want to provide interactive program construction (as a feature of the IDE).}

On the theoretical side, it might be desirable to automatize further already known transformations, to add to the toolbox of Uroboro transformations we started with this work. Examples of such transformations are CPS transformation and its converse, direct style transformation, as motivated in \autoref{ssec:defuncex} and \autoref{ssec:refuncex}, respectively.

We also have shone a light on the asymmetry between constructors and destructors in Uroboro in \autoref{sssec:asym}. The underlying problem directly relates to the difference between natural deduction and arbitrary sequent calculus, and it is not exclusive to Uroboro, but rather affects all current languages with copattern matching. Thus it might be beyond the principal scope of the Uroboro programme, at least in the short term, but nonetheless an interesting research problem. In the area of object-oriented programming there already exists quite some work on the somewhat analogous topic of \textit{multimethods}. ...