\chapter{Automatic de- and refunctionalization}

%%-- under construction

...

We present an algorithm that defunctionalizes arbitrary Uroboro programs with copattern coverage, and an algorithm that refunctionalizes such programs. Both algorithms are made up of two phases, in order:
\begin{enumerate}
\item Unnesting, and
\item core de-/refunctionalization.
\end{enumerate}

In short, the entire process can be described as follows. By unnesting them as far as necessary, the preprocessing phases brings the lhss of the program to the form accepted by the core de-/refunctionalization, which is essentially the two-way transformation of Rendel et al.

The unnesting is done by a parameterized algorithm $\textsf{Unnest}_i$, where the parameter $i$ can be either $d$ or $r$, standing for defunctionalization and refunctionalization, respectively. The parameter determines when the algorithm may stop, such that its results are legal inputs for de- or refunctionalization. The unnesting algorithm is essentially the copattern unnesting algorithm of Setzer et al., adapted to Uroboro.

We give the intended domain and range for each of the algorithms, all of which are specific fragments of Uroboro. Call the set of all well-typed Uroboro programs with copattern coverage $\mathbf{U}_{cc}$; the other fragments are defined below.
\begin{align*}
& \textsf{Unnest}_i: \mathbf{U}_{cc} \to \mathbf{U}_{cc}[fdef_{un,i}] \text{ for } i \in \{d,r\} \\
& \textsf{CoreDefunc}: \mathbf{U}_{cc}[fdef_{un,d}] \to \mathbf{U}^{defunc}_{cc} \\
& \textsf{CoreRefunc}: \mathbf{U}_{cc}[fdef_{un,r}] \to \mathbf{U}^{refunc}_{cc}
\end{align*}

\begin{definition}[Unnested Fragments for \textsf{CoreDefunc} and \textsf{CoreRefunc}]
The fragments $\mathbf{U}_{cc}[fdef_{un,d}]$, $\mathbf{U}_{cc}[fdef_{un,r}]$, for lhss unnested as far as necessary for \textsf{CoreDefunc} and \textsf{CoreRefunc}, respectively, are induced by the function definition fragments $fdef_{un,d}$ and $fdef_{un,r}$, respectively, both defined below using EBNF rules. For these, the basic EBNF rules from the definition of the syntax of Uroboro are reused.
\begin{align*}
fdef_{un,d} &::= eqn_{nd}^* ~ | ~ eqn_d^* \\
eqn_{nd} &::= fun(x^*).des(y^*) = t \\
eqn_d &::= fun(p^*) = t \\
\end{align*}
\begin{align*}
fdef_{un,r} &::= eqn_{nr}^* ~ | ~ eqn_r^* \\
eqn_r &::= fun(x^*).des(y^*)^* = t \\
eqn_{nr} &::= fun(con(x^*), y^*) = t \\
\end{align*}
\end{definition}

\begin{definition}[Defunctionalized fragment]
A well-typed Uroboro program is in the defunctionalized fragment $\mathbf{U}^{defunc}_{cc}$ if and only if it contains no codata type definitions.
\end{definition}

\begin{definition}[Refunctionalized fragment]
A well-typed Uroboro program is in the refunctionalized fragment $\mathbf{U}^{refunc}_{cc}$ if and only if it contains no data type definitions.
\end{definition}

For each algorithm it will be shown, in its respective section, that it actually has the range specified above. In total, four important properties will be shown for each algorithm: Termination, correct range, preservation of well-typedness, and preservation of semantics in a (weak) bisimulation.

The rest of the section is organized as follows. The first section describes the unnesting algorithm, shows why the three properties hold, and gives applies it to an example. Section 2 and 3 do the same for the unmixing algorithm, and core de-/refunctionalization, respectively.

\section{Unnesting}

We adapt the translation algorithm from section 3.3 of the paper of Setzer et al. to Uroboro. Their algorithm translates equations step-by-step depending upon the derivation of the copattern coverage of their lhss. Our adaptation only has steps which concern patterns that have a counterpart in Uroboro\footnote{I.e., not those for applications, units, and pairs. In the adapted algorithm for Uroboro, the last one is merged into the steps for destructors and constructors, while the others are irrelevant because Uroboro doesn't have the corresponding higher-order constructs.}. Each such translation step can be considered an extraction as defined in chapter 3.

\subsection{Simple patterns}

Before we start with the translation algorithm, we adapt and introduce, respectively, two notions of simplicity for patterns, the second of which corresponds to the intended range of the translation algorithm. We first adapt the definition of a \textit{simple pattern}, as given by Setzer et al., to Uroboro. Call a copattern simple if it is of one of the three forms $fun(\overline{x})$, $fun(\overline{x}).des(\overline{y})$, or $fun(con(\overline{x}), \overline{y})$.

Next, we generalize this definition to define \textit{sufficiently simple patterns} for a purpose, which is either de- or refunctionalization. Call a copattern \textit{sufficiently simple for defunctionalization} if it is of one of the two forms $fun(\overline{x}).des(\overline{y})$, $fun(\overline{p})$, and \textit{sufficiently simple for refunctionalization} if it is of one of the two forms $fun(\overline{x}).\overline{des(\overline{y})}$, $fun(con(\overline{x}), \overline{y})$. We will also say that a copattern is sufficiently simple for $i$, for $i \in \{d,r\}$, and mean that it is sufficiently simple for defunctionalization or refunctionalization, respectively.

Those notions correspond directly to the forms of lhss allowed in the unnested fragments for \textsf{CoreDefunc} and \textsf{CoreRefunc}, respectively. It is clear that each simple copattern is also sufficiently simple for both de- and refunctionalization.

\subsection{Translation algorithm}

We describe the algorithm for $\textsf{Unnest}_i$, adapted from section 3.3 of the paper of Setzer et al. to Uroboro, as lined out above.

\begin{algorithm}[$\textsf{Unnest}_i$]

Like Setzer et al., we consider the last step in the derivation of the copattern coverage for the lhss of a function definition. Just like them, we are not interested in the case where the last step is C\textsubscript{Head}, since that means the lhs is already simple, and we terminate. When the last step isn't C\textsubscript{Head}, but the lhss are all sufficiently simple for $i$ nonetheless, we also terminate.

\begin{prooftree}
\AxiomC{$fun \lhd | ~ Q ~ (q)$}
\RightLabel{\textbf{C}}
\UnaryInfC{$fun \lhd | ~ Q ~ (q_i)_{i \in I}$}
\end{prooftree}

Also like Setzer et al., we then introduce a fresh auxiliary function and translate the program depending on \textbf{C}. As stated before, these translations are slightly adapted to fit the framework of Uroboro, such that two remain, one for destructors and one for constructors. More importantly, both of those are in fact extractions as defined in chapter 3, namely destructor and constructor extraction. 

\begin{enumerate}
\item \textbf{C} is C\textsubscript{Des}, and the last derivation step looks as follows.

\begin{prooftree}
\AxiomC{$fun \lhd | ~ Q ~ (q^\tau)$}
\RightLabel{C\textsubscript{Des}}
\UnaryInfC{$fun \lhd | ~ Q ~ (q.des(\overline{x^{des}}))_{des \in Dess_\tau}$}
\end{prooftree}

Apply extraction \textsf{ExtractDes} targeting the equations with lhss $q.des(\overline{x^{des}})$, for all $des \in Dess_\tau$, to the function definition for $fun$. From this we obtain the changed function definition $def'_{fun}$ for $fun$ and the auxiliary function definition. The lhss of $def'_{fun}$ are
\[
Q \cup \{ \texttt{get}(q.des(\overline{x^{des}})) ~ | ~ des \in Dess_\tau \} = Q \cup \{q\},
\]
where \texttt{get} is the retrieving part of the lens underlying \textsf{ExtractDes}. This set of lhss is the same as that in $fun \lhd | ~ Q ~ (q^\tau)$ from the derivation step above. The lhss of the auxiliary function definition are
\begin{multline*}
\{ q_{\zeta_r} ~ | ~ r \in T \} = \{ \texttt{putback}(\langle \texttt{get}(q_r) \rangle^{aux}, q_r) ~ | ~ r \in T \} \\
= \{ \sigma^{q_r}_\pi(aux(\langle q \rangle^{vars})) ~ | ~ r \in T \} = \{ aux(\langle q \rangle^{vars}).des(\overline{x^{des}}) ~ | ~ des \in Dess_\tau \} \\
= \{ aux(\langle q \rangle^{vars}).des(\overline{x^{des}}) ~ | ~ des \in Dess_\tau \},
\end{multline*}
where $\zeta$ is the function in the triple that is \textsf{ExtractCon}(p). It is clear that each $q_{\zeta_r}$ is simple and that $\{ q_{\zeta_r} ~ | ~ r \in T \}$ covers $aux$:
\begin{prooftree}
\AxiomC{}
\RightLabel{C\textsubscript{Head}}
\UnaryInfC{$aux \lhd | ~ aux(x, \overline{y})$}
\RightLabel{C\textsubscript{ResSplit}}
\UnaryInfC{$aux \lhd | ~ (q_{\zeta_r})_{r \in T}$}
\end{prooftree}

\item \textbf{C} is C\textsubscript{Con}, and the last derivation step looks as follows. 

\begin{prooftree}
\AxiomC{$fun \lhd | ~ Q ~ (q(x^\tau))$}
\RightLabel{C\textsubscript{Con}}
\UnaryInfC{$fun \lhd | ~ Q ~ (q[x := con(\overline{y^{con}})])_{con \in Cons_\tau}$}
\end{prooftree}

Let $p$ be the position of $x$ in $q$. Apply extraction \textsf{ExtractCon}(p) targeting the equations with lhss $q[x := con(\overline{y^{con}})]$, for all $con \in Cons_\tau$ to the original function definition for $fun$. From this we obtain the changed function definition $def'_{fun}$ for $fun$ and the auxiliary function definition. The lhss of $def'_{fun}$ are
\[
Q \cup \{ \texttt{get}(q[x := con(\overline{y^{con}})]) ~ | ~ con \in Cons_\tau \} = Q \cup \{q\},
\]
where the pair of \texttt{get} and \texttt{putback} is the lens underlying \textsf{ExtractCon}(p). This set of lhss is the same as that in $fun \lhd | ~ Q ~ (q)$ from the derivation step above. The lhss of the auxiliary function definition are
\begin{multline*}
\{ q_{\zeta_r} ~ | ~ r \in T \} = \{ \texttt{putback}(\langle \texttt{get}(q_r) \rangle^{aux}, q_r) ~ | ~ r \in T \} \\
= \{ \sigma^{q_r}_\pi(aux(\langle q \rangle^{vars})) ~ | ~ r \in T \} = \{ aux(\langle q \rangle^{vars})[x := con(\overline{y^{con}})] ~ | ~ con \in Cons_\tau \} \\
= \{ aux(x, \langle q_r \rangle^{vars})[x := con(\overline{y^{con}})] \text{ for some } r \in T ~ | ~ con \in Cons_\tau \},
\end{multline*}
where $\zeta$ is the function in the triple that is \textsf{ExtractCon}(p). It is clear that each $q_{\zeta_r}$ is simple and that $\{ q_{\zeta_r} ~ | ~ r \in T \}$ covers $aux$:
\begin{prooftree}
\AxiomC{}
\RightLabel{C\textsubscript{Head}}
\UnaryInfC{$aux \lhd | ~ aux(x, \overline{y})$}
\RightLabel{C\textsubscript{VarSplit}}
\UnaryInfC{$aux \lhd | ~ (q_{\zeta_r})_{r \in T}$}
\end{prooftree}
\end{enumerate}

As shown for each of the two cases, after the extractions copattern coverage still holds for the translated program, and we even know its derivation tree. Thus we can go back to the start and do further translations, if necessary.
\end{algorithm}

Next, we consider important properties of the translation algorithm.

\textbf{Range.} The algorithm only stops when all lhss are sufficiently simple for $i$ and works on the coverage derivation trees, thus we have the desired range $\mathbf{U}_{cc}[fdef_{un,i}]$ if it terminates in all cases, which is shown next.

\textbf{Termination.} To show that the algorithm terminates, we can basically repeat the argument of Setzer et al. Each translation results in a changed function definition $def'_{fun}$ for $fun$ and a new function definition $def_{aux}$ for the auxiliary function. The lhss of $def'_{fun}$ are $Q \cup \{q\}$, which means that they cover $fun$ in the same way $fun$ is covered via $fun \lhd | ~ Q ~ (q)$ in the derivation step above. This means that the translation reduces the depth of the derivation tree for the coverage of $fun$, thus eventually arriving at sufficiently simple patterns. The added auxiliary function definitions already have simple lhss, thus they are not translated, and eventually the algorithm terminates.

\textbf{Bisimulation.} Because copattern coverage holds for the translated program, the translated program has no overlapping lhss. Therefore, by the propositions 3.3.1 and 3.3.2, we know that the translation preserves the semantics of the program in the kind of weak bisimulation described in section 3.3.

\subsection{Example}

As an example application of the algorithm, consider the following program fragment.

\begin{lstlisting}

fun(x).des().des1(con1()) = t1
fun(x).des().des1(con2()) = t2
fun(x).des().des2() = t3

\end{lstlisting}

The final step in the coverage derivation for $fun$ is splitting \texttt{fun(x).des().des1(y)} into \texttt{fun(x).des().des1(con1())} and \texttt{fun(x).des().des1(con2())} by splitting variable $y$. Therefore we first target these two lhss for constructor extraction at the common position of \texttt{con1()} and \texttt{con2()} in the two lhss; the result of the extraction can be seen below.

\begin{lstlisting}

fun(x).des().des1(y) = aux(y, x)
fun(x).des().des2() = t3

aux(con1(), x) = t1
aux(con2(), x) = t2

\end{lstlisting}

For this program, the final step in the coverage derivation for $fun$ is splitting \texttt{fun(x).des()} into \texttt{fun(x).des().des1(y)} and \texttt{fun(x).des().des2()} by result splitting. Therefore we target these two lhss for destructor extraction; the result of the extraction can be seen below. Note that \texttt{fun(x).des() = aux2(x)} is generated twice but only present once in the function definition, as these are sets.

\begin{lstlisting}

fun(x).des() = aux2(x)

aux2(x).des1(y) = aux(y, x)
aux2(x).des2() = t3

\end{lstlisting}

The \texttt{aux} function definition remains unchanged and is omitted. This program is in the desired fragment; the algorithm terminates here because all lhss of the program are simple.

\section{Core de-/refunctionalization}

...

\textsf{CoreDefunc} and \textsf{CoreRefunc} use -- and in fact essentially are -- the respective sides of the two-way transformation of Rendel et al. One side of this is the defunctionalization for the Codata Fragment, which we call $d^{codata}$ in here, and the other side is the refunctionalization for the Data Fragment, which we call $r^{data}$. Their definitions are repeated below for the convenience of the reader.

...

\subsection{Core defunctionalization}

The core defunctionalization \textsf{CoreDefunc} applies the defunctionalization of Rendel et al. for the Codata Fragment to the parts of the program that are in this fragment, and leaves the rest, which is already in a defunctionalized form after \textsf{Unnest}, virtually unchanged. That is, the only change to these parts affects the right-hand sides of equations, which are transformed to account for the syntactic differences between function and destructor calls.\footnote{I.e., the difference between $fun(...)$ and $t.des(...)$. This difference vanishes when changing the syntax of destructor calls to $des(t, ...)$.} The respective transformation for terms is $d$, defined below with the algorithm.

\begin{algorithm}[\textsf{CoreDefunc}]

First, we define the class $FDEF^{prg}_d$ of function definitions of a program $prg$ which are already defunctionalized. A function definition is already defunctionalized when all of its equations have lhss without destructors. We define the class of already defunctionalized functions $F^{prg}_d$ as those which have already defunctionalized function definitions.

Next, we give the definition for \textsf{CoreDefunc}. This needs further explanation due to technical difficulties, as follows below.

\begin{alignat*}{3}
\langle prg \rangle^{\textsf{CoreDefunc}} & = ~&& \langle && \{ def \in prg ~ | ~ def = ``\textbf{codata } ..." \text{ or } def = ``\textbf{function } ..." \not\in F^{prg}_d \} \rangle^{d^{codata}} \\
& \cup && \{ && \textrm{\textbf{data }} ... ~ | ~ `` \textrm{\textbf{data }} ... " \in prg \} \\
& \cup && \{ && \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} \{ q = \langle t \rangle^d ~ | ~ "q = t" \in eqns \} \\
& && | && `` \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} eqns " \in F^{prg}_d \} 
\end{alignat*}

This definition is not quite legal, because the argument of $d^{codata}$ possibly has equations with right-hand sides which cannot be correctly transformed by $d^{codata}$. There are two different problems which can possibly arise, but which are also easily circumvented, as follows.
\begin{enumerate}
\item There are function calls to functions which are already defunctionalized (those in $F_d$); $d^{codata}$ wants to transform them into constructor calls, which is neither possible nor necessary. To circumvent this, replace each function name $fun \in F_d$ (in a right-hand side term) with a destructor name $des_{fun}$ unique to $fun$, and set $\langle des_{fun} \rangle^d = fun$. Then $d^{codata}$ will transform them back into the original function calls, which means that they ultimately are left unchanged, as desired.

\item There are constructor calls; the domain of $d^{codata}$, the Codata Fragment, doesn't allow them. To circumvent this, replace such calls to a constructor $con$ with function calls with a function name $fun_{con}$ unique to $con$, and set $\langle fun_{con} \rangle^d = con$. Then $d^{codata}$ will transform them back into the original constructor calls, which means that they ultimately are left unchanged, as desired.
\end{enumerate}

Below, we define the transformation for terms $d$, which is only necessary due to the syntactic differences between function and destructor calls.

\begin{align*}
\langle x \rangle^d = x \\
\langle s.des(t_1, ..., t_n) \rangle^d = \langle des \rangle^d (\langle s \rangle^d, \langle t_1 \rangle^d, ..., \langle t_n \rangle^d) \\
\langle fun(t_1, ..., t_n) \rangle^d = fun(\langle t_1 \rangle^d, ..., \langle t_n \rangle^d), \text{ if } fun \in F_d \\
\langle fun(t_1, ..., t_n) \rangle^d = \langle fun \rangle^d (\langle t_1 \rangle^d, ..., \langle t_n \rangle^d), \text{ if } fun \not\in F_d \\
\langle con(t_1, ..., t_n) \rangle^d = con(\langle t_1 \rangle^d, ..., \langle t_n \rangle^d)
\end{align*}

\end{algorithm}

We consider important properties of the transformation.

\textbf{Bisimulation.} For \textsf{CoreDefunc}, strong bisimulation holds. The proof relies on properties of $d^{codata}$. Note that the domain of $d^{codata}$ is Rendel et al.'s Codata Fragment. As stated in section 2.3.1, the reduction relation of the Codata Fragment in the work of Rendel et al. and our work's standard reduction relation, restricted to this fragment, are the same, as long as programs are required to have copattern coverage. Analogously, the domain of $r^{data}$ is the Data Fragment, and Rendel et al.'s reduction relation for this fragment is the same as ours restricted to this fragment. In section 3 of their paper, Rendel et al. prove Lemma 5, which in terms of our work can be stated as follows.

\begin{lemma}[Strong bisimulation for $d^{codata}, r^{data}$]
\[
s \longrightarrow_{prg} t \iff \langle s \rangle^d \longrightarrow_{\langle prg \rangle^{d^{codata}}} \langle t \rangle^d
\]
and
\[
s \longrightarrow_{prg} t \iff \langle s \rangle^r \longrightarrow_{\langle prg \rangle^{r^{codata}}} \langle t \rangle^r.
\]
\end{lemma}

Using this, we prove strong bisimulation for \textsf{CoreDefunc}.

\begin{lemma}[Strong bisimulation for \textsf{CoreDefunc}]
\[
s \longrightarrow_{prg} t \iff \langle s \rangle^d \longrightarrow_{\langle prg \rangle^{\textsf{CoreDefunc}}} \langle t \rangle^d
\]

\begin{proof}
For the sake of this proof, we will neglect the syntactic differences between destructor and function calls. By the definition of \textsf{CoreDefunc}, it is
\[
\langle prg \rangle^{\textsf{CoreDefunc}} = \langle prg' \rangle^{d^{codata}} \cup prg''
\]
such that $prg' \cup prg'' = prg$. By Lemma 4.2.1, the reduction relations pertaining to the programs $prg'$ and $\langle prg' \rangle^{d^{codata}}$ are one and the same. The reduction relation pertaining to $prg$ is that of $prg'$ changed according to the equations of $prg''$, and the reduction relation pertaining to $\langle prg \rangle^{\textsf{CoreDefunc}}$ is also that of $prg'$ changed according to the equations of $prg''$. Thus these reduction relations are the same, which is equivalent to the statement of this lemma.
\end{proof}
\end{lemma}

\subsection{Core refunctionalization}

Core refunctionalization is defined analogously to core defunctionalization. It applies the refunctionalization of Rendel et al. for the Data Fragment to the parts of the program that are in this fragment, and leaves the rest, which is already in a refunctionalized form after \textsf{Unnest}, virtually unchanged. 

\begin{algorithm}[\textsf{CoreRefunc}]

First, we define the class $FDEF^{prg}_r$ of function definitions of a program $prg$ which are already refunctionalized. A function definition is already refunctionalized when (a) all of its equations have destructor patterns, or (b) the function has no arguments, or (c) the first argument of every lhs is a variable. We define the class of already refunctionalized functions $F^{prg}_r$ as those which have already defunctionalized function definitions.

Next, we give the definition for \textsf{CoreRefunc}. This needs further explanation due to technical difficulties, as follows below.

\begin{alignat*}{3}
\langle prg \rangle^{\textsf{CoreRefunc}} & = ~&& \langle && \{ def \in prg ~ | ~ def \textrm{ is data def. or function def. } \not\in FDEF^{prg}_r \rangle^{r^{data}} \\
& \cup && \{ && \textrm{\textbf{codata }} ... ~ | ~ `` \textrm{\textbf{codata }} ... " \in prg \} \\
& \cup && \{ && \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} \{ p = \langle t \rangle^r ~ | ~ ``p = t" \in eqns \} \\
& && | && `` \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} eqns " \in FDEF^{prg}_r \} 
\end{alignat*}

This definition is not quite legal, because the argument of $r^{data}$ possibly has equations with right-hand sides which cannot be correctly transformed by $r^{data}$. There a two different problems which can possibly arise, but which are also easily circumvented, as follows. Note that these points mirror those for \textsf{CoreDefunc}.
\begin{enumerate}
\item There are function calls to functions which are already refunctionalized (those in $F_r$); $r^{data}$ wants to transform them into destructor calls, which is neither possible nor necessary. The following technical trick circumvents this problem: For the sake of this usage of $r^{data}$, replace each function name $fun \in F_r$ (in a right-hand side term) with a constructor name $con_{fun}$ unique to $fun$, and set $\langle con_{fun} \rangle^r = fun$. Then $r^{data}$ will transform them back into the original function calls, which means that they ultimately are left unchanged, as desired.
\item There are destructor calls; the domain of $r^{data}$, the Data Fragment, doesn't allow them. To circumvent this problem, for the sake of this usage of $r^{data}$, replace such calls to a destructor named $des$ with function calls with a function name $fun_{des}$ unique to $des$, and set $\langle fun_{des} \rangle^d = des$. Then $r^{data}$ will transform them back into the original destructor calls, which means that they ultimately are left unchanged, as desired.
\end{enumerate}

Below, we define the transformation for terms $r$, which is only necessary due to the syntactic differences between function and destructor calls.

\begin{align*}
\langle x \rangle^r = x \\
\langle s.des(t_1, ..., t_n) \rangle^r = \langle s \rangle^r .des(\langle t_1 \rangle^r, ..., \langle t_n \rangle^r) \\
\langle fun(t_1, ..., t_n) \rangle^r = fun(\langle t_1 \rangle^r, ..., \langle t_n \rangle^r), \text{ if } fun \in F_r \\
\langle fun(t_1, ..., t_n) \rangle^r = \langle t_1 \rangle^r .\langle fun \rangle^r (\langle t_2 \rangle^r, ..., \langle t_n \rangle^r), \text{ if } fun \not\in F_r \\
\langle con(t_1, ..., t_n) \rangle^r = \langle con \rangle^r (\langle t_1 \rangle^r, ..., \langle t_n \rangle^r)
\end{align*}

\end{algorithm}

We consider important properties of the transformation.

\textbf{Bisimulation.} For \textsf{CoreRefunc}, strong bisimulation holds. The proof relies on properties of $r^{data}$. In the ``Bisimulation'' part of the previous subsection, we already outlined the main points: The domain of $r^{data}$ is the Data Fragment, and Rendel et al.s reduction relation for this fragment is the same as ours restricted to this fragment. In section 3 of their paper, Rendel et al. prove Lemma 5, which we have restated as Lemma 4.2.1. Using this, we prove strong bisimulation for \textsf{CoreRefunc}.

\begin{lemma}[Strong bisimulation for \textsf{CoreRefunc}]
\[
s \longrightarrow_{prg} t \iff \langle s \rangle^r \longrightarrow_{\langle prg \rangle^{\textsf{CoreRefunc}}} \langle t \rangle^r
\]

\begin{proof}
For the sake of this proof, we will neglect the syntactic differences between destructor and function calls. By the definition of \textsf{CoreRefunc}, it is
\[
\langle prg \rangle^{\textsf{CoreRefunc}} = \langle prg' \rangle^{r^{data}} \cup prg''
\]
such that $prg' \cup prg'' = prg$. By Lemma 4.2.1, the reduction relations pertaining to the programs $prg'$ and $\langle prg' \rangle^{r^{data}}$ are one and the same. The reduction relation pertaining to $prg$ is that of $prg'$ changed according to the equations of $prg''$, and the reduction relation pertaining to $\langle prg \rangle^{\textsf{CoreRefunc}}$ is also that of $prg'$ changed according to the equations of $prg''$. Thus these reduction relations are the same, which is equivalent to the statement of this lemma.
\end{proof}
\end{lemma}

\subsection{Example}

We continue with the example fragment of section 4.1.3, augmented with (co)data definitions and signatures.

\begin{lstlisting}

data P where
  con1(): P
  con2(): P

codata N1 where
  N1.des(): N2

codata N2 where
  N2.des1(P): P
  N2.des2(): P

function fun(N1): N1 where
  fun(x).des() = aux2(x)

function aux(P, N1): P where
  aux(con1(), x) = t1
  aux(con2(), x) = t2

function aux2(N1): N2 where
  aux2(x).des1(y) = aux(y, x)
  aux2(x).des2() = t3

\end{lstlisting}

Using the \textsf{CoreDefunc} algorithm on this yields the following program, by leaving the function definition for \texttt{aux} and the data definition unchanged, and applying the defunctionalization of Rendel et al. to the other definitions.

\begin{lstlisting}

data P where
  con1(): P
  con2(): P

data N1 where
  fun(N1): N1

data N2 where
  aux2(N1): N2

function aux(P, N1): P where
  aux(con1(), x) = t1
  aux(con2(), x) = t2

function des(N1): N2 where
  des(fun(x)) = aux2(x)

function des1(N2, P): P where
  des1(aux2(x), y) = aux(y, x)

function des2(N2): P where
  des2(aux2(x)) = t3

\end{lstlisting}

Using the \textsf{CoreRefunc} algorithm on the original program yields the following program, by leaving the function definitions for \texttt{fun} and \texttt{aux2} and the codata definitions unchanged, and applying the refunctionalization of Rendel et al. to the other definitions.

\begin{lstlisting}

codata P where
  P.aux(N1): P

codata N1 where
  N1.des(): N2

codata N2 where
  N2.des1(P): P
  N2.des2(): P

function fun(N1): N1 where
  fun(x).des() = aux2(x)

function aux2(N1): N2 where
  aux2(x).des1(y) = aux(y, x)
  aux2(x).des2() = t3

function con1() where
  con1().aux(x) = t1

function con2() where
  con2().aux(x) = t2

\end{lstlisting}

%%-- end under construction