\chapter{Automatic de- and refunctionalization}

\section{Common pretransformations}

...

\subsection{Aligning patterns}

To prevent destructor extraction from introducing overlaps, it is necessary that, for all function definitions of the program, all lhss of the function definition \textit{align} -- and in fact, this property is already sufficient for this purpose. In short, for two copatterns $q_1, q_2$ to align means that any pattern directly under $q_1$ has the same specificity as its respective counterpart under $q_2$, if any. In this section, we first illustrate why the correctness of destructor extraction depends upon the alignment of the lhss. Then we formally define alignment and prove that alignment suffices to prevent the introduction of overlaps via destructor extraction. In appendix B, we give an algorithm for aligning copatterns.

When extracting destructors out of a program which has non-aligning lhss, the resulting program can have overlapping lhss even though the original program didn't. Consider the following example where the first and the third equations don't align (as well as the second and the third equation).

\begin{lstlisting}

fun().d1(c1()).d1() = t_1
fun().d1(c2()).d1() = t_2
fun().d1(x).d2() = t_3

\end{lstlisting}

Why don't these equations align? The third equation's left-hand side has a catch-all pattern (variable) in its first destructor call $d1$. The first destructor in the first and second equations' left-hand sides is also $d1$, but the patterns there are the constructors $c1()$ and $c2()$, respectively; they are more specific than the catch-all pattern.

If we target the first lhs for destructor extraction, its final destructor is extracted; the result of this is shown below (we omit the generated auxiliary function definition).

\begin{lstlisting}

fun().d1(c1()) = aux()
fun().d1(c2()).d1() = t_2
fun().d1(x).d2() = t_3

\end{lstlisting}

Now, the first and the third lhs overlap. For destructor extraction to work correctly, the catch-all pattern must be split before the extraction. The program fragment after this split is shown below.

\begin{lstlisting}

fun().d1(c1()).d1() = t_1
fun().d1(c2()).d1() = t_2
fun().d1(c1()).d2() = t_3
fun().d1(c2()).d2() = t_3

\end{lstlisting}

When we now target the first lhs for destructor extraction, this transformation also affects the third lhs because they have the same remains. Thus the extraction results in the equations shown below.

\begin{lstlisting}

fun().d1(c1()) = aux()
fun().d1(c2()).d1() = t_2
fun().d1(c1()) = aux()
fun().d1(c2()).d2() = t_3

\end{lstlisting}

The first and the third equation are identical and are thus present only once in the program, thus the program doesn't have overlapping lhss. The program that was transformed has only aligned lhss. In fact, to prevent destructor extraction from introducing overlaps it suffices that the transformed program has this property, as we will show further on.

Now, we formally define what it means for a (co-)pattern to be \textit{aligned} with another (co-)pattern.

\begin{definition}[Aligning patterns]
Two patterns $p_1, p_2$ of the same type align if they are (a) both variables, (b) both constructor calls of different constructors, or (c) constructor calls of the same constructor $con$ such that
\[
p_1 = con(p'_1, ..., p'_n), p_2 = con(p''_1, ..., p''_n),
\]
where, for all $i \in \{1, ..., n\}$, $p'_i$ and $p''_i$ align.
\end{definition}

\begin{definition}[Aligning copatterns]
Two copatterns $q_1, q_2$ of the same function definition, for a function $fun$, align if the respective arguments of their largest common destructor call chains align.
\end{definition}

Aligning patterns of a program before applying destructor extraction guarantees that the destructor extraction doesn't introduce overlaps. As shown in subsection 4.2.2, this follows from the following lemma.

\begin{lemma}
For any program $prg$ without overlapping lhss and where, for all of its function definitions $def$, all lhss of $def$ align with each other, the following holds: Whenever two prefixes of $prg$ overlap, one of them is a prefix of the other.

\begin{proof}
Suppose there are two lhss $q_1, q_2$ with prefixes $q^{\mathit{pref}}_1$ and $q^{\mathit{pref}}_2$, respectively, such that these prefixes overlap. Especially, this means that one of them -- w.l.o.g., $q^{\mathit{pref}}_1$ -- has an initial destructor chain $C$ that is identical to the entire destructor chain of the other, $q^{\mathit{pref}}_2$. Thus the entire destructor chain of $q^{\mathit{pref}}_2$ is a part of the largest common destructor chain of $q_1$ and $q_2$. It follows that all of the pattern arguments of the initial destructor chain $C$ of $q^{\mathit{pref}}_1$ align with the respective arguments of the destructor chain of $q^{\mathit{pref}}_2$. For the associated instances of these two destructor chains to overlap, it also needs to be the case that their respective pattern arguments overlap. Whenever two patterns overlap and align they are the same, thus $q^{\mathit{pref}}_2$ is a prefix of $q^{\mathit{pref}}_1$.
\end{proof}
\end{lemma}

\section{Transformation steps}

Both de- and refunctionalization are made up of a couple of preprocessing steps, followed by the core de-/refunctionalization, which is essentially the two-way transformation from the paper of Rendel et al.

Automatic defunctionalization consists of the following steps:
\begin{enumerate}
\item Eliminate multiple destructors. ($elim\_multi\_des_d$)

\item Unmix function definitions. ($unmix$)

\item Eliminate constructors from destructor copatterns. ($elim\_cons\_from\_des$)

\item Core defunctionalization. ($d_{core}$)

\end{enumerate}

Automatic refunctionalization consists of the following steps:
\begin{enumerate}
\item Eliminate multiple destructors from copatterns containing constructors. ($elim\_multi\_des_r$)

\item Unmix function definitions. ($unmix$)

\item Eliminate constructors from destructor copatterns. ($elim\_cons\_from\_des$)

\item Eliminate multiple constructors. ($elim\_multi\_con$)

\item Core refunctionalization. ($r_{core}$)

\end{enumerate}

Each preprocessing step is applied to each function definition individually. It is thus assumed that the function definition to be transformed is available to the transformation. For the complete step, simply transform all function definitions, in arbitrary order.

Each preprocessing steps can be defined as a recursive composition of one of the basic building blocks described in the next section. One such building block is an extraction function lifted to programs with $extract\_helpers$. The definitions for each step follow below; for them, the following conditional recursion combinator will be used:
\[
    condrec(f, cond) :=
\begin{cases}
    condrec(f, cond) \circ f,& \text{if $cond$ holds} \\
   id,& \text{otherwise}
\end{cases}
\]

Let $q^{work}$ denote any copattern which isn't yet in the desired form. For $unmix$, this means that it has a destructor, for all other steps this means that the condition passed to $condrec$ holds for the individual copattern. Let $n$ be the number of constructors in the targeted pattern (i.e., the extracted constructor is the right-most one).

\begin{framed}

\begin{alignat*}{1}
&elim\_multi\_des_i = condrec(liftp(extract\_des(q^{work})), cond_i), \textrm{ for } i \in \{d, r\}, \textrm{ with } \\
&\qquad cond_d = \textrm{``the function def. contains multiple destructors''} \\
&\qquad cond_r = \textrm{``the function def. contains a multiple destructor copattern with constructors''} \\
&unmix = condrec(liftp(extract\_des(q^{work})), cond), \textrm{ with}\\
&\qquad cond = \textrm{``the function def. is mixed''} \\
&elim\_cons\_from\_des = condrec(liftp(extract\_patterns(q^{work})), cond), \textrm{ with}\\
&\qquad cond = \textrm{``the function def. has destructor copatterns with constructors''} \\
&elim\_multi\_con = condrec(liftp(extract\_con_n(q^{work})), cond), \textrm{ with}\\
&\qquad cond = \textrm{``the function def. has copatterns with multiple constructors''}
\end{alignat*}

\end{framed}

As stated above, $r_{core}$ and $d_{core}$ are essentially two ways of the transformation of Rendel et al. Their precise definitions are given in section 3.6.

\subsection{Bisimulation}

All of the preprocessing steps are recursive compositions of lifted extraction functions. Each of those extraction functions preserve the semantics of the program in the kind of weak bisimulation described in the previous chapter, when the program doesn't have overlapping lhss.

For the bisimulation to hold, it is therefore necessary that each application of an extraction function in the preprocessing steps doesn't introduce overlapping lhss. This will be shown in the next subsection.

For core de-/refunctionalization, strong bisimulation holds. This is essentially a corollary of that property for the two-way transformation of Rendel et al., as will be shown in the section on core de- and refunctionalization.

\subsection{Absence of overlaps}

The three extraction functions used, $extract\_des$, $extract\_patterns$, and $extract\_con_n$ are shown to preserve the absence of overlapping lhss wherever they are applied in the preprocessing steps. By Proposition 2.4.1, it suffices to show that $q_\epsilon$ doesn't overlap with any lhs of an equation taken over unchanged from the original program.

\subsubsection{Destructor extraction}

By Lemma 4.1.1, the pre-transformation $align\_patterns$ ensures that, whenever two prefixes of lhss of the original program overlap, one of them is a prefix of the other. $q_\epsilon$ is a prefix of an lhs $q_r$ of the original program; if it overlapped with a $q_{r'}$ taken over unchanged then $q_{r'}$ (a prefix of itself) and the prefix $q_\epsilon$ of $q_r$ overlapped. But then, by Lemma 4.1.1, either (a) $q_\epsilon$ is a prefix of $q_{r'}$ or (b) $q_{r'}$ is a prefix of $q_\epsilon$. In case (a) it is either $q_\epsilon = q_{r'}$, but then $q_{r'}$ and $q_r$ overlapped contrary to assumption, or, since $q_{r'}$ doesn't have more destructors than $q_r$, $q_{r'}$ is identical to $q_r$ except for the last destructor call, but then $q_{r'}$ would also be targeted by the destructor extraction, contrary to assumption. In case (b) $q_{r'}$ is a prefix of $q_r$ and thus they overlap, again contrary to assumption.

\subsubsection{Pattern extraction}

The extraction $extract\_patterns$ is only ever applied to single-destructor copatterns and transforms them to single-destructor copatterns without any constructors. It is also only ever used in unmixed function definitions where all lhss have exactly one destructor. If the destructor of such an lhs $q$ is different from that of $q_\epsilon$, they cannot overlap. But if the destructor of $q$ is the same as that of $q_\epsilon$, and thus the same as that of $q_r$, the extraction result is the same for both $q_r$ and $q$. Thus, by the definition of extraction functions, the equations of $q_r$ and $q$ are the same.

\subsubsection{Constructor extraction}

The only transformed equations have no destructors on their lhs. Constructor extraction is only ever used with unmixed function definitions. It follows that, if $q_\epsilon$ overlapped with an unchanged lhs, the latter has no destructors, too. Since the extracted constructor is further right than the right-most constructor in the unchanged lhs, the unchanged lhs and $q_\epsilon$ would overlap, contrary to assumption.

\section{Core de- and refunctionalization}

\subsection{Core defunctionalization}

After the preprocessing steps, the only thing that remains is to apply the defunctionalization for the Codata Fragment of Uroboro, as developed by Rendel et al., to the not yet defunctionalized parts of the program. It can be applied to these parts because the preprocessing steps guarantee that they are in the Codata Fragment. Call the defunctionalization for the Data Fragment of Uroboro $d^{codata}$; the core defunctionalization for programs is defined as follows below.

\begin{alignat*}{3}
\langle prg \rangle^{d_{core}} & = ~&& \langle && \{ def \in prg ~ | ~ def \textrm{ is codata def. or} \\ & && &&\quad \textrm{ function def. with equations } eqns \neq \emptyset: \forall e \in eqns: e \textrm{ has destr. pattern } \} \rangle^{d^{codata}} \\
& \cup && \{ && \textrm{\textbf{data }} ... ~ | ~ `` \textrm{\textbf{data }} ... " \in prg \} \\
& \cup && \{ && \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} \{ p = \langle t \rangle^d ~ | ~ "p = t" \in eqns \} \\
& && | && `` \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} eqns " \in prg \textrm{ with } \forall e \in eqns: e \textrm{ has hole pattern}\} 
\end{alignat*}

Technical note on constructor subsumption:

The input of $d^{codata}$ in the definition above is actually not in its domain. This is because it can contain constructor calls. The following technical trick allows to transform such inputs as well: For the sake of $d^{codata}$, subsume constructor names under function names (as if they were from the same syntactic domain). After the transformation, since names aren't changed (or when name changes are desired, the original name can still be retrieved), the subsumed constructor names (or their equivalents after a name change) are once again considered constructor names (from the original syntactic domain).

Defunctionalizing terms: \\
$\langle x \rangle^d = x$ \\
$\langle s.des(t_1, ..., t_n) \rangle^d = \langle des \rangle^d (\langle s \rangle^d, \langle t_1 \rangle^d, ..., \langle t_n \rangle^d)$ \\
$\langle fun(t_1, ..., t_n) \rangle^d = \langle fun \rangle^d (\langle t_1 \rangle^d, ..., \langle t_n \rangle^d)$ \\
$\langle con(t_1, ..., t_n) \rangle^d = con(\langle t_1 \rangle^d, ..., \langle t_n \rangle^d)$ \\

\subsubsection{Proof of strong bisimulation}

For $d_{core}$, strong bisimulation holds. The proof relies on properties of $d^{codata}$. As stated in section 2.3.1, the authors' notion of reducibility is the same than that of this work when restricted to the domain of $d^{codata}$, the Codata Fragment.

In section 3, Rendel et al. prove Lemma 5, which in terms of this work can be stated as follows (possible since the reducibility notions are identical):

$s \longrightarrow_{prg} t \iff \langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$ for all input terms $s,t$ of $\langle \cdot \rangle$ (*)

Here, the angular brackets can stand for either of their transformations, the refunctionalization $r^{data}$ and the defunctionalization $d^{codata}$. Statement (*) means that strong bisimulation holds for $d^{codata}$.

Using (*), it will now be shown that strong bisimulation holds for $d_{core}$.

\begin{proof}[Proof of strong bisimulation for $d_{core}$] ~

$`` \Rightarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$s =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(prg)$}
\UnaryInfC{$s \longrightarrow s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = t$; the immediate subterms of $s$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^d$, $\langle t \rangle = \langle t \rangle^d$. $d$ is the defunctionalization of terms as defined above. This defunctionalization of terms is also, for all input terms from the fragment, identical to that of the Codata Fragment.

\begin{itemize}

\item \underline{Case 1}: $q$ is hole pattern:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a hole pattern (other cases are excluded by the relevant input fragment for $d_{core}$). Such equations (and indeed the function definitions) are left unchanged by $d_{core}$ except for defunctionalizing the right-hand term, as can be seen directly in the definition of $d_{core}$ (last set in the highest-level union). Thus Rules($\langle prg \rangle$) contains $(q, \langle s' \rangle)$.

By inversion, we have from $s =^? q \searrow \sigma$ that $s$ has the form $fun(v_1, ..., v_n)$ for some values $v_1, ..., v_n$, thus $\langle s \rangle = fun(\langle v_1 \rangle, ..., \langle v_n \rangle)$. By inversion for values, we have that each $v_i$ is either a constructor application or a value of codata type. If it is a value of codata type, by inversion on pattern matching, the relevant subpattern of $q$ can only be a variable, thus it is also matched by $\langle v_i \rangle$. If it is a constructor application, the relevant subpattern of $q$ is either a variable, and the same holds, or it is a constructor pattern, and by recursively descending into its subpatterns we still get that $\langle v_i \rangle = con(\langle v^1_i \rangle, ..., \langle v^m_n \rangle)$ matches against the subpattern of $q$.

By carrying the substitutions returned from the matchings along in the above recursive argument, we get a substitution $\sigma'$ such that $\langle s \rangle =^? q \searrow \sigma'$ and, by distributing over $\langle s' \rangle$, $\langle s' \rangle [\sigma'] = \langle s'[\sigma] \rangle = \langle t \rangle$. It follows that $\langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$.

\item \underline{Case 2}: $q = fun(p_1, ..., p_n).des(p'_1, ..., p'_k)$:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a destructor pattern (other cases are excluded by the relevant input fragment for $d_{core}$). Thus $s$ reduces to $t$ already with respect to the part of the program that is passed to $d^{codata}$, as specified in the definition of $d_{core}$. Let this part, amended by the ``constructor subsumption" noted for the definition of $d_{core}$, be $prg'$; it is: $s \longrightarrow_{prg'} t$

By (*) we would have

\begin{equation*}
s \longrightarrow_{prg'} t \iff \langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle,
\end{equation*}

were $prg'$ a well-typed program with copattern coverage for all subterms of $s$. 

For the coverage, bear in mind that the equation $`` q = s' "$ enabling the reduction of $s$ by the ``Subst" rule is part of $prg'$ by the precondition of Case 2. As $s$ matches against $q$, copattern coverage for $s$ is trivially fulfilled in $prg'$. The immediate subterms of $s$ are values with respect to $prg$ and, by inversion, their immediate subterms and so forth, which especially means that there is no rule in $prg$ against which they match. But $prg$ has copattern coverage for such a subterm (TODO: make this a general precondition) and there is already no rule for it in $prg$. It follows that $prg'$ still has copattern coverage for the subterm even though there is no rule for it in $prg'$. This is because, either (1) the subterm is a destructor call, then it can only be covered by destructor copatterns (as it matches against a destructor copattern) and those only occur within $prg'$, or (2) it is a constructor call, which doesn't need to be matched for coverage. It can't be a function call, since these can only be covered by directly matching the call, which isn't the case even in $prg$, for which coverage is assumed. Thus coverage holds for $prg'$.

For well-typedness, simply treat the missing types temporarily, that is, for the sake of (*), as codata types. This is no problem for the restriction to the domain of $d^{codata}$, since such types could be introduced inside the Codata Fragment with codata definitions. To be more precise, empty function definitions can be added for missing ones and empty codata definitions for missing types, and removed again after using (*), without adding or removing possible reductions, respectively. All in all, we have by (*):
\begin{equation*}
s \longrightarrow_{prg'} t \iff \langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle
\end{equation*}

But this program $\langle prg' \rangle^{d^{codata}}$ is a subset of $\langle prg \rangle$, as can be seen in the definition of $d_{core}$. This implies the desired $\langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$.

\end{itemize}

Other cases are excluded by the relevant input fragment.

\item \textbf{``Cong" case}:

\begin{prooftree}
\AxiomC{$s' \longrightarrow t'$}
\RightLabel{Cong}
\UnaryInfC{$\mathcal{E}[s'] \longrightarrow \mathcal{E}[t']$}
\end{prooftree}

with $\mathcal{E}[s'] = s$ and $\mathcal{E}[t'] = t$.

By the induction hypothesis we have $\langle s' \rangle \longrightarrow_{\langle prg \rangle} \langle t' \rangle$. Let $\langle \mathcal{E} \rangle$ denote the transformation of $\mathcal{E}$, defined analogously to the transformation of terms by transforming the terms in $\mathcal{E}$ and by setting $\langle [] \rangle = []$. By applying the congruence rule we get $\langle \mathcal{E} \rangle[\langle s' \rangle] \longrightarrow_{\langle prg \rangle} \langle \mathcal{E} \rangle[\langle t' \rangle]$. It is clear that $\langle \mathcal{E} \rangle[\langle s' \rangle] = \langle \mathcal{E}[s'] \rangle = \langle s \rangle$ and $\langle \mathcal{E} \rangle[\langle t' \rangle] = \langle \mathcal{E}[t'] \rangle = \langle t \rangle$.

\end{enumerate}

$`` \Leftarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$\langle s \rangle =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(\langle prg \rangle)$}
\UnaryInfC{$\langle s \rangle \longrightarrow_{\langle prg \rangle} s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = \langle t \rangle$; the immediate subterms of $\langle s \rangle$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^d$, $\langle t \rangle = \langle t \rangle^d$. $d$ is the defunctionalization of terms as defined above. This defunctionalization of terms is also, for all input terms from the fragment, identical to that of the Codata Fragment.

The equation $`` q = s' "$ can either be contained in that part of $\langle prg \rangle$ that results from the application of $d^{codata}$ to the relevant part of $prg$, as specified in the definition of $d''$, or it can be in the other part of $\langle prg \rangle$. As can be seen in the definition of $d''$, this other part is taken over unchanged from $prg$ except for defunctionalizing the right-hand terms. Thus for an equation $`` q = s' "$ from this part, the equation $`` q = s'' "$ with $s' = \langle s'' \rangle$ is present in $prg$. For such an equation, $q$ has hole pattern. It can then be easily seen that $s =^? q \searrow \sigma'$ for a $\sigma'$ with $s''[\sigma'] = t$ by an argument analogous to that of $`` \Rightarrow "$, ``Subst" case, Case 1.

Now, suppose that $`` q = s' "$ is contained in the part of $\langle prg \rangle$ that results from the application of $d^{codata}$ to the relevant part $prg' \subseteq prg$. Thus $\langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle$.

By (*) we would have

\begin{equation*}
\langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle \iff s \longrightarrow_{prg'} t,
\end{equation*}

were $prg'$ a well-typed program with copattern coverage for all subterms of $s$. Both of those properties can be shown or simulated similarly to the way they are in the $`` \Rightarrow "$ part.

But it is $prg' \subseteq prg$, as can be seen in the definition of $d''$. This implies the desired $s \longrightarrow_{prg} t$.

\item \textbf{``Cong" case}:

\begin{prooftree}
\AxiomC{$s' \longrightarrow_{\langle prg \rangle} t'$}
\RightLabel{Cong}
\UnaryInfC{$\mathcal{E}[s'] \longrightarrow \mathcal{E}[t']$}
\end{prooftree}

with $\mathcal{E}[s'] = \langle s \rangle$ and $\mathcal{E}[t'] = \langle t \rangle$.

By the induction hypothesis we have $s'' \longrightarrow_{prg} t''$ with $s' = \langle s'' \rangle$, $t' = \langle t'' \rangle$. Let $\langle \mathcal{E} \rangle$ denote the transformation of $\mathcal{E}$ (defined as in the $`` \Rightarrow "$ part). Apply the congruence rule to get $\mathcal{E}'[s''] \longrightarrow_{prg} \mathcal{E}'[t'']$ with $\mathcal{E} = \langle \mathcal{E}' \rangle$. That is, $\mathcal{E}'$ is the result of applying the inverse of $\langle \cdot \rangle$ to $\mathcal{E}$, which is possible, since, for instance, $\mathcal{E}[s'] = \langle s \rangle$. It is $\langle \mathcal{E}'[s''] \rangle = \langle \mathcal{E}' \rangle[\langle s'' \rangle] = \mathcal{E}[s'] = \langle s \rangle$ and $\langle \mathcal{E}'[t''] \rangle = \langle \mathcal{E}' \rangle[\langle t'' \rangle] = \mathcal{E}[t'] = \langle t \rangle$ and thus we have the desired $s \longrightarrow_{prg} t$.
\end{enumerate}

\end{proof}

\subsection{Core refunctionalization}

This is defined analogously to core defunctionalization, by applying the refunctionalization for the Data Fragment of Uroboro to the not yet refunctionalized parts of the program. It can be applied to these parts because the preprocessing steps guarantee that they are in the Data Fragment. Call the refunctionalization for the Data Fragment of Uroboro $r^{data}$; the core refunctionalization for programs is defined as follows below.

First, a technical note: As $r_{core}$ doesn't allow destructor terms in its inputs, they have to be converted beforehand. This conversion is the same as that of $r$ for terms below, restricted to destructor terms. Call this conversion lifted to programs (in the way that all destructor terms on right-hand sides or as subterms of them are converted) $des\_conv$.

\begin{alignat*}{3}
\langle prg \rangle^{r_{core}} & = ~&& \langle \langle && \{ def \in prg ~ | ~ def \textrm{ is data def. or} \\ & && &&\quad \textrm{ function def. with equations } eqns \neq \emptyset: \forall e \in eqns: e \textrm{ has no destr. pattern}, \\
& && &&\qquad \textrm{the first argument of the lhs isn't a variable } \} \rangle^{des\_conv} \rangle^{r_{core}} \\
& \cup && \{ && \textrm{\textbf{codata }} ... ~ | ~ `` \textrm{\textbf{codata }} ... " \in prg \} \\
& \cup && \{ && \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} \{ p = \langle t, prg \rangle^r ~ | ~ "p = t" \in eqns \} \\
& && | && `` \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} eqns " \in prg \textrm{ with } \forall e \in eqns: e \textrm{ has destr. pattern} \\
& && &&\quad \textrm{or where } n = 0 \textrm{ or where the first argument of the lhs is a variable} \} 
\end{alignat*}

Along with the transformation for programs, a transformation of terms is necessary, which is a conservative extension of $r^{data}$ for programs. For this, write $r$ short for $r_{core}$ \\
$\langle x, prg \rangle^r = x$ \\
$\langle s.des(t_1, ..., t_n), prg \rangle^r = \langle s, prg \rangle^r .des(\langle t_1, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$ \\
$\langle fun(t_1, ..., t_n), prg \rangle^r = fun(\langle t_1, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$, \\
if ``\textbf{function} $fun(\tau_n, ..., \tau_n): \sigma$ \textbf{where} $eqns$" $\in prg$  with $\forall e \in eqns: e$ has destructor pattern or where $n = 0$ or where the first argument of the lhs is a variable \\
$\langle fun(t_1, ..., t_n), prg \rangle^r = \langle t_1, prg \rangle^r .\langle fun, prg \rangle^r (\langle t_2, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$, \\
otherwise \\
$\langle con(t_1, ..., t_n), prg \rangle^r = \langle con, prg \rangle^r (\langle t_1, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$ \\

Note that the case distinction above is only necessary because of the special syntax for destructors ($q(...).des(...)$ instead of $des(..., ...)$).

\subsubsection{Proof of strong bisimulation}

For $r_{core}$, strong bisimulation holds. The proof relies on properties of $r^{data}$. As stated in section 2.3.1, the authors' notion of reducibility is the same than that of this work when restricted to the domain of $r^{data}$, the Data Fragment.

In section 3, Rendel et al. prove Lemma 5, which in terms of this work can be stated as follows (possible since the reducibility notions are identical):

$s \longrightarrow_{prg} t \iff \langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$ for all input terms $s,t$ of $\langle \cdot \rangle$ (*)

Here, the angular brackets can stand for either of their transformations, the refunctionalization $r^{data}$ and the defunctionalization $d^{codata}$. Statement (*) means that strong bisimulation holds for $r^{data}$.

Using (*), it will now be shown that strong bisimulation holds for $r_{core}$.

\begin{proof}[Proof of strong bisimulation for $r_{core}$] ~

$`` \Rightarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$s =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(prg)$}
\UnaryInfC{$s \longrightarrow s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = t$; the immediate subterms of $s$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^r$, $\langle t \rangle = \langle t \rangle^r$. $r$ is the refunctionalization of terms as defined above (it is omitted that $prg$ is passed to $r$ as well). This refunctionalization of terms is also, for all input terms from the fragment, identical to that of the Data Fragment.

\begin{itemize}

\item \underline{Case 1}: $q$ is destructor pattern:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a destructor pattern (other cases are excluded by the relevant input fragment for $r_{core}$). Such equations (and indeed the function definitions) are left unchanged by $r_{core}$ except for refunctionalizing the right-hand term, as can be seen directly in the definition of $r_{core}$ (last set in the highest-level union). Thus Rules($\langle prg \rangle$) contains $(q, \langle s' \rangle)$.

From here, the argument proceeds analogously to that of $`` \Rightarrow "$, ``Subst" case, Case 1, in the proof for $d_{core}$.

\item \underline{Case 2}: $q$ is hole pattern without arguments or where the first argument is a variable:

Then the equation is left unchanged by $r_{core}$ except for refunctionalizing the right-hand term, as can be seen directly in the definition of $r_{core}$ (last set in the highest-level union). Proceed as in Case 1.

\item \underline{Case 3}: $q$ is hole pattern and has a first argument which is a constructor pattern:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a hole pattern (other cases are excluded by the relevant input fragment for $r_{core}$), and it has a first argument with data type. Thus $s$ reduces to $t$ already with respect to the part of the program that is passed to $des\_conv$, and then the result of this to $r^{data}$, as specified in the definition of $r_{core}$. Let the part passed to $des\_conv$ be $prg'$; it is: $s \longrightarrow_{prg'} t$.

By (*) we have

\begin{equation*}
s \longrightarrow_{prg'} t \iff \langle s \rangle \longrightarrow_{\langle prg' \rangle^{r^{data}}} \langle t \rangle,
\end{equation*}

But this program $\langle prg' \rangle^{r^{data}}$ is a subset of $\langle prg \rangle$, as can be seen in the definition of $r_{core}$. Thus we have the desired $\langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$.

\end{itemize}

\item \textbf{``Cong" case}:

The argument here is identical to that of this case of this direction in the proof for $d_{core}$.

\end{enumerate}

$`` \Leftarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$\langle s \rangle =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(\langle prg \rangle)$}
\UnaryInfC{$\langle s \rangle \longrightarrow_{\langle prg \rangle} s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = \langle t \rangle$; the immediate subterms of $\langle s \rangle$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^r$, $\langle t \rangle = \langle t \rangle^r$. $r$ is the refunctionalization of terms defined above. This refunctionalization of terms is also, for all input terms from the fragment, identical to that of the Data Fragment.

The equation $`` q = s' "$ can either be contained in that part of $\langle prg \rangle$ that results from the application of $des\_conv$ and then $r^{data}$ to the relevant part of $prg$, as specified in the definition of $r_{core}$, or it can be in the other part of $\langle prg \rangle$. As can be seen in the definition of $r_{core}$, this other part is taken over unchanged from $prg$ except for refunctionalizing the right-hand terms. Thus for an equation $`` q = s' "$ from this part, the equation $`` q = s'' "$ with $s' = \langle s'' \rangle$ is present in $prg$. For such an equation, $q$ has hole pattern. It can then be easily seen that $s =^? q \searrow \sigma'$ for a $\sigma'$ with $s''[\sigma'] = t$ by an argument analogous to that of $`` \Rightarrow "$, ``Subst" case, Case 1, in the proof for $d_{core}$.

Now, suppose that $`` q = s' "$ is contained in the part of $\langle prg \rangle$ that results from the application of $des\_conv$ and then $r^{data}$ to the relevant part $prg' \subseteq prg$. Thus $\langle s \rangle \longrightarrow_{\langle \langle prg' \rangle^{des\_conv} \rangle^{r^{data}}} \langle t \rangle$.

By (*) we have

\begin{equation*}
\langle s \rangle \longrightarrow_{\langle \langle prg' \rangle^{des\_conv} \rangle^{r^{data}}} \langle t \rangle \iff s \longrightarrow_{\langle prg' \rangle^{des\_conv}} t.
\end{equation*}

In the result of $des\_conv$, no new matching left-hand sides are added. That is, $prg'$ contains at least all the matching left-hand sides that $\langle prg' \rangle^{des\_conv}$ has. Thus any reduction that is possible with respect to $\langle prg' \rangle^{des\_conv}$ is already possible with respect to $prg'$.

But it is $prg' \subseteq prg$, as can be seen in the definition of $r_{core}$. This implies the desired $s \longrightarrow_{prg} t$.
\end{enumerate}

\item \textbf{``Cong" case}:

The argument here is identical to that of this case of this direction in the proof for $d_{core}$.

\end{proof}

%\section{Simplifying copatterns (Alternative approach to de- and refunc.}
%
%Both de- and refunctionalization are made up of two major parts:
%\begin{enumerate}
%\item First, destructor and constructor extractions alternate to transform the program into a form which can be used by the second part.
%
%\item This second part is the core de-/refunctionalization, which is essentially the two-way transformation from the paper of Rendel et al.
%\end{enumerate}
%
%The \textit{simplifying} part of the defunctionalization transformation is made up of destructor and constructor extraction steps and stops when the program is in the input fragment of core defunctionalization, described below. The simplifying part of the refunctionalization transformation is defined like that, with the only difference being that it stops when the program is in the input fragment of core refunctionalization, also described below.
%
%This simplification is done individually for each function definition, the order in which the function definitions are transformed is unimportant. For one function definition $def$, the algorithm is defined below.
%
%\[
%  \langle prg \rangle^{simplify(def)}=\begin{cases}
%               prg, &\text{ if $def$ is in the desired fragment}\\
%               \langle prg \rangle^{simplify\_step(def)} \rangle^{simplify(def)}, &\text{ otherwise}
%            \end{cases}
%\]
%
%\[
%  \langle prg \rangle^{simplify\_step(def)}=\begin{cases}
%               \langle prg \rangle^{liftp(des\_extract(q^{max}_{def}))}, \\
%               \qquad\text{ if } \langle prg \rangle^{liftp(con_{n_{def}}\_extract(q^{max}_{def}))} \text{ has overlaps}\\
%               \langle prg \rangle^{liftp(con_{n_{def}}\_extract(q^{max}_{def}))},\\
%               \qquad\text{ otherwise}
%            \end{cases}
%\]
%
%with
%
%\[
%q^{max}_{def} = \textrm{max}_{\# con.} \textrm{max}_{\# des.} \{q ~ | ~ q \text{ is lhs in $def$ } \}
%\]
%
%and $n_{def}$ the number of the inner-most constructor in $q^{max}_{def}$ which has a variable ``in its place'' in another lhs of $def$. For a pattern $p$ of a copattern $q$ to be ``in the place'' of another pattern $p'$ in another copattern $q'$ means:
%\begin{itemize}
%\item When $p$ is a subterm of the $n$-th pattern immediately under $q$, then $p'$ is a subterm of the $n$-th pattern immediately under $q$,
%
%\item the same for the $m$-th pattern immediately under the $n$-th patterns if $p$ and/or $p'$ aren't the $n$-th patterns themselves,
%
%\item and so on recursively.
%\end{itemize}
%
%As can be seen in the definition of $simplify\_step$, the algorithm switches from destructor to constructor extraction whenever constructor extraction would produce overlapping lhss. This actually prevents overlaps, because, whenever constructor extraction would produce overlaps, destructor extraction doesn't, as will be shown below.
%
%Clearly, this also means that the algorithm eventually arrives at a function definition without any destructors and without any constructors, unless it stops before that, thus ensuring that the desired fragment will be reached in any case.
%
%\subsection{Bisimulation}
%
%Two properties are desired for this algorithm: some kind of bisimulation, and that no overlapping lhss are generated. Since the algorithm is made up only of $des\_extract$ and $con\_extract$ steps, these properties follow from their respective properties.
%
%When overlapping lhss are absent in the transformed program, we have the kind of weak bisimulation as established by Proposition 2.3.1 for both $des\_extract$ and $con\_extract$, irrespective of which lhs is targeted. That overlaps aren't generated by one such step will be shown in the following subsection.
%
%\subsection{Absence of overlaps}
%
%By Proposition 2.4.1, for both $des\_extract$ and $con\_extract$, it suffices to show that $q_\epsilon$ doesn't overlap with unchanged lhss. This doesn't hold for arbitrary targeted lhss; in order to avoid generating overlaps, $simplify\_step$ was defined as above. It is now shown that this definition really prevents overlaps in the resulting program of one such step. As pointed out above, because of the definition of $simplify\_step$, it suffices to show that destructor extraction doesn't produce overlaps whenever constructor extraction does.
%
%When constructor extraction leads to overlaps, ...
