\chapter{Automatic de- and refunctionalization}

%%-- under construction

...

We present an algorithm that defunctionalizes arbitrary Uroboro programs with copattern coverage, and an algorithm that refunctionalizes such programs. Both algorithms are made up of two phases, in order:
\begin{enumerate}
\item Unnesting, and
\item core de-/refunctionalization.
\end{enumerate}

In short, the entire process can be described as follows. By unnesting them as far as necessary, the preprocessing phases brings the lhss of the program to the form accepted by the core de-/refunctionalization, which is essentially the two-way transformation of Rendel et al.

The unnesting is done by a parameterized algorithm $\textsf{Unnest}_i$, where the parameter $i$ can be either $d$ or $r$, standing for defunctionalization and refunctionalization, respectively. The parameter determines when the algorithm may stop, such that its results are legal inputs for de- or refunctionalization. The unnesting algorithm is essentially the copattern unnesting algorithm of Setzer et al., adapted to Uroboro.

We give the intended domain and range for each of the algorithms, all of which are specific fragments of Uroboro. Call the set of all well-typed Uroboro programs with copattern coverage $\mathbf{U}_{cc}$; the other fragments are defined below.
\begin{align*}
& \textsf{Unnest}_i: \mathbf{U}_{cc} \to \mathbf{U}_{cc}[fdef_{un,i}] \text{ for } i \in \{d,r\} \\
& \textsf{CoreDefunc}: \mathbf{U}_{cc}[fdef_{un,d}] \to \mathbf{U}^{defunc}_{cc} \\
& \textsf{CoreRefunc}: \mathbf{U}_{cc}[fdef_{un,r}] \to \mathbf{U}^{refunc}_{cc}
\end{align*}

\begin{definition}[Unnested Fragments for \textsf{CoreDefunc} and \textsf{CoreRefunc}]
The fragments $\mathbf{U}_{cc}[fdef_{un,d}]$, $\mathbf{U}_{cc}[fdef_{un,r}]$, for lhss unnested as far as necessary for \textsf{CoreDefunc} and \textsf{CoreRefunc}, respectively, are induced by the function definition fragments $fdef_{un,d}$ and $fdef_{un,r}$, respectively, both defined below using EBNF rules. For these, the basic EBNF rules from the definition of the syntax of Uroboro are reused.
\begin{align*}
fdef_{un,d} &::= eqn_{nd}^* ~ | ~ eqn_d^* \\
eqn_{nd} &::= fun(x^*).des(y^*) = t \\
eqn_d &::= fun(p^*) = t \\
\end{align*}
\begin{align*}
fdef_{un,r} &::= eqn_{nr}^* ~ | ~ eqn_r^* \\
eqn_r &::= fun(x^*).des(y^*)^* = t \\
eqn_{nr} &::= fun(x^*, con(y^*), z^*) = t \\
\end{align*}
\end{definition}

\begin{definition}[Defunctionalized fragment]
A well-typed Uroboro program is in the defunctionalized fragment $\mathbf{U}^{defunc}_{cc}$ if and only if it contains no codata type definitions.
\end{definition}

\begin{definition}[Refunctionalized fragment]
A well-typed Uroboro program is in the refunctionalized fragment $\mathbf{U}^{refunc}_{cc}$ if and only if it contains no data type definitions.
\end{definition}

For each algorithm it will be shown, in its respective section, that it actually has the range specified above. In total, four important properties will be shown for each algorithm: Termination, correct range, preservation of well-typedness, and preservation of semantics in a (weak) bisimulation.

The rest of the section is organized as follows. The first section describes the unnesting algorithm, shows why the three properties hold, and gives applies it to an example. Section 2 and 3 do the same for the unmixing algorithm, and core de-/refunctionalization, respectively.

\section{Unnesting}

We adapt the translation algorithm from section 3.3 of the paper of Setzer et al. to Uroboro. Their algorithm translates equations step-by-step depending upon the derivation of the copattern coverage of their lhss. Our adaptation only has steps which concern patterns that have a counterpart in Uroboro\footnote{I.e., not those for applications, units, and pairs. In the adapted algorithm for Uroboro, the last one is merged into the steps for destructors and constructors, while the others are irrelevant because Uroboro doesn't have the corresponding higher-order constructs.}. Each such translation step can be considered an extraction as defined in chapter 3.

\subsection{Simple patterns}

Before we start with the translation algorithm, we adapt and introduce, respectively, two notions of simplicity for patterns, the second of which corresponds to the intended range of the translation algorithm. We first adapt the definition of a \textit{simple pattern}, as given by Setzer et al., to Uroboro. Call a copattern simple if it is of one of the three forms $fun(\overline{x})$, $fun(\overline{x}).des(\overline{y})$, or $fun(\overline{x}, con(\overline{y}), \overline{z})$.

Next, we generalize this definition to define \textit{sufficiently simple patterns} for a purpose, which is either de- or refunctionalization. Call a copattern \textit{sufficiently simple for defunctionalization} if it is of one of the two forms $fun(\overline{x}).des(\overline{y})$, $fun(\overline{p})$, and \textit{sufficiently simple for refunctionalization} if it is of one of the two forms $fun(\overline{x}).\overline{des(\overline{y})}$, $fun(\overline{x}, con(\overline{y}), \overline{z})$. We will also say that a copattern is sufficiently simple for $i$, for $i \in \{d,r\}$, and mean that it is sufficiently simple for defunctionalization or refunctionalization, respectively.

Those notions correspond directly to the forms of lhss allowed in the unnested fragments for \textsf{CoreDefunc} and \textsf{CoreRefunc}, respectively. It is clear that each simple copattern is also sufficiently simple for both de- and refunctionalization.

\subsection{Translation algorithm}

We describe the algorithm for $\textsf{Unnest}_i$, adapted from section 3.3 of the paper of Setzer et al. to Uroboro, as lined out above.

\begin{algorithm}[$\textsf{Unnest}_i$]

Like Setzer et al., we consider the last step in the derivation of the copattern coverage for the lhss of a function definition. Just like them, we are not interested in the case where the last step is C\textsubscript{Head}, since that means the lhs is already simple, and we terminate. When the last step isn't C\textsubscript{Head}, but the lhss are all sufficiently simple for $i$ nonetheless, we also terminate.

\begin{prooftree}
\AxiomC{$fun \lhd | ~ Q ~ (q)$}
\RightLabel{\textbf{C}}
\UnaryInfC{$fun \lhd | ~ Q ~ (q_i)_{i \in I}$}
\end{prooftree}

Also like Setzer et al., we then introduce a fresh auxiliary function and translate the program depending on \textbf{C}. As stated before, these translations are slightly adapted to fit the framework of Uroboro, such that two remain, one for destructors and one for constructors. More importantly, both of those are in fact extractions as defined in chapter 3, namely destructor and constructor extraction. 

\begin{enumerate}
\item \textbf{C} is C\textsubscript{Des}, and the last derivation step looks as follows.

\begin{prooftree}
\AxiomC{$fun \lhd | ~ Q ~ (q^\tau)$}
\RightLabel{C\textsubscript{Des}}
\UnaryInfC{$fun \lhd | ~ Q ~ (q.des(\overline{x^{des}}))_{des \in Dess_\tau}$}
\end{prooftree}

Apply extraction \textsf{ExtractDes} targeting the equations with lhss $q.des(\overline{x^{des}})$, for all $des \in Dess_\tau$, to the function definition for $fun$. From this we obtain the changed function definition $def'_{fun}$ for $fun$ and the auxiliary function definition. The lhss of $def'_{fun}$ are
\[
Q \cup \{ \texttt{get}(q.des(\overline{x^{des}})) ~ | ~ des \in Dess_\tau \} = Q \cup \{q\},
\]
where \texttt{get} is the retrieving part of the lens underlying \textsf{ExtractDes}. This set of lhss is the same as that in $fun \lhd | ~ Q ~ (q^\tau)$ from the derivation step above. The lhss of the auxiliary function definition are
\begin{multline*}
\{ q_{\zeta_r} ~ | ~ r \in T \} = \{ \texttt{putback}(\langle \texttt{get}(q_r) \rangle^{aux}, q_r) ~ | ~ r \in T \} \\
= \{ \sigma^{q_r}_\pi(aux(\langle q \rangle^{vars})) ~ | ~ r \in T \} = \{ aux(\langle q \rangle^{vars}).des(\overline{x^{des}}) ~ | ~ des \in Dess_\tau \} \\
= \{ aux(\langle q \rangle^{vars}).des(\overline{x^{des}}) ~ | ~ des \in Dess_\tau \},
\end{multline*}
where $\zeta$ is the function in the triple that is \textsf{ExtractCon}(p). It is clear that each $q_{\zeta_r}$ is simple and that $\{ q_{\zeta_r} ~ | ~ r \in T \}$ covers $aux$:
\begin{prooftree}
\AxiomC{}
\RightLabel{C\textsubscript{Head}}
\UnaryInfC{$aux \lhd | ~ aux(x, \overline{y})$}
\RightLabel{C\textsubscript{ResSplit}}
\UnaryInfC{$aux \lhd | ~ (q_{\zeta_r})_{r \in T}$}
\end{prooftree}

\item \textbf{C} is C\textsubscript{Con}, and the last derivation step looks as follows. 

\begin{prooftree}
\AxiomC{$fun \lhd | ~ Q ~ (q(x^\tau))$}
\RightLabel{C\textsubscript{Con}}
\UnaryInfC{$fun \lhd | ~ Q ~ (q[x := con(\overline{y^{con}})])_{con \in Cons_\tau}$}
\end{prooftree}

Let $p$ be the position of $x$ in $q$. Apply extraction \textsf{ExtractCon}(p) targeting the equations with lhss $q[x := con(\overline{y^{con}})]$, for all $con \in Cons_\tau$ to the original function definition for $fun$. From this we obtain the changed function definition $def'_{fun}$ for $fun$ and the auxiliary function definition. The lhss of $def'_{fun}$ are
\[
Q \cup \{ \texttt{get}(q[x := con(\overline{y^{con}})]) ~ | ~ con \in Cons_\tau \} = Q \cup \{q\},
\]
where the pair of \texttt{get} and \texttt{putback} is the lens underlying \textsf{ExtractCon}(p). This set of lhss is the same as that in $fun \lhd | ~ Q ~ (q)$ from the derivation step above. The lhss of the auxiliary function definition are
\begin{multline*}
\{ q_{\zeta_r} ~ | ~ r \in T \} = \{ \texttt{putback}(\langle \texttt{get}(q_r) \rangle^{aux}, q_r) ~ | ~ r \in T \} \\
= \{ \sigma^{q_r}_\pi(aux(\langle q \rangle^{vars})) ~ | ~ r \in T \} = \{ aux(\langle q \rangle^{vars})[x := con(\overline{y^{con}})] ~ | ~ con \in Cons_\tau \} \\
= \{ aux(x, \langle q_r \rangle^{vars})[x := con(\overline{y^{con}})] \text{ for some } r \in T ~ | ~ con \in Cons_\tau \},
\end{multline*}
where $\zeta$ is the function in the triple that is \textsf{ExtractCon}(p). It is clear that each $q_{\zeta_r}$ is simple and that $\{ q_{\zeta_r} ~ | ~ r \in T \}$ covers $aux$:
\begin{prooftree}
\AxiomC{}
\RightLabel{C\textsubscript{Head}}
\UnaryInfC{$aux \lhd | ~ aux(x, \overline{y})$}
\RightLabel{C\textsubscript{VarSplit}}
\UnaryInfC{$aux \lhd | ~ (q_{\zeta_r})_{r \in T}$}
\end{prooftree}
\end{enumerate}

As shown for each of the two cases, after the extractions copattern coverage still holds for the translated program, and we even know its derivation tree. Thus we can go back to the start and do further translations, if necessary.
\end{algorithm}

Next, we consider important properties of the translation algorithm.

\textbf{Range.} The algorithm only stops when all lhss are sufficiently simple for $i$ and works on the coverage derivation trees, thus we have the desired range $\mathbf{U}_{cc}[fdef_{un,i}]$ if it terminates in all cases, which is shown next.

\textbf{Termination.} To show that the algorithm terminates, we can basically repeat the argument of Setzer et al. Each translation results in a changed function definition $def'_{fun}$ for $fun$ and a new function definition $def_{aux}$ for the auxiliary function. The lhss of $def'_{fun}$ are $Q \cup \{q\}$, which means that they cover $fun$ in the same way $fun$ is covered via $fun \lhd | ~ Q ~ (q)$ in the derivation step above. This means that the translation reduces the depth of the derivation tree for the coverage of $fun$, thus eventually arriving at sufficiently simple patterns. The added auxiliary function definitions already have simple lhss, thus they are not translated, and eventually the algorithm terminates.

\textbf{Bisimulation.} Because copattern coverage holds for the translated program, the translated program has no overlapping lhss. Therefore, by the propositions 3.3.1 and 3.3.2, we know that the translation preserves the semantics of the program in the kind of weak bisimulation described in section 3.3.

\subsection{Example}

As an example application of the algorithm, consider the following program fragment.

\begin{lstlisting}

fun(x).des().des1(con1()) = t1
fun(x).des().des1(con2()) = t2
fun(x).des().des2() = t3

\end{lstlisting}

The final step in the coverage derivation for $fun$ is splitting \texttt{fun(x).des().des1(y)} into \texttt{fun(x).des().des1(con1())} and \texttt{fun(x).des().des1(con2())} by splitting variable $y$. Therefore we first target these two lhss for constructor extraction at the common position of \texttt{con1()} and \texttt{con2()} in the two lhss; the result of the extraction can be seen below.

\begin{lstlisting}

fun(x).des().des1(y) = aux(y, x)
fun(x).des().des2() = t3

aux(con1(), x) = t1
aux(con2(), x) = t2

\end{lstlisting}

For this program, the final step in the coverage derivation for $fun$ is splitting \texttt{fun(x).des()} into \texttt{fun(x).des().des1(y)} and \texttt{fun(x).des().des2()} by result splitting. Therefore we target these two lhss for destructor extraction; the result of the extraction can be seen below. Note that \texttt{fun(x).des() = aux2(x)} is generated twice but only present once in the function definition, as these are sets.

\begin{lstlisting}

fun(x).des() = aux2(x)

aux2(x).des1(y) = aux(y, x)
aux2(x).des2() = t3

\end{lstlisting}

The \texttt{aux} function definition remains unchanged and is omitted. This program is in the desired fragment; the algorithm terminates here because all lhss of the program are simple.

\section{Core de-/refunctionalization}

...

\textsf{CoreDefunc} and \textsf{CoreRefunc} use -- and in fact essentially are -- the respective sides of the two-way transformation of Rendel et al. One side of this is the defunctionalization for the Codata Fragment, which we call $d^{codata}$ in here, and the other side is the refunctionalization for the Data Fragment, which we call $r^{data}$. Their definitions are repeated below for the convenience of the reader.

...

\subsection{Core defunctionalization}

The core defunctionalization \textsf{CoreDefunc} applies the defunctionalization of Rendel et al. for the Codata Fragment to the parts of the program that are in this fragment, and leaves the rest, which is already in a defunctionalized form after \textsf{Unnest}, virtually unchanged. That is, the only change to these parts affects the right-hand sides of equations, which are transformed to account for the syntactic differences between function and destructor calls.\footnote{I.e., the difference between $fun(...)$ and $t.des(...)$. This difference vanishes when changing the syntax of destructor calls to $des(t, ...)$.} The respective transformation for terms is $d$, defined below with the algorithm.

First, we define the class of function definitions of a program $prg$ which are already defunctionalized. A function definition is already defunctionalized when all of its equations have lhss without destructors. We define the class of already defunctionalized functions $F^{prg}_d$ as those which have already defunctionalized function definitions.

Using this definition, we define defunctionalization of terms.

\begin{align*}
\langle x \rangle^d = x \\
\langle s.des(t_1, ..., t_n) \rangle^d = \langle des \rangle^d (\langle s \rangle^d, \langle t_1 \rangle^d, ..., \langle t_n \rangle^d) \\
\langle fun(t_1, ..., t_n) \rangle^d = fun(\langle t_1 \rangle^d, ..., \langle t_n \rangle^d), \text{ if } fun \in F_d \\
\langle fun(t_1, ..., t_n) \rangle^d = \langle fun \rangle^d (\langle t_1 \rangle^d, ..., \langle t_n \rangle^d), \text{ if } fun \not\in F_d \\
\langle con(t_1, ..., t_n) \rangle^d = con(\langle t_1 \rangle^d, ..., \langle t_n \rangle^d)
\end{align*}

This transformation only changes symbols, but leaves the structure of the terms unchanged (disregarding the syntactic sugar for destructor calls). Especially, this means that $\langle q[\sigma] \rangle^d = \langle q \rangle^d [\langle \cdot \rangle^d \circ \sigma]$ for any copattern $q$ and substitution $\sigma$. A property that is important for the definition of \textsf{CoreRefunc} below is that, for any copattern $q$ that is allowed as a lhs in the domain of \textsf{CoreRefunc}, $\langle q \rangle^d$ is also a copattern. This can be easily shown by induction on the structure of $q$.

Next, we give the definition for \textsf{CoreDefunc}. Like Rendel et al. do for their de- and refunctionalization, we use set-builder notation.

\begin{algorithm}[\textsf{CoreDefunc}]

\begin{align*}
\langle prg \rangle^{\textsf{CoreDefunc}} & = ~&& \{ && \textrm{\textbf{data }} \sigma \textrm{\textbf{ where }} \span\span\span\span \\
& && && && \{ \langle fun \rangle^d (\tau_1, ..., \tau_n): \sigma ~ | ~ `` fun(\tau_1, ..., \tau_n): \tau " \in prg \text{ s.t. } fun \not\in F^{prg}_d \} \\
& && | && `` \textrm{\textbf{codata }} \sigma ... " \in prg \} \span\span\span\span \\
& \cup && \{ && \textrm{\textbf{function }} \langle des \rangle^d (\sigma, \tau_1, ..., \tau_n) \textrm{\textbf{ where}} \span\span\span\span \\
& && && && \{ \langle des \rangle^d (\langle fun \rangle^d (\overline{x}), \overline{y}) = \langle t \rangle^d ~ | ~ `` fun(\overline{x}).des(\overline{y}) = t " \in prg \} \\
& && | && `` \sigma.des(\tau_1, ..., \tau_n) " \in prg \} \span\span\span\span \\
& \cup && \{ && \textrm{\textbf{data }} ... ~ | ~ `` \textrm{\textbf{data }} ... " \in prg \} \span\span\span\span \\
& \cup && \{ && \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} \{ q = \langle t \rangle^d ~ | ~ "q = t" \in eqns \} \span\span\span\span \\
& && | && `` \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} eqns " \text{ s.t. } fun \in F^{prg}_d \} \span\span\span\span
\end{align*}

\end{algorithm}

We consider important properties of the transformation.

\textbf{Bisimulation.} For \textsf{CoreDefunc}, strong bisimulation holds. To show this, we first show a general result that an isomorphism between rule sets of two programs is also an isomorphism between the respective reduction relations of the programs. In the following, $\langle \cdot \rangle$ is some program transformation when applied to programs. When applied to terms it stands for some transformation of terms that only changes symbols, but leaves the structure of the terms unchanged.

\begin{lemma}[Rules isomorphism is reduction isomorphism]
\label{lem:iso}
For any program $prg$, when it is
\[
\forall s,t \in \textrm{Term}_{prg}. (s, t) \in \textrm{Rules}(prg) \iff (\langle s \rangle, \langle t \rangle) \in \textrm{Rules}(prg).
\]
, then it also holds that
\[
\forall s,t \in \textrm{Term}_{prg}. s \longrightarrow_{prg} t \iff \langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle.
\]
\end{lemma}

In order to prove this, we first show some auxiliary lemmas concerning the value judgement and evaluation contexts.

\begin{lemma}[Isomorphic value judgements]
For any program $prg$, when it is
\[
\forall s,t \in \textrm{Term}_{prg}. (s, t) \in \textrm{Rules}(prg) \iff (\langle s \rangle, \langle t \rangle) \in \textrm{Rules}(prg).
\]
, then it also holds that
\label{lem:ivj}
\[
\forall t \in \textrm{Term}_{prg}. \vdash_{v_{prg}} t \iff \vdash_{v_{\langle prg \rangle}} \langle t \rangle
\]
\begin{proof}
$``\Rightarrow"$: By induction on the structure of $t$. By the derivation of $\vdash_{v_{prg}} t$ it is (a) $\vdash_{v_{prg}} t_i$ for all immediate subterms $t_i$ of $t$ and (b) $t \neq^? q$ for all lhss $q$ of rules of $prg$. By the premiss we know that for all lhss $q'$ of rules of $\langle prg \rangle$, there is a lhs $q$ of $prg$ such that $q' = \langle q \rangle$; thus it is $\langle t \rangle \neq^? q'$ for all lhss $q'$ of rules of $\langle prg \rangle$. By the induction hypothesis, we know that $\vdash_{v_{\langle prg \rangle}} \langle t_i \rangle$. Since the immediate subterms of $\langle t \rangle^d$ are the $\langle t_i \rangle$ for each $t_i$, we have the derivation for $\vdash_{v_{\langle prg \rangle}} \langle t \rangle$.

$``\Leftarrow"$: By induction on the structure of $t$. By the derivation of $\vdash_{v_{\langle prg \rangle}} t$ it is (a) $\vdash_{v_{\langle prg \rangle}} t'_i$ for all immediate subterms $t'_i$ of $\langle t \rangle$ and (b) $\langle t \rangle \neq^? q'$ for all lhss $q'$ of rules of $\langle prg \rangle$. By the premiss we know that for all lhss $q$ of rules of $prg$, there is a lhs $\langle q \rangle$ of $\langle prg \rangle$; thus it is $t \neq^? q$ for all lhss $q$ of rules of $prg$. By the induction hypothesis, since it is $\langle t_i \rangle = t'_i$ for each immediate subterm $t_i$ of $t$, we know that $\vdash_{v_{prg}} t_i$. All in all, we have the derivation for $\vdash_{v_{prg}} t$.
\end{proof}
\end{lemma}

\begin{lemma}[Isomorphic evaluation contexts]
\label{lem:iec}
For any program $prg$, when it is
\[
\forall s,t \in \textrm{Term}_{prg}. (s, t) \in \textrm{Rules}(prg) \iff (\langle s \rangle, \langle t \rangle) \in \textrm{Rules}(prg).
\]
, then it also holds that
\[
\forall \mathcal{E}. \mathcal{E} \in \textrm{EC}_{prg} \iff \langle \mathcal{E} \rangle \in \textrm{EC}_{\langle prg \rangle}
\]
\begin{proof}
$``\Rightarrow"$: By induction on the structure of $\mathcal{E}$. $\mathcal{E}$ has a corresponding generic evaluation context $\mathcal{GE}$ and a placeholder order $<$ such that there is a placeholder $p$ that is replaced by an evaluation context $\mathcal{E}'$ for $prg$ in $\mathcal{E}$, and that all placeholders $< p$ are replaced in $\mathcal{E}$ by values, i.e., terms $v$ with $\vdash_{v_{prg}} v$. By \autoref{lem:ivj}, for each such $v$ it is $\vdash_{v_{\langle prg \rangle}} \langle v \rangle$, and by the induction hypothesis $\langle \mathcal{E}' \rangle$ is an evaluation context for $prg$. Consequent, we can construct an evaluation context starting with $\langle \mathcal{GE} \rangle$ as follows: In this g.e.c., replace all placeholders $< p$ with the respective $\langle v \rangle$, replace $p$ with $\langle \mathcal{E}' \rangle$, and replace all placeholders $> p$ with the respective terms from $\mathcal{E}$. The result is the desired $\langle \mathcal{E} \rangle$.

$``\Leftarrow"$: Analogously to $``\Rightarrow"$.
\end{proof}
\end{lemma}

Next, we show that \autoref{lem:iso} holds restricted to contraction, from which the full \autoref{lem:iso} directly follows.

\begin{lemma}[Rules isomorphism is contraction isomorphism]
\label{lem:isoc}
For any program $prg$, when it is
\[
\forall s,t \in \textrm{Term}_{prg}. (s, t) \in \textrm{Rules}(prg) \iff (\langle s \rangle, \langle t \rangle) \in \textrm{Rules}(prg).
\]
, then it also holds that
\[
\forall s,t \in \textrm{Term}_{prg}. s \mapsto_{prg} t \iff \langle s \rangle \mapsto_{\langle prg \rangle} \langle t \rangle.
\]
\begin{proof}
$``\Rightarrow"$: By the derivation of $s \mapsto_{prg} t$ there is a rule $r := (q_r, t_r) \in \textrm{Rules}(prg)$ and a substitution $\sigma$ such that $s = q_r[\sigma]$ and $t = t_r[\sigma]$ and the right-hand sides of $\sigma$ are values in $prg$. By the premiss we know that there is a rule $\langle r \rangle := (\langle q_r \rangle, \langle t_r \rangle) \in \textrm{Rules}(prg)$, and by \autoref{lem:ivj} we know that, for each term $v$ that is a value in $prg$, $\langle v \rangle$ is a value in $\langle prg \rangle$ and thus the right-hand sides of $\sigma \circ \langle \cdot \rangle$ are values in $\langle prg \rangle$. Consequently, it is $\langle s \rangle = \langle q_r \rangle[\sigma \circ \langle \cdot \rangle] \mapsto \langle t_r \rangle[\sigma \circ \langle \cdot \rangle] = \langle t \rangle$.

$``\Leftarrow"$: By the derivation of $\langle s \rangle \mapsto_{prg} \langle t \rangle$ there is a rule $r' := (q_{r'}, t_{r'}) \in \textrm{Rules}(\langle prg \rangle)$ and a substitution $\sigma'$ such that $\langle s \rangle = q_{r'}[\sigma']$ and $\langle t \rangle = t_{r'}[\sigma']$ and the right-hand sides of $\sigma'$ are values in $prg$. By the premiss we know that there is a rule $r  := (q_r, t_r) \in \textrm{Rules}(prg)$ such that $\langle q_r \rangle = q_{r'}, \langle t_r \rangle = t_{r'}$, and by \autoref{lem:ivj} we know that, for each term $v'$ that is a value in $\langle prg \rangle$, each term $v$ with $v' = \langle v \rangle$ is a value in $prg$ and thus the right-hand sides of $\sigma$ with $\sigma' = \sigma \circ \langle \cdot \rangle$ are values in $prg$. Consequently, it is $s = q_r[\sigma] \mapsto t_r[\sigma] = t$.
\end{proof}
\end{lemma}

\begin{proof}[Proof of \autoref{lem:iso}]
$``\Rightarrow"$: By the derivation of $s \longrightarrow_{prg} t$ there are terms $s', t'$ and an evaluation context $\mathcal{E}$ for $prg$ such that $s = \mathcal{E}[s'], t = \mathcal{E}[t']$ and $s' \mapsto_{prg} t'$. By \autoref{lem:iec} and \autoref{lem:isoc} we know that $\langle \mathcal{E} \rangle$ is an evaluation context for $\langle prg \rangle$ and that $\langle s' \rangle \mapsto_{\langle prg \rangle} \langle t' \rangle^d$, respectively. Consequently, it is $\langle s \rangle = \langle \mathcal{E} \rangle [\langle s' \rangle] \longrightarrow_{\langle prg \rangle} \langle \mathcal{E} \rangle [\langle t' \rangle] = \langle t \rangle$.

$``\Leftarrow"$: By the derivation of $\langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$ there are terms $\langle s' \rangle, \langle t' \rangle$ and an evaluation context $\langle \mathcal{E} \rangle$ for $prg$ such that $\langle s \rangle = \langle \mathcal{E} \rangle[\langle s' \rangle], \langle t \rangle = \langle \mathcal{E} \rangle [\langle t' \rangle]$ and $\langle s' \rangle \mapsto_{\langle prg \rangle} \langle t' \rangle$. By \autoref{lem:iec} and \autoref{lem:isoc} we know that $\mathcal{E}$ is an evaluation context for $prg$ and that $s' \mapsto_{prg} t'$, respectively. Consequently, it is $s = \mathcal{E}[s'] \longrightarrow_{prg} \mathcal{E}[t'] = t$.
\end{proof}

Using \autoref{lem:iso}, we finally prove strong bisimulation for \textsf{CoreDefunc}, by showing that the premiss of the lemma holds.

\begin{lemma}[Strong bisimulation of the rule relations]
\label{lem:sbruld}
\[
\forall s,t \in \textrm{Term}_{prg}. (s, t) \in \textrm{Rules}(prg) \iff (\langle s \rangle^d, \langle t \rangle^d) \in \textrm{Rules}(\langle prg \rangle^{\textsf{CoreDefunc}}).
\]
\begin{proof}
By inspecting the definition of \textsf{CoreDefunc}, it can be easily seen that for each rule $(s, t) \in \textrm{Rules}(prg)$, there is a rule $(\langle s \rangle^d, \langle t \rangle^d) \in \textrm{Rules}(\langle prg \rangle^{\textsf{CoreDefunc}})$, and that there are no other rules in $\textrm{Rules}(\langle prg \rangle^{\textsf{CoreDefunc}})$.
\end{proof}
\end{lemma}

\begin{corollary}[Strong bisimulation of \textsf{CoreDefunc}]
\[
\forall s,t \in \textrm{Term}_{prg}. s \longrightarrow_{prg} t \iff \langle s \rangle^d \longrightarrow_{\langle prg \rangle^{\textsf{CoreDefunc}}} \langle t \rangle^d.
\]
\begin{proof}
By combining \autoref{lem:sbruld} and \autoref{lem:iso}.
\end{proof}
\end{corollary}

\subsection{Core refunctionalization}

Core refunctionalization is defined analogously to core defunctionalization, with the exception of needing one more preprocessing, described below. The actual algorithm applies the refunctionalization of Rendel et al. for the Data Fragment to the parts of the program that are in this fragment, and leaves the rest, which is already in a refunctionalized form after \textsf{Unnest}, virtually unchanged. 

\textbf{Preprocessing } Before we give the actual algorithm, as stated above, one more preprocessing is necessary. We first explain the reason for it. The actual algorithm given below has a domain slightly different from that given in the introduction. The difference is that it doesn't suffice that at most one constructor appears in lhss, this constructor also needs to be at the correct place, that is, at the leftmost position. In symbols, the lhss need to have one of the two forms $fun(\overline{x}).des(\overline{y})$ and $fun(con(\overline{x}), \overline{y})$, it doesn't suffice to be of the form $fun(\overline{x}, con(\overline{y}), \overline{z})$. The fragment $\mathbf{U}_cc[fdef_{un,r'}]$ of Uroboro that is the domain for the actual \textsf{CoreRefunc} is induced by the following syntax for function definitions:
\begin{align*}
fdef_{un,r} &::= eqn_{nr}^* ~ | ~ eqn_r^* \\
eqn_r &::= fun(x^*).des(y^*)^* = t \\
eqn_{nr} &::= fun(con(x^*), z^*) = t \\
\end{align*}
Now, we briefly outline the preprocessing. To get from the original input fragment for refunctionalization, $\mathbf{U}_{cc}[fdef_{un,r}]$, to $\mathbf{U}_{cc}[fdef_{un,r'}]$, simply
\begin{itemize}
\item reorder the arguments in the signature and in the lhss of the function definitions which don't have the desired form yet, bringing the constructors in front, and
\item change calls to the function accordingly.
\end{itemize}
As an example, consider the program fragment below.
\begin{lstlisting}

function f(T, T) where
  f(x, c1()) = t1
  f(x, c2()) = t2

function g() where
  g() = f(c1(), c2())

\end{lstlisting}
By the preprocessing, the arguments of \texttt{f} are reordered such that the constructors are in front, resulting in the program fragment below.
\begin{lstlisting}

function f(T, T) where
  f(c1(), x) = t1
  f(c2(), x) = t2

function g() where
  g() = f(c2(), c1())

\end{lstlisting}
It is clear that this preprocessing doesn't affect the semantics of the program in a disruptive way, i.e., reductions might be carried out in a different order.

Now, we turn to the actual algorithm, with domain $\mathbf{U}_{cc}[fdef_{un,r'}]$.

First, we define the class of function definitions of a program $prg$ which are already refunctionalized. A function definition is already refunctionalized when (a) all of its equations have destructor patterns, or (b) the function has no arguments, or (c) the first argument of every lhs is a variable. We define the class of already refunctionalized functions $F^{prg}_r$ as those which have already defunctionalized function definitions.

Using this definition, we define refunctionalization of terms.

\begin{align*}
\langle x \rangle^r = x \\
\langle s.des(t_1, ..., t_n) \rangle^r = \langle s \rangle^r .des(\langle t_1 \rangle^r, ..., \langle t_n \rangle^r) \\
\langle fun(t_1, ..., t_n) \rangle^r = fun(\langle t_1 \rangle^r, ..., \langle t_n \rangle^r), \text{ if } fun \in F_r \\
\langle fun(t_1, ..., t_n) \rangle^r = \langle t_1 \rangle^r .\langle fun \rangle^r (\langle t_2 \rangle^r, ..., \langle t_n \rangle^r), \text{ if } fun \not\in F_r \\
\langle con(t_1, ..., t_n) \rangle^r = \langle con \rangle^r (\langle t_1 \rangle^r, ..., \langle t_n \rangle^r)
\end{align*}

Next, we give the definition for \textsf{CoreRefunc}.

\begin{algorithm}[\textsf{CoreRefunc}]

\begin{align*}
\langle prg \rangle^{\textsf{CoreDefunc}} & = ~&& \{ && \textrm{\textbf{codata }} \sigma \textrm{\textbf{ where }} \span\span\span\span \\
& && && && \{ \sigma.\langle fun \rangle^d (\tau_1, ..., \tau_n): \tau ~ | ~ `` fun(\sigma, \tau_1, ..., \tau_n): \tau " \in prg \text{ s.t. } fun \not\in F^{prg}_d \} \\
& && | && `` \textrm{\textbf{data }} \sigma ... " \in prg \} \span\span\span\span \\
& \cup && \{ && \textrm{\textbf{function }} \langle con \rangle^r (\tau_1, ..., \tau_n): \tau \textrm{\textbf{ where}} \span\span\span\span \\
& && && && \{ \langle con \rangle^r (\langle fun \rangle^d (\overline{x}), \overline{y}) = \langle t \rangle^d ~ | ~ `` fun(con(\overline{x}), \overline{y}) = t " \in prg \} \\
& && | && `` con(\tau_1, ..., \tau_n): \tau " \in prg \} \span\span\span\span \\
& \cup && \{ && \textrm{\textbf{codata }} ... ~ | ~ `` \textrm{\textbf{codata }} ... " \in prg \} \span\span\span\span \\
& \cup && \{ && \textrm{\textbf{function }} fun(\tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} \{ q = \langle t \rangle^r ~ | ~ "q = t" \in eqns \} \span\span\span\span \\
& && | && `` \textrm{\textbf{function }} fun(\tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} eqns " \text{ s.t. } fun \in F^{prg}_r \} \span\span\span\span
\end{align*}

\end{algorithm}

We consider important properties of the transformation.

\textbf{Bisimulation.} For \textsf{CoreRefunc}, strong bisimulation holds. The proof relies on properties of $r^{data}$. In the ``Bisimulation'' part of the previous subsection, we already outlined the main points: The domain of $r^{data}$ is the Data Fragment, and Rendel et al.s reduction relation for this fragment is the same as ours restricted to this fragment. In section 3 of their paper, Rendel et al. prove Lemma 5, which we have restated as Lemma 4.2.1. Using this, we prove strong bisimulation for \textsf{CoreRefunc}.

\begin{lemma}[Strong bisimulation for \textsf{CoreRefunc}]
\[
s \longrightarrow_{prg} t \iff \langle s \rangle^r \longrightarrow_{\langle prg \rangle^{\textsf{CoreRefunc}}} \langle t \rangle^r
\]

\begin{proof}
For the sake of this proof, we will neglect the syntactic differences between destructor and function calls. By the definition of \textsf{CoreRefunc}, it is
\[
\langle prg \rangle^{\textsf{CoreRefunc}} = \langle prg' \rangle^{r^{data}} \cup prg''
\]
such that $prg' \cup prg'' = prg$. By Lemma 4.2.1, the reduction relations pertaining to the programs $prg'$ and $\langle prg' \rangle^{r^{data}}$ are one and the same. The reduction relation pertaining to $prg$ is that of $prg'$ changed according to the equations of $prg''$, and the reduction relation pertaining to $\langle prg \rangle^{\textsf{CoreRefunc}}$ is also that of $prg'$ changed according to the equations of $prg''$. Thus these reduction relations are the same, which is equivalent to the statement of this lemma.
\end{proof}
\end{lemma}

\subsection{Example}

We continue with the example fragment of section 4.1.3, augmented with (co)data definitions and signatures.

\begin{lstlisting}

data P where
  con1(): P
  con2(): P

codata N1 where
  N1.des(): N2

codata N2 where
  N2.des1(P): P
  N2.des2(): P

function fun(N1): N1 where
  fun(x).des() = aux2(x)

function aux(P, N1): P where
  aux(con1(), x) = t1
  aux(con2(), x) = t2

function aux2(N1): N2 where
  aux2(x).des1(y) = aux(y, x)
  aux2(x).des2() = t3

\end{lstlisting}

Using the \textsf{CoreDefunc} algorithm on this yields the following program, by leaving the function definition for \texttt{aux} and the data definition unchanged, and applying the defunctionalization of Rendel et al. to the other definitions.

\begin{lstlisting}

data P where
  con1(): P
  con2(): P

data N1 where
  fun(N1): N1

data N2 where
  aux2(N1): N2

function aux(P, N1): P where
  aux(con1(), x) = t1
  aux(con2(), x) = t2

function des(N1): N2 where
  des(fun(x)) = aux2(x)

function des1(N2, P): P where
  des1(aux2(x), y) = aux(y, x)

function des2(N2): P where
  des2(aux2(x)) = t3

\end{lstlisting}

Using the \textsf{CoreRefunc} algorithm on the original program yields the following program, by leaving the function definitions for \texttt{fun} and \texttt{aux2} and the codata definitions unchanged, and applying the refunctionalization of Rendel et al. to the other definitions.

\begin{lstlisting}

codata P where
  P.aux(N1): P

codata N1 where
  N1.des(): N2

codata N2 where
  N2.des1(P): P
  N2.des2(): P

function fun(N1): N1 where
  fun(x).des() = aux2(x)

function aux2(N1): N2 where
  aux2(x).des1(y) = aux(y, x)
  aux2(x).des2() = t3

function con1() where
  con1().aux(x) = t1

function con2() where
  con2().aux(x) = t2

\end{lstlisting}

%%-- end under construction