\chapter{Automatic de- and refunctionalization}

...

Both de- and refunctionalization are made up of a couple of preprocessing steps, followed by the core de-/refunctionalization, which is essentially the two-way transformation from the paper of Rendel et al. Here, we give an overview of these steps for both transformations. In brackets, we name the step; this name will be used throughout the chapter. What can already be seen here is that steps $unmix$ and $elim\_cons\_from\_des$ are used for both transformations.

Automatic defunctionalization consists of the following steps:
\begin{enumerate}
\item Eliminate multiple destructors. ($elim\_multi\_des_d$)

\item Unmix function definitions. ($unmix$)

\item Eliminate constructors from destructor copatterns. ($elim\_cons\_from\_des$)

\item Core defunctionalization. ($d_{core}$)

\end{enumerate}

Automatic refunctionalization consists of the following steps:
\begin{enumerate}
\item Eliminate multiple destructors from copatterns containing constructors. ($elim\_multi\_des_r$)

\item Unmix function definitions. ($unmix$)

\item Eliminate constructors from destructor copatterns. ($elim\_cons\_from\_des$)

\item Eliminate multiple constructors. ($elim\_multi\_con$)

\item Core refunctionalization. ($r_{core}$)

\end{enumerate}

Both de- and refunctionalization require that all lhss of the program that is to be transformed are \textit{aligned}. We introduce this notion in the following section; an algorithm to achieve alignment can be found in appendix B.

The rest of the chapter is organized as follows. The first section introduces alignment and some notations used. In section 2, we define the preprocessing steps and show that they preserve the semantics of the program in a weak bisimulation; we also give their domains and ranges to show that they can be applied one after the other as laid out above. In section 3, we define the core de- and refunctionalization and prove strong bisimulation for them. Section 4 discusses related work.

\section{Preliminaries}

\subsection{Aligning patterns}

To prevent destructor extraction from introducing overlaps, it is necessary that, for all function definitions of the program, all lhss of the function definition \textit{align} -- and in fact, this property is already sufficient for this purpose. In short, for two copatterns $q_1, q_2$ to align means that any pattern directly under $q_1$ has the same specificity as its respective counterpart under $q_2$, if any. In this section, we first illustrate why the correctness of destructor extraction depends upon the alignment of the lhss. Then we formally define alignment and prove that alignment suffices to prevent the introduction of overlaps via destructor extraction. In appendix B, we give an algorithm for aligning copatterns.

When extracting destructors out of a program which has non-aligning lhss, the resulting program can have overlapping lhss even though the original program didn't. Consider the following example where the first and the third equations don't align (as well as the second and the third equation).

\begin{lstlisting}

fun().d1(c1()).d1() = t_1
fun().d1(c2()).d1() = t_2
fun().d1(x).d2() = t_3

\end{lstlisting}

Why don't these equations align? The third equation's left-hand side has a catch-all pattern (variable) in its first destructor call $d1$. The first destructor in the first and second equations' left-hand sides is also $d1$, but the patterns there are the constructors $c1()$ and $c2()$, respectively; they are more specific than the catch-all pattern.

If we target the first lhs for destructor extraction, its final destructor is extracted; the result of this is shown below (we omit the generated auxiliary function definition).

\begin{lstlisting}

fun().d1(c1()) = aux()
fun().d1(c2()).d1() = t_2
fun().d1(x).d2() = t_3

\end{lstlisting}

Now, the first and the third lhs overlap. For destructor extraction to work correctly, the catch-all pattern must be split before the extraction. The program fragment after this split is shown below.

\begin{lstlisting}

fun().d1(c1()).d1() = t_1
fun().d1(c2()).d1() = t_2
fun().d1(c1()).d2() = t_3
fun().d1(c2()).d2() = t_3

\end{lstlisting}

When we now target the first lhs for destructor extraction, this transformation also affects the third lhs because they have the same remains. Thus the extraction results in the equations shown below.

\begin{lstlisting}

fun().d1(c1()) = aux()
fun().d1(c2()).d1() = t_2
fun().d1(c1()) = aux()
fun().d1(c2()).d2() = t_3

\end{lstlisting}

The first and the third equation are identical and are thus present only once in the program, thus the program doesn't have overlapping lhss. The program that was transformed has only aligned lhss. In fact, to prevent destructor extraction from introducing overlaps it suffices that the transformed program has this property, as we will show further on.

Now, we formally define what it means for a (co-)pattern to be \textit{aligned} with another (co-)pattern.

\begin{definition}[Aligning patterns]
Two patterns $p_1, p_2$ of the same type align if they are (a) both variables, (b) both constructor calls of different constructors, or (c) constructor calls of the same constructor $con$ such that
\[
p_1 = con(p'_1, ..., p'_n), p_2 = con(p''_1, ..., p''_n),
\]
where, for all $i \in \{1, ..., n\}$, $p'_i$ and $p''_i$ align.
\end{definition}

\begin{definition}[Aligning copatterns]
Two copatterns $q_1, q_2$ of the same function definition, for a function $fun$, align if the respective arguments of their largest common destructor call chains align.
\end{definition}

Aligning patterns of a program before applying destructor extraction guarantees that the destructor extraction doesn't introduce overlaps. As shown in subsection 4.2.2, this follows from the following lemma.

\begin{lemma}
For any program $prg$ without overlapping lhss and where, for all of its function definitions $def$, all lhss of $def$ align with each other, the following holds: Whenever two prefixes of $prg$ overlap, one of them is a prefix of the other.

\begin{proof}
Suppose there are two lhss $q_1, q_2$ with prefixes $q^{\mathit{pref}}_1$ and $q^{\mathit{pref}}_2$, respectively, such that these prefixes overlap. Especially, this means that one of them -- w.l.o.g., $q^{\mathit{pref}}_1$ -- has an initial destructor chain $C$ that is identical to the entire destructor chain of the other, $q^{\mathit{pref}}_2$. Thus the entire destructor chain of $q^{\mathit{pref}}_2$ is a part of the largest common destructor chain of $q_1$ and $q_2$. It follows that all of the pattern arguments of the initial destructor chain $C$ of $q^{\mathit{pref}}_1$ align with the respective arguments of the destructor chain of $q^{\mathit{pref}}_2$. For the associated instances of these two destructor chains to overlap, it also needs to be the case that their respective pattern arguments overlap. Whenever two patterns overlap and align they are the same, thus $q^{\mathit{pref}}_2$ is a prefix of $q^{\mathit{pref}}_1$.
\end{proof}
\end{lemma}

\subsection{Notation}

We define the following conditional recursion combinator:
\[
    condrec(f, cond) :=
\begin{cases}
    condrec(f, cond) \circ f,& \text{if $cond$ holds} \\
   id,& \text{otherwise}
\end{cases}
\]

\section{Preprocessing steps}

Each preprocessing step is applied to each function definition individually. It is thus assumed that the function $fun$ of the function definition to be transformed is available to the transformation. For the complete step, simply transform all function definitions, in arbitrary order.

Roughly, each preprocessing step is defined as a recursive composition of one of three example extractions defined at the end of chapter 3 lifted to programs with $liftp$. More precisely, they all have definitions of the form
\[
condrec(liftp(extract \circ q\_selector), cond),
\]
for some continue condition $cond$, some extraction transformation (as defined in chapter 3) $extract$ with the targeted copattern left as an argument, and some function $q\_selector$ selecting the lhs (of the function definition of $fun$) that is to be targeted. The three parameters $cond$, $extract$, and $q\_selector$ uniquely determine the desired preprocessing step, thus all of those steps will be defined by only defining them. In any case $extract$ is chosen to be one of the example extractions from section 3.5, that is, either $extract\_des$, $extract\_con$, or $extract\_patterns$.

For each preprocessing, to show that a kind of weak bisimulation holds it suffices to show that, at no point in the recursive extraction, overlapping lhss are generated. From chapter 3, we know that the in there described kind of weak bisimulation holds for any extraction transformation as defined in chapter 3, as long as the transformed program doesn't have overlapping lhss. Both steps are defined as recursive compositions of $extract\_des$, thus we can combine the bisimulation statements for $extract\_des$ to obtain a kind of weak bisimulation for the entire preprocessing step, provided that overlapping lhss are never generated in the recursive process.

\subsection{Eliminate multiple destructors}

In this section, we define both $elim\_multi\_des_d$ and $elim\_multi\_des_r$, by defining their common parameters $q\_selector$ and $extract$ and their respective continue conditions $cond_d$ and $cond_r$.

\begin{itemize}
\item $q\_selector$: Selects an lhs with a maximal number of lhss (but is otherwise arbitrary).

\item $extract := extract\_des$ (as defined in chapter 3).

\item $cond_d$: Continue when the function definition still contains multiple destructor lhss.

\item $cond_r$: Continue when the function definition still contains multiple destructor lhss with constructors.
\end{itemize}

Now, we show that, at no point in the recursive extraction, overlapping lhss are generated.

Now, consider a singular destructor extraction. By Proposition 3.4.1, we need only compare equations taken over unchanged and the equation $\epsilon$ generated by the extraction. By Lemma 4.1.1, since all lhss of the input program align, whenever two prefixes of lhss of the original program overlap, one of them is a prefix of the other. $q_\epsilon$ is a prefix of an lhs $q_r$ of the original program; if it overlapped with a $q_{r'}$ taken over unchanged then $q_{r'}$ (a prefix of itself) and the prefix $q_\epsilon$ of $q_r$ overlapped. But then, by Lemma 4.1.1, either (a) $q_\epsilon$ is a prefix of $q_{r'}$ or (b) $q_{r'}$ is a prefix of $q_\epsilon$. In case (a) it is either $q_\epsilon = q_{r'}$, but then $q_{r'}$ and $q_r$ overlapped contrary to assumption, or, since $q_{r'}$ doesn't have more destructors than $q_r$, $q_{r'}$ is identical to $q_r$ except for the last destructor call, but then $q_{r'}$ would also be targeted by the destructor extraction, contrary to assumption. In case (b) $q_{r'}$ is a prefix of $q_r$ and thus they overlap, again contrary to assumption.

\subsection{Unmix}

In this section, we define $unmix$, by defining its parameters $q\_selector$, $extract$, and $cond$.

\begin{itemize}
\item $q\_selector$: Selects an lhs with a maximal number of lhss (but is otherwise arbitrary).

\item $extract := extract\_des$ (as defined in section 3.5.1).

\item $cond$: Continue when the function definition still is mixed.
\end{itemize}

Overlapping lhss are never generated, for the same reasons we gave for $elim\_multi\_des_d$ and $elim\_multi\_des_r$ in section 4.2.1.

\subsection{Eliminate constructors from destructor copatterns}

In this section, we define $elim\_cons\_from\_des$, by defining its parameters $q\_selector$, $extract$, and $cond$.

\begin{itemize}
\item $q\_selector$: Selects an arbitrary lhs.

\item $extract := extract\_patterns$ (as defined in section 3.5.3).

\item $cond$: Continue when the function definition still has lhss with constructors.
\end{itemize}

Now, we show that, at no point in the recursive extraction, overlapping lhss are generated. We consider a singular extraction with $extract\_patterns$. By Proposition 3.4.1, we need only compare equations taken over unchanged and the equation $\epsilon$ generated by the extraction. The extraction $extract\_patterns$ is only ever applied to single-destructor copatterns and transforms them to single-destructor copatterns without any constructors. It is also only ever used in unmixed function definitions where all lhss have exactly one destructor. If the destructor of such an lhs $q$ is different from that of $q_\epsilon$, they cannot overlap. But if the destructor of $q$ is the same as that of $q_\epsilon$, and thus the same as that of $q_r$, the extraction result is the same for both $q_r$ and $q$. Thus, by the definition of extraction functions, the equations of $q_r$ and $q$ are the same.

\subsection{Eliminate multiple constructors}

In this section, we define $elim\_multi\_con$, by defining its parameters $q\_selector$, $extract$, and $cond$.

\begin{itemize}
\item $q\_selector$: Selects an arbitrary lhs.

\item $extract := extract\_con$ (as defined in section 3.5.3).

\item $cond$: Continue when there still is an lhs that doesn't have the form $fun(con(\overline{x}), \overline{y})$ or $fun(\overline{x})$.
\end{itemize}

Now, we show that, at no point in the recursive extraction, overlapping lhss are generated. We consider a singular extraction with $extract\_con$. TODO

\section{Core de- and refunctionalization}

\subsection{Core defunctionalization}

After the preprocessing steps, the only thing that remains is to apply the defunctionalization for the Codata Fragment of Uroboro, as developed by Rendel et al., to the not yet defunctionalized parts of the program. It can be applied to these parts because the preprocessing steps guarantee that they are in the Codata Fragment. Call the defunctionalization for the Data Fragment of Uroboro $d^{codata}$; the core defunctionalization for programs is defined as follows below.

\begin{alignat*}{3}
\langle prg \rangle^{d_{core}} & = ~&& \langle && \{ def \in prg ~ | ~ def \textrm{ is codata def. or} \\ & && &&\quad \textrm{ function def. with equations } eqns \neq \emptyset: \forall e \in eqns: e \textrm{ has destr. pattern } \} \rangle^{d^{codata}} \\
& \cup && \{ && \textrm{\textbf{data }} ... ~ | ~ `` \textrm{\textbf{data }} ... " \in prg \} \\
& \cup && \{ && \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} \{ p = \langle t \rangle^d ~ | ~ "p = t" \in eqns \} \\
& && | && `` \textrm{\textbf{function }} fun(\sigma, \tau_1, ..., \tau_k): \tau \textrm{\textbf{ where }} eqns " \in prg \textrm{ with } \forall e \in eqns: e \textrm{ has hole pattern}\} 
\end{alignat*}

Technical note on constructor subsumption:

The input of $d^{codata}$ in the definition above is actually not in its domain. This is because it can contain constructor calls. The following technical trick allows to transform such inputs as well: For the sake of $d^{codata}$, subsume constructor names under function names (as if they were from the same syntactic domain). After the transformation, since names aren't changed (or when name changes are desired, the original name can still be retrieved), the subsumed constructor names (or their equivalents after a name change) are once again considered constructor names (from the original syntactic domain).

Defunctionalizing terms: \\
$\langle x \rangle^d = x$ \\
$\langle s.des(t_1, ..., t_n) \rangle^d = \langle des \rangle^d (\langle s \rangle^d, \langle t_1 \rangle^d, ..., \langle t_n \rangle^d)$ \\
$\langle fun(t_1, ..., t_n) \rangle^d = \langle fun \rangle^d (\langle t_1 \rangle^d, ..., \langle t_n \rangle^d)$ \\
$\langle con(t_1, ..., t_n) \rangle^d = con(\langle t_1 \rangle^d, ..., \langle t_n \rangle^d)$ \\

\subsubsection{Proof of strong bisimulation}

For $d_{core}$, strong bisimulation holds. The proof relies on properties of $d^{codata}$. As stated in section 2.3.1, the authors' notion of reducibility is the same than that of this work when restricted to the domain of $d^{codata}$, the Codata Fragment.

In section 3, Rendel et al. prove Lemma 5, which in terms of this work can be stated as follows (possible since the reducibility notions are identical):

$s \longrightarrow_{prg} t \iff \langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$ for all input terms $s,t$ of $\langle \cdot \rangle$ (*)

Here, the angular brackets can stand for either of their transformations, the refunctionalization $r^{data}$ and the defunctionalization $d^{codata}$. Statement (*) means that strong bisimulation holds for $d^{codata}$.

Using (*), it will now be shown that strong bisimulation holds for $d_{core}$.

\begin{proof}[Proof of strong bisimulation for $d_{core}$] ~

$`` \Rightarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$s =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(prg)$}
\UnaryInfC{$s \longrightarrow s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = t$; the immediate subterms of $s$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^d$, $\langle t \rangle = \langle t \rangle^d$. $d$ is the defunctionalization of terms as defined above. This defunctionalization of terms is also, for all input terms from the fragment, identical to that of the Codata Fragment.

\begin{itemize}

\item \underline{Case 1}: $q$ is hole pattern:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a hole pattern (other cases are excluded by the relevant input fragment for $d_{core}$). Such equations (and indeed the function definitions) are left unchanged by $d_{core}$ except for defunctionalizing the right-hand term, as can be seen directly in the definition of $d_{core}$ (last set in the highest-level union). Thus Rules($\langle prg \rangle$) contains $(q, \langle s' \rangle)$.

By inversion, we have from $s =^? q \searrow \sigma$ that $s$ has the form $fun(v_1, ..., v_n)$ for some values $v_1, ..., v_n$, thus $\langle s \rangle = fun(\langle v_1 \rangle, ..., \langle v_n \rangle)$. By inversion for values, we have that each $v_i$ is either a constructor application or a value of codata type. If it is a value of codata type, by inversion on pattern matching, the relevant subpattern of $q$ can only be a variable, thus it is also matched by $\langle v_i \rangle$. If it is a constructor application, the relevant subpattern of $q$ is either a variable, and the same holds, or it is a constructor pattern, and by recursively descending into its subpatterns we still get that $\langle v_i \rangle = con(\langle v^1_i \rangle, ..., \langle v^m_n \rangle)$ matches against the subpattern of $q$.

By carrying the substitutions returned from the matchings along in the above recursive argument, we get a substitution $\sigma'$ such that $\langle s \rangle =^? q \searrow \sigma'$ and, by distributing over $\langle s' \rangle$, $\langle s' \rangle [\sigma'] = \langle s'[\sigma] \rangle = \langle t \rangle$. It follows that $\langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$.

\item \underline{Case 2}: $q = fun(p_1, ..., p_n).des(p'_1, ..., p'_k)$:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a destructor pattern (other cases are excluded by the relevant input fragment for $d_{core}$). Thus $s$ reduces to $t$ already with respect to the part of the program that is passed to $d^{codata}$, as specified in the definition of $d_{core}$. Let this part, amended by the ``constructor subsumption" noted for the definition of $d_{core}$, be $prg'$; it is: $s \longrightarrow_{prg'} t$

By (*) we would have

\begin{equation*}
s \longrightarrow_{prg'} t \iff \langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle,
\end{equation*}

were $prg'$ a well-typed program with copattern coverage for all subterms of $s$. 

For the coverage, bear in mind that the equation $`` q = s' "$ enabling the reduction of $s$ by the ``Subst" rule is part of $prg'$ by the precondition of Case 2. As $s$ matches against $q$, copattern coverage for $s$ is trivially fulfilled in $prg'$. The immediate subterms of $s$ are values with respect to $prg$ and, by inversion, their immediate subterms and so forth, which especially means that there is no rule in $prg$ against which they match. But $prg$ has copattern coverage for such a subterm (TODO: make this a general precondition) and there is already no rule for it in $prg$. It follows that $prg'$ still has copattern coverage for the subterm even though there is no rule for it in $prg'$. This is because, either (1) the subterm is a destructor call, then it can only be covered by destructor copatterns (as it matches against a destructor copattern) and those only occur within $prg'$, or (2) it is a constructor call, which doesn't need to be matched for coverage. It can't be a function call, since these can only be covered by directly matching the call, which isn't the case even in $prg$, for which coverage is assumed. Thus coverage holds for $prg'$.

For well-typedness, simply treat the missing types temporarily, that is, for the sake of (*), as codata types. This is no problem for the restriction to the domain of $d^{codata}$, since such types could be introduced inside the Codata Fragment with codata definitions. To be more precise, empty function definitions can be added for missing ones and empty codata definitions for missing types, and removed again after using (*), without adding or removing possible reductions, respectively. All in all, we have by (*):
\begin{equation*}
s \longrightarrow_{prg'} t \iff \langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle
\end{equation*}

But this program $\langle prg' \rangle^{d^{codata}}$ is a subset of $\langle prg \rangle$, as can be seen in the definition of $d_{core}$. This implies the desired $\langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$.

\end{itemize}

Other cases are excluded by the relevant input fragment.

\item \textbf{``Cong" case}:

\begin{prooftree}
\AxiomC{$s' \longrightarrow t'$}
\RightLabel{Cong}
\UnaryInfC{$\mathcal{E}[s'] \longrightarrow \mathcal{E}[t']$}
\end{prooftree}

with $\mathcal{E}[s'] = s$ and $\mathcal{E}[t'] = t$.

By the induction hypothesis we have $\langle s' \rangle \longrightarrow_{\langle prg \rangle} \langle t' \rangle$. Let $\langle \mathcal{E} \rangle$ denote the transformation of $\mathcal{E}$, defined analogously to the transformation of terms by transforming the terms in $\mathcal{E}$ and by setting $\langle [] \rangle = []$. By applying the congruence rule we get $\langle \mathcal{E} \rangle[\langle s' \rangle] \longrightarrow_{\langle prg \rangle} \langle \mathcal{E} \rangle[\langle t' \rangle]$. It is clear that $\langle \mathcal{E} \rangle[\langle s' \rangle] = \langle \mathcal{E}[s'] \rangle = \langle s \rangle$ and $\langle \mathcal{E} \rangle[\langle t' \rangle] = \langle \mathcal{E}[t'] \rangle = \langle t \rangle$.

\end{enumerate}

$`` \Leftarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$\langle s \rangle =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(\langle prg \rangle)$}
\UnaryInfC{$\langle s \rangle \longrightarrow_{\langle prg \rangle} s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = \langle t \rangle$; the immediate subterms of $\langle s \rangle$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^d$, $\langle t \rangle = \langle t \rangle^d$. $d$ is the defunctionalization of terms as defined above. This defunctionalization of terms is also, for all input terms from the fragment, identical to that of the Codata Fragment.

The equation $`` q = s' "$ can either be contained in that part of $\langle prg \rangle$ that results from the application of $d^{codata}$ to the relevant part of $prg$, as specified in the definition of $d''$, or it can be in the other part of $\langle prg \rangle$. As can be seen in the definition of $d''$, this other part is taken over unchanged from $prg$ except for defunctionalizing the right-hand terms. Thus for an equation $`` q = s' "$ from this part, the equation $`` q = s'' "$ with $s' = \langle s'' \rangle$ is present in $prg$. For such an equation, $q$ has hole pattern. It can then be easily seen that $s =^? q \searrow \sigma'$ for a $\sigma'$ with $s''[\sigma'] = t$ by an argument analogous to that of $`` \Rightarrow "$, ``Subst" case, Case 1.

Now, suppose that $`` q = s' "$ is contained in the part of $\langle prg \rangle$ that results from the application of $d^{codata}$ to the relevant part $prg' \subseteq prg$. Thus $\langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle$.

By (*) we would have

\begin{equation*}
\langle s \rangle \longrightarrow_{\langle prg' \rangle^{d^{codata}}} \langle t \rangle \iff s \longrightarrow_{prg'} t,
\end{equation*}

were $prg'$ a well-typed program with copattern coverage for all subterms of $s$. Both of those properties can be shown or simulated similarly to the way they are in the $`` \Rightarrow "$ part.

But it is $prg' \subseteq prg$, as can be seen in the definition of $d''$. This implies the desired $s \longrightarrow_{prg} t$.

\item \textbf{``Cong" case}:

\begin{prooftree}
\AxiomC{$s' \longrightarrow_{\langle prg \rangle} t'$}
\RightLabel{Cong}
\UnaryInfC{$\mathcal{E}[s'] \longrightarrow \mathcal{E}[t']$}
\end{prooftree}

with $\mathcal{E}[s'] = \langle s \rangle$ and $\mathcal{E}[t'] = \langle t \rangle$.

By the induction hypothesis we have $s'' \longrightarrow_{prg} t''$ with $s' = \langle s'' \rangle$, $t' = \langle t'' \rangle$. Let $\langle \mathcal{E} \rangle$ denote the transformation of $\mathcal{E}$ (defined as in the $`` \Rightarrow "$ part). Apply the congruence rule to get $\mathcal{E}'[s''] \longrightarrow_{prg} \mathcal{E}'[t'']$ with $\mathcal{E} = \langle \mathcal{E}' \rangle$. That is, $\mathcal{E}'$ is the result of applying the inverse of $\langle \cdot \rangle$ to $\mathcal{E}$, which is possible, since, for instance, $\mathcal{E}[s'] = \langle s \rangle$. It is $\langle \mathcal{E}'[s''] \rangle = \langle \mathcal{E}' \rangle[\langle s'' \rangle] = \mathcal{E}[s'] = \langle s \rangle$ and $\langle \mathcal{E}'[t''] \rangle = \langle \mathcal{E}' \rangle[\langle t'' \rangle] = \mathcal{E}[t'] = \langle t \rangle$ and thus we have the desired $s \longrightarrow_{prg} t$.
\end{enumerate}

\end{proof}

\subsection{Core refunctionalization}

This is defined analogously to core defunctionalization, by applying the refunctionalization for the Data Fragment of Uroboro to the not yet refunctionalized parts of the program. It can be applied to these parts because the preprocessing steps guarantee that they are in the Data Fragment. Call the refunctionalization for the Data Fragment of Uroboro $r^{data}$; the core refunctionalization for programs is defined as follows below.

First, a technical note: As $r_{core}$ doesn't allow destructor terms in its inputs, they have to be converted beforehand. This conversion is the same as that of $r$ for terms below, restricted to destructor terms. Call this conversion lifted to programs (in the way that all destructor terms on right-hand sides or as subterms of them are converted) $des\_conv$.

\begin{alignat*}{3}
\langle prg \rangle^{r_{core}} & = ~&& \langle \langle && \{ def \in prg ~ | ~ def \textrm{ is data def. or} \\ & && &&\quad \textrm{ function def. with equations } eqns \neq \emptyset: \forall e \in eqns: e \textrm{ has no destr. pattern}, \\
& && &&\qquad \textrm{the first argument of the lhs isn't a variable } \} \rangle^{des\_conv} \rangle^{r_{core}} \\
& \cup && \{ && \textrm{\textbf{codata }} ... ~ | ~ `` \textrm{\textbf{codata }} ... " \in prg \} \\
& \cup && \{ && \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} \{ p = \langle t, prg \rangle^r ~ | ~ "p = t" \in eqns \} \\
& && | && `` \textrm{\textbf{function }} fun(\tau_1, ..., \tau_n): \sigma \textrm{\textbf{ where }} eqns " \in prg \textrm{ with } \forall e \in eqns: e \textrm{ has destr. pattern} \\
& && &&\quad \textrm{or where } n = 0 \textrm{ or where the first argument of the lhs is a variable} \} 
\end{alignat*}

Along with the transformation for programs, a transformation of terms is necessary, which is a conservative extension of $r^{data}$ for programs. For this, write $r$ short for $r_{core}$ \\
$\langle x, prg \rangle^r = x$ \\
$\langle s.des(t_1, ..., t_n), prg \rangle^r = \langle s, prg \rangle^r .des(\langle t_1, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$ \\
$\langle fun(t_1, ..., t_n), prg \rangle^r = fun(\langle t_1, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$, \\
if ``\textbf{function} $fun(\tau_n, ..., \tau_n): \sigma$ \textbf{where} $eqns$" $\in prg$  with $\forall e \in eqns: e$ has destructor pattern or where $n = 0$ or where the first argument of the lhs is a variable \\
$\langle fun(t_1, ..., t_n), prg \rangle^r = \langle t_1, prg \rangle^r .\langle fun, prg \rangle^r (\langle t_2, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$, \\
otherwise \\
$\langle con(t_1, ..., t_n), prg \rangle^r = \langle con, prg \rangle^r (\langle t_1, prg \rangle^r, ..., \langle t_n, prg \rangle^r)$ \\

Note that the case distinction above is only necessary because of the special syntax for destructors ($q(...).des(...)$ instead of $des(..., ...)$).

\subsubsection{Proof of strong bisimulation}

For $r_{core}$, strong bisimulation holds. The proof relies on properties of $r^{data}$. As stated in section 2.3.1, the authors' notion of reducibility is the same than that of this work when restricted to the domain of $r^{data}$, the Data Fragment.

In section 3, Rendel et al. prove Lemma 5, which in terms of this work can be stated as follows (possible since the reducibility notions are identical):

$s \longrightarrow_{prg} t \iff \langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$ for all input terms $s,t$ of $\langle \cdot \rangle$ (*)

Here, the angular brackets can stand for either of their transformations, the refunctionalization $r^{data}$ and the defunctionalization $d^{codata}$. Statement (*) means that strong bisimulation holds for $r^{data}$.

Using (*), it will now be shown that strong bisimulation holds for $r_{core}$.

\begin{proof}[Proof of strong bisimulation for $r_{core}$] ~

$`` \Rightarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$s =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(prg)$}
\UnaryInfC{$s \longrightarrow s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = t$; the immediate subterms of $s$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^r$, $\langle t \rangle = \langle t \rangle^r$. $r$ is the refunctionalization of terms as defined above (it is omitted that $prg$ is passed to $r$ as well). This refunctionalization of terms is also, for all input terms from the fragment, identical to that of the Data Fragment.

\begin{itemize}

\item \underline{Case 1}: $q$ is destructor pattern:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a destructor pattern (other cases are excluded by the relevant input fragment for $r_{core}$). Such equations (and indeed the function definitions) are left unchanged by $r_{core}$ except for refunctionalizing the right-hand term, as can be seen directly in the definition of $r_{core}$ (last set in the highest-level union). Thus Rules($\langle prg \rangle$) contains $(q, \langle s' \rangle)$.

From here, the argument proceeds analogously to that of $`` \Rightarrow "$, ``Subst" case, Case 1, in the proof for $d_{core}$.

\item \underline{Case 2}: $q$ is hole pattern without arguments or where the first argument is a variable:

Then the equation is left unchanged by $r_{core}$ except for refunctionalizing the right-hand term, as can be seen directly in the definition of $r_{core}$ (last set in the highest-level union). Proceed as in Case 1.

\item \underline{Case 3}: $q$ is hole pattern and has a first argument which is a constructor pattern:

Then the function definition that contains $`` q = s' "$ contains only equations where the left-hand side is a hole pattern (other cases are excluded by the relevant input fragment for $r_{core}$), and it has a first argument with data type. Thus $s$ reduces to $t$ already with respect to the part of the program that is passed to $des\_conv$, and then the result of this to $r^{data}$, as specified in the definition of $r_{core}$. Let the part passed to $des\_conv$ be $prg'$; it is: $s \longrightarrow_{prg'} t$.

By (*) we have

\begin{equation*}
s \longrightarrow_{prg'} t \iff \langle s \rangle \longrightarrow_{\langle prg' \rangle^{r^{data}}} \langle t \rangle,
\end{equation*}

But this program $\langle prg' \rangle^{r^{data}}$ is a subset of $\langle prg \rangle$, as can be seen in the definition of $r_{core}$. Thus we have the desired $\langle s \rangle \longrightarrow_{\langle prg \rangle} \langle t \rangle$.

\end{itemize}

\item \textbf{``Cong" case}:

The argument here is identical to that of this case of this direction in the proof for $d_{core}$.

\end{enumerate}

$`` \Leftarrow "$: By induction on the structure of $\mathcal{D}$.

\begin{enumerate}
\item \textbf{``Subst" case}:

\begin{prooftree}
\AxiomC{$\mathcal{D}_{\textrm{PM}}$}
\UnaryInfC{$\langle s \rangle =^? q \searrow \sigma$ with $(q, s') \in \textrm{Rules}(\langle prg \rangle)$}
\UnaryInfC{$\langle s \rangle \longrightarrow_{\langle prg \rangle} s'[\sigma]$}
\end{prooftree}

with $s'[\sigma] = \langle t \rangle$; the immediate subterms of $\langle s \rangle$ are values; $\mathcal{D}_{\textrm{PM}}$ is a derivation of the pattern matching. This transformation changes input terms, thus $\langle s \rangle = \langle s \rangle^r$, $\langle t \rangle = \langle t \rangle^r$. $r$ is the refunctionalization of terms defined above. This refunctionalization of terms is also, for all input terms from the fragment, identical to that of the Data Fragment.

The equation $`` q = s' "$ can either be contained in that part of $\langle prg \rangle$ that results from the application of $des\_conv$ and then $r^{data}$ to the relevant part of $prg$, as specified in the definition of $r_{core}$, or it can be in the other part of $\langle prg \rangle$. As can be seen in the definition of $r_{core}$, this other part is taken over unchanged from $prg$ except for refunctionalizing the right-hand terms. Thus for an equation $`` q = s' "$ from this part, the equation $`` q = s'' "$ with $s' = \langle s'' \rangle$ is present in $prg$. For such an equation, $q$ has hole pattern. It can then be easily seen that $s =^? q \searrow \sigma'$ for a $\sigma'$ with $s''[\sigma'] = t$ by an argument analogous to that of $`` \Rightarrow "$, ``Subst" case, Case 1, in the proof for $d_{core}$.

Now, suppose that $`` q = s' "$ is contained in the part of $\langle prg \rangle$ that results from the application of $des\_conv$ and then $r^{data}$ to the relevant part $prg' \subseteq prg$. Thus $\langle s \rangle \longrightarrow_{\langle \langle prg' \rangle^{des\_conv} \rangle^{r^{data}}} \langle t \rangle$.

By (*) we have

\begin{equation*}
\langle s \rangle \longrightarrow_{\langle \langle prg' \rangle^{des\_conv} \rangle^{r^{data}}} \langle t \rangle \iff s \longrightarrow_{\langle prg' \rangle^{des\_conv}} t.
\end{equation*}

In the result of $des\_conv$, no new matching left-hand sides are added. That is, $prg'$ contains at least all the matching left-hand sides that $\langle prg' \rangle^{des\_conv}$ has. Thus any reduction that is possible with respect to $\langle prg' \rangle^{des\_conv}$ is already possible with respect to $prg'$.

But it is $prg' \subseteq prg$, as can be seen in the definition of $r_{core}$. This implies the desired $s \longrightarrow_{prg} t$.
\end{enumerate}

\item \textbf{``Cong" case}:

The argument here is identical to that of this case of this direction in the proof for $d_{core}$.

\end{proof}

%\section{Simplifying copatterns (Alternative approach to de- and refunc.}
%
%Both de- and refunctionalization are made up of two major parts:
%\begin{enumerate}
%\item First, destructor and constructor extractions alternate to transform the program into a form which can be used by the second part.
%
%\item This second part is the core de-/refunctionalization, which is essentially the two-way transformation from the paper of Rendel et al.
%\end{enumerate}
%
%The \textit{simplifying} part of the defunctionalization transformation is made up of destructor and constructor extraction steps and stops when the program is in the input fragment of core defunctionalization, described below. The simplifying part of the refunctionalization transformation is defined like that, with the only difference being that it stops when the program is in the input fragment of core refunctionalization, also described below.
%
%This simplification is done individually for each function definition, the order in which the function definitions are transformed is unimportant. For one function definition $def$, the algorithm is defined below.
%
%\[
%  \langle prg \rangle^{simplify(def)}=\begin{cases}
%               prg, &\text{ if $def$ is in the desired fragment}\\
%               \langle prg \rangle^{simplify\_step(def)} \rangle^{simplify(def)}, &\text{ otherwise}
%            \end{cases}
%\]
%
%\[
%  \langle prg \rangle^{simplify\_step(def)}=\begin{cases}
%               \langle prg \rangle^{liftp(des\_extract(q^{max}_{def}))}, \\
%               \qquad\text{ if } \langle prg \rangle^{liftp(con_{n_{def}}\_extract(q^{max}_{def}))} \text{ has overlaps}\\
%               \langle prg \rangle^{liftp(con_{n_{def}}\_extract(q^{max}_{def}))},\\
%               \qquad\text{ otherwise}
%            \end{cases}
%\]
%
%with
%
%\[
%q^{max}_{def} = \textrm{max}_{\# con.} \textrm{max}_{\# des.} \{q ~ | ~ q \text{ is lhs in $def$ } \}
%\]
%
%and $n_{def}$ the number of the inner-most constructor in $q^{max}_{def}$ which has a variable ``in its place'' in another lhs of $def$. For a pattern $p$ of a copattern $q$ to be ``in the place'' of another pattern $p'$ in another copattern $q'$ means:
%\begin{itemize}
%\item When $p$ is a subterm of the $n$-th pattern immediately under $q$, then $p'$ is a subterm of the $n$-th pattern immediately under $q$,
%
%\item the same for the $m$-th pattern immediately under the $n$-th patterns if $p$ and/or $p'$ aren't the $n$-th patterns themselves,
%
%\item and so on recursively.
%\end{itemize}
%
%As can be seen in the definition of $simplify\_step$, the algorithm switches from destructor to constructor extraction whenever constructor extraction would produce overlapping lhss. This actually prevents overlaps, because, whenever constructor extraction would produce overlaps, destructor extraction doesn't, as will be shown below.
%
%Clearly, this also means that the algorithm eventually arrives at a function definition without any destructors and without any constructors, unless it stops before that, thus ensuring that the desired fragment will be reached in any case.
%
%\subsection{Bisimulation}
%
%Two properties are desired for this algorithm: some kind of bisimulation, and that no overlapping lhss are generated. Since the algorithm is made up only of $des\_extract$ and $con\_extract$ steps, these properties follow from their respective properties.
%
%When overlapping lhss are absent in the transformed program, we have the kind of weak bisimulation as established by Proposition 2.3.1 for both $des\_extract$ and $con\_extract$, irrespective of which lhs is targeted. That overlaps aren't generated by one such step will be shown in the following subsection.
%
%\subsection{Absence of overlaps}
%
%By Proposition 2.4.1, for both $des\_extract$ and $con\_extract$, it suffices to show that $q_\epsilon$ doesn't overlap with unchanged lhss. This doesn't hold for arbitrary targeted lhss; in order to avoid generating overlaps, $simplify\_step$ was defined as above. It is now shown that this definition really prevents overlaps in the resulting program of one such step. As pointed out above, because of the definition of $simplify\_step$, it suffices to show that destructor extraction doesn't produce overlaps whenever constructor extraction does.
%
%When constructor extraction leads to overlaps, ...
